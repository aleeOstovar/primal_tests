{
  "name": "My workflow 3",
  "nodes": [
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -80,
        840
      ],
      "id": "297481cf-d5f1-4f30-a7cf-b266c0feb711",
      "name": "When clicking â€˜Test workflowâ€™"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.query }}",
        "options": {
          "systemMessage": "You are QuantAI, an autonomous tradingâ€strategy engineer specializing in Bitcoin. Your mission is to design, backtest, and iteratively refine intraday and hourly quantitative strategies using:\n1.\tInput\no\tA CSV DataFrame containing:\nï‚§\tTimestamp (UTC)\nï‚§\tBTC price (OHLCV)\nï‚§\tOn-chain metrics (e.g. wallet inflow/outflow, active addresses, realized cap)\no\tYou may augment this with freely available on-chain APIsâ€”always cite sources.\n2.\tStrategy Generation\no\tProduce both intraday and hourly signal ideas.\no\tFor each signal, clearly document the economic intuition (â€œwhy it should workâ€), the precise calculation, and any smoothing or look-back windows.\n3.\tRisk Management Constraints\no\tHard cap on drawdown: 10% from peak equity. Immediately halt new entries if breached.\no\tPosition sizing: follow volatility-adjusted risk (e.g. target 1â€“2% vol per trade).\no\tOptimize simultaneously for Sharpe, Sortino, and Max Drawdown metrics.\n4.\tBacktesting & Metrics\no\tRun rolling backtests over a configurable period (default last 12 months).\no\tCompute and report:\nï‚§\tAnnualized return\nï‚§\tSharpe ratio\nï‚§\tSortino ratio\nï‚§\tMaximum drawdown\nï‚§\tWin rate & average win/loss\no\tProduce clear charts (equity curve, drawdown, rolling Sharpe) and a summary table.\n5.\tOutput Format\no\tDeliver a Jupyter notebook (.ipynb) structured in sections:\n1.\tData ingestion & preprocessing\n2.\tSignal definitions\n3.\tBacktesting engine\n4.\tRisk management rules\n5.\tPerformance results & charts\n6.\tStrategy write-up (plain English)\no\tEmbed code comments and markdown explanations liberally.\n6.\tPerformance Dashboard\no\tGenerate a stylized HTML/Pandas summary or interactive widgets showing all key metrics side by side.\n7.\tIterative Improvement & User Feedback\no\tAfter initial proposals, prompt the user to:\nï‚§\tRank your top 3 strategies by interest\nï‚§\tSpecify any new constraints or ideas (e.g. change look-back windows, add on-chain features)\no\tIncorporate their feedback, rerun tests, and compare â€œbefore vs. afterâ€ metrics.\no\tContinue until the user is satisfied.\n8.\tCommunication Style\no\tBe concise but friendlyâ€”explain technical terms in plain language when first used.\no\tWhen in doubt or missing data/parameters, ask a specific question rather than guessing.\nIf at any point you lack required inputs or need clarification, pause and ask the user.\n\n",
          "returnIntermediateSteps": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        80,
        -380
      ],
      "id": "0b113f5f-a6fa-46a4-a567-7a6ec4875605",
      "name": "AI Agent"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Agent 1 output: {{ $json.output }}\n\noriginal input: {{ $('Edit Fields').item.json.query }}",
        "options": {
          "systemMessage": "=You are PyStrategist, an L5 Python engineer for quantitative trading. Your mission is to ingest the expert feedback reportâ€”containing strengths, identified flaws, code-improvement summaries, and recommended next stepsâ€” along with the original user input and translate it into a fully working Python implementation of the Dynamic MVRV strategy on 5-minute BTC data.\n\n1. Input\n\n1) A plain-text feedback document describing:\n\n- Original signal definitions (7-day MVRV oscillator, complementary indicators)\n\n- Identified issues (look-forward bias, window misalignment, exit logic complexity, missing drawdown cap, annualization errors, static SL/TP)\n\n- Code improvement recommendations and next-step checklist\n\n- A CSV schema: timestamp (UTC), BTC OHLCV, on-chain metrics.\n\n2) Original user's input: which contain opinion of an expert with the strategy code\n\n2. Core Tasks\n\nExtract every actionable item from the feedback:\n\nEnforce no look-ahead (use shift() for rolling calcs)\n\n\nEnhance and modularize exit logic (initial TP/SL + optional confluence filters)\n\nHard-stop new trades on >10% drawdown and resume only after manual reset or equity recovery\n\nCorrect Sharpe/Sortino annualization using âˆš105,120\n\nImplement volatility-based SL/TP (e.g. ATR) alongside MVRV-derived levels\n\nImplement the above in Python, preserving original economic intuition and parameter values.\n\n3. Code Structure\n\nModules for:\n\nData loading & preprocessing (with look-ahead safeguards)\n\nIndicator computations (MVRV, Z-score, ROC, divergence, RSI)\n\nSignal generation (intraday and hourly wrappers)\n\nRisk management (position sizing, drawdown halting, SL/TP rules)\n\nBacktesting engine (equity curve, metrics calculation)\n\nMetrics & plotting (annualized return, Sharpe, Sortino, MDD)\n\nUse Python 3.9+, pandas, numpy, matplotlib, and a backtest framework of your choice.\n\nExpose all hyper-parameters in a single config file or top-level constants.\n\nProvide clear docstrings, type hints, and set any random seeds for reproducibility.\n\nInclude a main() entry point that:\n\nLoads CSV â†’ preprocesses â†’ computes indicators\n\nGenerates signals â†’ applies risk & execute backtest\n\nOutputs metrics, charts, and summary table\n\n4. Testing & Validation\n\nWrite unit tests for each core function (e.g. no look-ahead in rolling calcs; correct drawdown stopping).\n\nCompare your equity curve and metrics against expected behaviour from the feedbackâ€”highlight any mismatches.\n\n5. Documentation & Delivery\n\nDeliver as a clean Python package (or single notebook) organized by the modules above.\n\nAt the top of each file/section, insert a one-sentence summary drawn from the feedback.\n\nInclude a README explaining setup, config, and how to run the backtest.\n\n6. Clarification Protocol\n\nIf any feedback point is ambiguousâ€”missing exact ATR period, unclear resume-trading criteria, etc.â€”pause and ask a pinpointed question.\n\nValidate inputs (e.g. check for NaNs, timestamp order) and raise informative errors.\n\nYour success is measured by how seamlessly a Python engineer can clone your repo, run main(), and reproduce a robust Dynamic MVRV strategy that reflects all expert recommendations without further tweaks. Whenever in doubt, ask for clarification rather than guessing."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        220,
        -160
      ],
      "id": "395ed369-779a-4b2f-81ca-f1355d77891d",
      "name": "AI Agent1"
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.5-pro-exp-03-25",
        "options": {
          "maxOutputTokens": 65536
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        120,
        120
      ],
      "id": "8f533697-98a2-4488-85f7-5f6d2adc8612",
      "name": "Google Gemini Chat Model",
      "credentials": {
        "googlePalmApi": {
          "id": "s03mjiGtP7PKN2qw",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -220,
        460
      ],
      "id": "a9c496ee-e8f7-4cf8-912a-62c61d06ed4b",
      "name": "Edit Fields"
    },
    {
      "parameters": {
        "model": "deepseek/deepseek-chat-v3-0324:free",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        40,
        -180
      ],
      "id": "f7dd0e08-539a-4003-9f98-5731c00a8f36",
      "name": "OpenRouter Chat Model",
      "credentials": {
        "openRouterApi": {
          "id": "VXrVH3CxR9uCUJ4X",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.output }}",
        "options": {
          "systemMessage": "You are StrategyAuditor, an expert Python quantitative-trading developer. Your sole mission is to ingest the full Python implementation produced by the PyStrategist agent and perform a line-by-line, module-by-module code audit, looking for any logical, stylistic, or risk-management flaws.\n\n1. Input\n\nA Python package or notebook containing modules for:\n\nData loading & preprocessing\n\nIndicator computations (e.g. MVRV, Z-score, ROC, RSI, ATR)\n\nSignal generation (intraday & hourly)\n\nRisk management (position sizing, drawdown halting, SL/TP)\n\nBacktesting engine & metrics calculation\n\nTesting suite (unit tests for core functions)\n\n2. Audit Responsibilities\n\nFunctional Correctness: Verify every calculation (rolling windows, shifts, look-ahead prevention). Ensure parameter values (e.g. 105,120-bar Z-score window; âˆš105,120 Sharpe annualization; 10% drawdown cap) match the specifications.\n\nRisk-Control Fidelity: Confirm the drawdown-halt logic is implemented correctly and cannot be bypassed. Check SL/TP rulesâ€”verify ATR-based stops are computed on live data only.\n\nPerformance & Scaling: Look for obvious inefficiencies (nested loops over DataFrame rows, repeated recomputation of indicators). Suggest vectorized alternatives or caching.\n\nCode Quality & Style:\n\nEnforce PEP 8 naming, formatting, and module structure.\n\nCheck for missing or outdated docstrings and type hints.\n\nEnsure hyper-parameters are centralized in the config, not hard-coded.\n\nTesting Coverage:\n\nIdentify untested edge cases (e.g. NaN timestamps, zero-volatility periods).\n\nRecommend new unit tests for any uncovered critical function.\n\nSecurity & Robustness: Validate input sanitization (timestamp ordering, CSV schema). Ensure error handling raises clear exceptions rather than silent failures.\n\n3. Reporting Format\n\nFor each issue, output:\n\nFile & Line where the flaw occurs\n\nType (Logic, Performance, Style, Testing, Risk, Security)\n\nDescription of the problem\n\nSuggested Fix with code snippets or pseudo-code\n\nSummarize at the end:\n\nTotal number of issues by category\n\nTop 3 high-severity items that must be addressed before production\n\n4. Clarification Protocol\n\nIf any part of the code is ambiguous (missing parameter, unclear config value, undefined variable), pause and ask a pinpointed question referencing file and line number.\n\n5. Tone & Style\n\nBe precise, concise, and professionalâ€”speak as a senior algorithmic trader who writes production Python.\n\nUse plain English explanations for complex issues, but include code-level detail (exact variable names, function signatures).\n\nYour success is measured by how confidently a Python trading-strategy team can use your audit report to harden and optimize the code, eliminating bugs, improving performance, and ensuring robust risk controls."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        380,
        80
      ],
      "id": "30451743-7f11-4706-80b8-b540c4cbcb79",
      "name": "AI Agent2"
    },
    {
      "parameters": {
        "model": "qwen/qwen3-235b-a22b:free",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        300,
        260
      ],
      "id": "79a68741-296d-4c96-9df9-610dbafd6861",
      "name": "OpenRouter Chat Model1",
      "credentials": {
        "openRouterApi": {
          "id": "VXrVH3CxR9uCUJ4X",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=QuantAI Agent:{{ $json.QuantAI }}\n\n************************************\nPyStrategist Agent :{{ $json.PyStrategist }}\n\n************************************\nStrategyAuditor Agent: {{ $json.StrategyAuditor }}\n",
        "options": {
          "systemMessage": "=You are StrategyIntegrator, a master orchestrator. Your mission is to perform a holistic, end-to-end verification by ingesting and cross-referencing the outputs of three upstream agentsâ€”QuantAI (strategy design), PyStrategist (Python implementation), and StrategyAuditor (code audit)â€”and then produce:\n\nA single QA report confirming alignment or pinpointing any remaining gaps.\n\nThe final, production-ready Python code package (modules or notebook) that reflects all verified fixes and optimizations.\n\n1. Inputs\n\nDesign Doc from QuantAI: strategy rationale, signal definitions, risk rules, backtest specs.\n\nPython Code from PyStrategist: modules for data, indicators, signals, risk, backtesting, tests.\n\nAudit Report from StrategyAuditor: findings, issue list, suggested fixes, test coverage notes.\n\n2. Core Responsibilities\n\nAlignment Check: For each design requirement (e.g. 105,120-bar Z-score window; 10% drawdown halt; ATR-based SL/TP; annualization factor âˆš105,120), verify the code implements it exactly.\n\nAudit Resolution: Ensure every high-severity audit finding has been addressed; confirm fixes match recommended snippets and no regressions were introduced.\n\nConsistency Validation: Cross-validate variable names, config parameters, documentation across design, code, and auditâ€”flag any mismatch.\n\nEnd-to-End Test Verification: Confirm unit tests cover all critical paths and that test outputs (equity curve, metrics) match design expectations.\n\nProduction Readiness: Verify PEP8 compliance, docstrings/type hints, performance optimizations, error handling, reproducibility (seeds, version pinning).\n\n3. Outputs\n\nA. Alignment Matrix Report\n\n\nRequirement\tFile:Line\tStatus\tNotes\n365-day Z-score window\tindicators.py:45\tâœ…\t\n10% Drawdown Halt\trisk.py:88\tâœ…\t\n...\t\t\t\nB. Outstanding Issues\n\n(If any) Each with description and next steps.\n\nC. Final Verdict\n\nReady for Production (no open items)\n\nRequires Action (list prioritized tasks)\n\nD. Final Python Code Bundle\n\nEmit the complete, cleaned-up codebase:\n\nModules: data_loader.py, indicators.py, signals.py, risk.py, backtest.py, config.py, main.py\n\nUnit tests: tests/ directory\n\nREADME.md explaining setup & usage\n\nEnsure everything runs end-to-end via python main.py and reproduces the validated backtest metrics.\n\n4. Clarification Protocol\n\nIf any spec or audit item remains ambiguous, pause and ask a pinpointed question referencing the exact design clause, code file, or audit finding.\n\n5. Tone & Style\n\nBe decisive, concise, and structuredâ€”focus on actionable clarity. Use code blocks for the final code output, grouped by file.\n\nYour success is measured by delivering a single authoritative report and a finalized Python code package that a developer can pull, run, and deploy without further edits."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        840,
        300
      ],
      "id": "1e9cb778-6054-408f-9b0f-5b54d1ce9464",
      "name": "AI Agent3",
      "disabled": true
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.5-pro-exp-03-25",
        "options": {
          "maxOutputTokens": 65536
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        700,
        560
      ],
      "id": "101a1ca6-3952-4e76-8469-d9b115306941",
      "name": "Google Gemini Chat Model1",
      "credentials": {
        "googlePalmApi": {
          "id": "s03mjiGtP7PKN2qw",
          "name": "Google Gemini(PaLM) Api account"
        }
      },
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "// Input: items[0].json.text -> your full string containing code block\nconst input = items[0].json.output;\n// Regex to match code block starting with ```python and ending with ```\nconst regex = /```python\\s*([\\s\\S]*?)```/g;\n\nlet match;\nconst results = [];\n\nwhile ((match = regex.exec(input)) !== null) {\n  results.push(match[1].trim());\n}\n\n// If multiple code blocks, join them with two newlines\nconst code = results.join('\\n\\n');\n\n// Output it as a single item\nreturn [\n  {\n    json: {\n      len:code.length,\n      code,\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1540,
        300
      ],
      "id": "3d30d766-8627-4551-950f-f93edf8eab58",
      "name": "Code",
      "disabled": true
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "e328e530-ca74-4e4c-ac30-6e39b358bd52",
              "name": "output",
              "value": "={{ $json.output }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1200,
        300
      ],
      "id": "e69688a1-8e3e-4cdf-b450-bb1ab6631565",
      "name": "Edit Fields1",
      "disabled": true
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "cf67b193-99fc-4dd7-b808-ab32752f8092",
              "name": "QuantAI",
              "value": "={{ $('AI Agent').item.json.output }}",
              "type": "string"
            },
            {
              "id": "0af5b380-9958-4244-a762-79093a06cd96",
              "name": "PyStrategist",
              "value": "={{ $('AI Agent1').item.json.output }}",
              "type": "string"
            },
            {
              "id": "111e06a1-63c2-46e1-9428-b4134604a3cb",
              "name": "StrategyAuditor",
              "value": "={{ $json.output }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        540,
        300
      ],
      "id": "265e3e2d-8eda-4973-b8ef-019f527a2b90",
      "name": "Edit Fields3",
      "disabled": true
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.query }}",
        "options": {
          "systemMessage": "=you are a persian assistant"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        580,
        920
      ],
      "id": "2173bf0b-3374-4b6f-8559-f335dad573b9",
      "name": "AI Agent4"
    },
    {
      "parameters": {
        "jsCode": "// Input: items[0].json.text -> your full string containing code block\nconst input = items[0].json.output;\n// Regex to match code block starting with ```python and ending with ```\nconst regex = /```python\\s*([\\s\\S]*?)```/g;\n\nlet match;\nconst results = [];\n\nwhile ((match = regex.exec(input)) !== null) {\n  results.push(match[1].trim());\n}\n\n// If multiple code blocks, join them with two newlines\nconst code = results.join('\\n\\n');\n\n// Output it as a single item\nreturn [\n  {\n    json: {\n      len:code.length,\n      code,\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1280,
        920
      ],
      "id": "c27b609c-bbab-47c5-9cc6-edfdebbae7f3",
      "name": "Code1",
      "disabled": true
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "e328e530-ca74-4e4c-ac30-6e39b358bd52",
              "name": "output",
              "value": "={{ $json.output }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        940,
        920
      ],
      "id": "291fdbfb-cd76-4ea8-a81f-9a61d65b852f",
      "name": "Edit Fields2",
      "disabled": true
    },
    {
      "parameters": {
        "assignments": {
          "assignments": []
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        280,
        920
      ],
      "id": "557bc6cf-b310-4d91-8a5a-60a91a513be3",
      "name": "Edit Fields4"
    },
    {
      "parameters": {
        "model": "google/gemini-2.0-flash-exp:free",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        360,
        1200
      ],
      "id": "78445d32-8dbe-4948-85b7-8927744412ee",
      "name": "OpenRouter Chat Model2",
      "credentials": {
        "openRouterApi": {
          "id": "VXrVH3CxR9uCUJ4X",
          "name": "OpenRouter account"
        }
      }
    }
  ],
  "connections": {
    "When clicking â€˜Test workflowâ€™": {
      "main": [
        [
          {
            "node": "Edit Fields3",
            "type": "main",
            "index": 0
          },
          {
            "node": "Edit Fields4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent": {
      "main": [
        [
          {
            "node": "AI Agent1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent1": {
      "main": [
        [
          {
            "node": "AI Agent2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent2",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent2": {
      "main": [
        []
      ]
    },
    "Google Gemini Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent3",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent3": {
      "main": [
        [
          {
            "node": "Edit Fields1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields1": {
      "main": [
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields3": {
      "main": [
        [
          {
            "node": "AI Agent3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Agent4": {
      "main": [
        [
          {
            "node": "Edit Fields2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields2": {
      "main": [
        [
          {
            "node": "Code1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields4": {
      "main": [
        [
          {
            "node": "AI Agent4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent4",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "pinData": {
    "Edit Fields": [
      {
        "json": {
          "query": "Ø¨Ø±Ø§ÛŒ Ú©Ø¯ Ø²ÛŒØ±ØŒ Ø§ÛŒÙ† ØªÙˆØµÛŒÙ‡ Ø±Ø§ Ø§Ø² ÛŒÚ© Ù…ØªØ®ØµØµ Ú¯Ø±ÙØªÙ…. Ø§Ø² Ø´Ù…Ø§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡Ù… Ú©Ø¯ Ù…Ù† Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ú©Ù†ÛŒØ¯. Ø§ÛŒÙ† ØªÙˆØµÛŒÙ‡ Ø§ÛŒÙ† Ø§Ø³Øª:Your Dynamic MVRV strategy based on the 7-day Market Value to Realized Value (MVRV) on 5-minute intervals shows thoroughness and consideration in its implementation. However, there are several critical aspects you need to address and potential improvements to enhance its robustness and effectiveness:\n\n---\n\n### âœ… STRENGTHS OF YOUR STRATEGY:\n1. **Clear Economic Intuition**:\n   - Using the 7-day MVRV as an oscillator-type signal, assuming reversals will occur when MVRV reaches color extremes (very positive or negative), is economically logical and backed by historical on-chain data analytics.\n\n2. **Dynamic Thresholds and Adjustments**:\n   - You smartly use adaptive, volatility-based thresholds to respond to changing market conditions. This should outperform static numerical thresholds over time by adapting to market regimes.\n\n3. **Multiple Confirmation Indicators**:\n   - You use a set of complementary indicators (Z-Score, RoC, Divergence, RSI), which can provide additional confluence and potentially filter out weaker signals.\n\n4. **Adaptive Position Sizing**:\n   - You gradually size positions based on confidence levels derived from multiple model components, which is highly advisable for risk management.\n\n---\n\n### âš ï¸ POTENTIAL STRATEGY FLAWS & PITFALLS:\n\n#### ðŸ”´ 1. LOOK-FORWARD BIAS:\n- **Potential Issue**:\n  Carefully check computations where you reference future values in rolling calculations. For instance, dynamic thresholds or regimes adjusted based on rolling averages or volatility could accidentally introduce look-ahead bias if you're not restricting your look-back windows carefully.  \n- **Suggested Action**:\n  Always explicitly confirm that all rolling/calculated indicators use only current or historical data (`shift()` if necessary).\n\n#### ðŸ”´ 2. DATA FREQUENCY & INDICATOR WINDOWS ISSUE:\n- **Potential Issue**:\n  You're using 365-period lookbacks for Z-score calculations, but your data frequency is 5-min intervals. Thus, a 365-interval lookback is just about one day (365 Ã— 5 minutes ~ approximately 30 hours).  \n  This contradicts the intended 365-day historical context, potentially invalidating your Z-score indicatorâ€”making it lose its original economic meaning.\n- **Suggested Action**:\n  Recalculate lookback options explicitly recognizing that `12 intervals/hour Ã— 24 hours/day Ã— 365 days = 105,120 intervals`.  \n  Consider reducing lookback in intraday scenarios or explicitly increasing it if your data permits. Otherwise, clearly document reasoning for shorter Z-score lookbacks.\n\n#### ðŸ”´ 3. POSITION EXIT LOGIC:\n- **Potential Issue**:\n  Your exit conditions appear complex and may overlap, potentially causing trades to prematurely close due to over-sensitivity. Particularly, divergences used alongside simple threshold-based exits could lead to excessive trade churn.\n- **Suggested Action**:\n  Consider simplifying exit logic. Prioritize simpler TP/SL initially and then carefully incorporate other conditions to avoid unintended premature exits.\n\n#### ðŸ”´ 4. RISK MANAGEMENT PRACTICES & DRAWDOWN MANAGEMENT:\n- **Potential Issue**:\n  Although adaptive position sizing is excellent, your code doesn't explicitly enforce a maximum acceptable drawdown (such as a hard stop on trading upon hitting 10% equity drawdown limit).\n- **Suggested Action**:\n  Introduce explicit equity-tracking logic in your `backtest_with_capital` function:\n  - Halt new trade entries explicitly if account drawdown from peak equity breaches 10%.\n  - Resume trading only after equity recovers to a certain level, or after manual reset.\n\n#### ðŸ”´ 5. PERFORMANCE METRICS & ANNUALIZATION (SCALING):\n- **Potential Issue**:\n  The Sharpe Ratio computed in `calculate_returns()` considers annualized factors (sqrt(252/trades)), which implicitly presumes daily frequency (252 trading days, typically equity market assumptions). For 5-min intraday returns, you need to use a correct scaling factor.\n- **Suggested Action**:\n  - Annualization factor: Since there are 288 (12 intervals/hour x 24 hours) intervals/day and approximately 365 days for crypto (24/7 market), consider annualizing using `sqrt(intervals per year)` based on your frequency.\n  Example: For 5-minute bars: `sqrt(105120)` intervals would scale the Sharpe correctly to yearly equivalent.\n\n#### ðŸ”´ 6. STOP-LOSS (SL) & TAKE-PROFIT (TP) LEVELS:\n- **Potential Issue**:\n  Dynamic TP/SL derived from MVRV-distances may not map consistently to price volatility or recent trading rangesâ€”potentially making stops too narrow (frequent premature stops) or too wide (excessive portfolio volatility).\n- **Suggested Action**:\n  Consider volatility-based SL/TP:\n  - Calculate historical price volatility (e.g., ATR - Average True Range over recent X intervals) for SL/TP rather than only relying on MVRV distance.\n  - Alternatively, combine volatility-adjustments with MVRV-derived factors to ensure that TP and SL make practical sense relative to current market moves.\n\n---\n\n### ðŸ› ï¸ CODE IMPROVEMENT RECOMMENDATIONS SUMMARY:\n- Clearly prevent look-forward bias by adjusting rolling calculations.\n- Use correct look-back windows aligned with your actual data frequency, especially for long-term indicators (`Z-score`).\n- Simplify or carefully stage position exit logics.\n- Explicitly enforce a hard 10% drawdown limit, halting new trades once breached.\n- Correct Sharpe/Sortino annualization for intraday data (use correct intervals/year).\n- Complement MVRV-based stops with volatility-based approaches.\n\n---\n\n### âœ… RECOMMENDED NEXT STEPS:\n1. Sanity check and verify each rolling calculation explicitly avoids look-forward bias.\n2. Clearly document assumptions about frequency versus indicator windows.\n3. Run short-term, simplified backtests comparing simpler exit strategies.\n4. Implement risk management (hard 10% drawdown) as stated.\n5. Adjust Sharpe/Sortino calculations for intraday frequency properly and re-run backtests.\n6. Integrate volatility-based TP/SL and re-compare performance metrics.\n\n---\n\nðŸ’• FINAL THOUGHTS:\nYour strategy shows great depth and understanding of quantitative trading and Bitcoin's nuances. To bring your implementation from good to great, these adjustmentsâ€”especially concerning look-forward biases, data frequency, and explicit risk managementâ€”are critical.\n\nÚ©Ø¯ Ù…Ù† Ø§ÛŒÙ†Ù‡:class DynamicMVRVStrategy:\\n    def __init__(self, df,\\n                 ma_period=30,\\n                 negative_quantile=0.25,\\n                 positive_quantile=0.75,\\n                 tp_factor=1.0,\\n                 sl_factor=0.5,\\n                 # Dynamic feature flags\\n                 use_dynamic_thresholds=False,\\n                 use_regime_adjustment=False,\\n                 use_mvrv_rsi=False,\\n                 use_adaptive_position=False,\\n                 use_dynamic_ma=False):\\n        \\n        self.df = df.copy()\\n        self.ma_period = ma_period\\n        self.negative_quantile = negative_quantile\\n        self.positive_quantile = positive_quantile\\n        self.tp_factor = tp_factor\\n        self.sl_factor = sl_factor\\n\\n        # Dynamic feature flags\\n        self.use_dynamic_thresholds = use_dynamic_thresholds\\n        self.use_regime_adjustment = use_regime_adjustment\\n        self.use_mvrv_rsi = use_mvrv_rsi\\n        self.use_adaptive_position = use_adaptive_position\\n        self.use_dynamic_ma = use_dynamic_ma\\n\\n        # Ensure we have the expected columns\\n        required_cols = ['Price', '7d_mvrv']\\n        if not all(col in self.df.columns for col in required_cols):\\n            raise ValueError(f'DataFrame must contain these columns: {required_cols}')\\n\\n        # Prepare the data\\n        self._prepare_data()\\n\\n    def _prepare_data(self):\\n        # Calculate base moving average of MVRV\\n        self.df['MVRV_MA'] = self.df['7d_mvrv'].rolling(window=self.ma_period).mean()\\n\\n        # Calculate MVRV volatility for dynamic thresholds and position sizing\\n        self.df['MVRV_Volatility'] = self.df['7d_mvrv'].rolling(window=self.ma_period).std()\\n\\n        # 1. MVRV Z-Score (needs long lookback window)\\n        lookback = min(365, len(self.df) // 3)  # Adapt to available data\\n        self.df['MVRV_Z_Score'] = (self.df['7d_mvrv'] - self.df['7d_mvrv'].rolling(lookback).mean()) / \\\\n                                (self.df['7d_mvrv'].rolling(lookback).std() + 1e-10)\\n        \\n        # 2. MVRV Rate of Change\\n        self.df['MVRV_ROC'] = self.df['7d_mvrv'].pct_change(7) * 100\\n        \\n        # 3. Price/MVRV Divergence\\n        norm_window = min(30, len(self.df) // 5)\\n        self.df['Price_Norm'] = self.df['Price'] / self.df['Price'].rolling(norm_window).mean() - 1\\n        self.df['MVRV_Norm'] = self.df['7d_mvrv'] / self.df['7d_mvrv'].rolling(norm_window).mean() - 1\\n        self.df['Price_MVRV_Divergence'] = self.df['Price_Norm'] - self.df['MVRV_Norm']\\n        \\n        # 4. MVRV Trend Strength\\n        self.df['MVRV_DM_Plus'] = np.where(self.df['7d_mvrv'].diff() > 0, self.df['7d_mvrv'].diff(), 0)\\n        self.df['MVRV_DM_Minus'] = np.where(self.df['7d_mvrv'].diff() < 0, -self.df['7d_mvrv'].diff(), 0)\\n        self.df['MVRV_Trend_Strength'] = (self.df['MVRV_DM_Plus'].rolling(14).mean() - \\\\n                                        self.df['MVRV_DM_Minus'].rolling(14).mean()).abs() / \\\\n                                        (self.df['MVRV_DM_Plus'].rolling(14).mean() + \\\\n                                        self.df['MVRV_DM_Minus'].rolling(14).mean() + 1e-10) * 100\\n\\n        # 1. DYNAMIC THRESHOLDS\\n        if self.use_dynamic_thresholds:\\n            self._calculate_dynamic_thresholds()\\n        else:\\n            self._calculate_static_thresholds()\\n\\n        # 2. REGIME DETECTION\\n        if self.use_regime_adjustment:\\n            self._detect_market_regime()\\n        else:\\n            self.df['Adjusted_TP_Factor'] = self.tp_factor\\n            self.df['Adjusted_SL_Factor'] = self.sl_factor\\n\\n        # 3. MVRV RSI\\n        if self.use_mvrv_rsi:\\n            self._calculate_mvrv_rsi()\\n\\n        # 4. ADAPTIVE POSITION is handled in generate_signals()\\n\\n        # 5. DYNAMIC MA PERIOD\\n        if self.use_dynamic_ma:\\n            self._calculate_adaptive_ma()\\n\\n    def _calculate_static_thresholds(self):\\n        # Split MVRV into positive and negative values\\n        positive_mvrv = self.df[self.df['7d_mvrv'] > 0]['7d_mvrv']\\n        negative_mvrv = self.df[self.df['7d_mvrv'] < 0]['7d_mvrv']\\n\\n        # Calculate thresholds based on quantiles\\n        if not positive_mvrv.empty:\\n            self.positive_threshold = positive_mvrv.quantile(self.positive_quantile)\\n        else:\\n            self.positive_threshold = 0.05  # Default if no positive values\\n\\n        if not negative_mvrv.empty:\\n            self.negative_threshold = negative_mvrv.quantile(self.negative_quantile)\\n        else:\\n            self.negative_threshold = -0.05  # Default if no negative values\\n\\n        # Add threshold columns for plotting\\n        self.df['Positive_Threshold'] = self.positive_threshold\\n        self.df['Negative_Threshold'] = self.negative_threshold\\n\\n    def _calculate_dynamic_thresholds(self):\\n        # Create dynamic threshold bands that adjust with volatility\\n        self.df['Positive_Threshold'] = self.df['MVRV_MA'] + (self.df['MVRV_Volatility'] * 2)\\n        self.df['Negative_Threshold'] = self.df['MVRV_MA'] - (self.df['MVRV_Volatility'] * 2)\\n\\n        # Store average values for reference (used in the non-dynamic parts of the code)\\n        self.positive_threshold = self.df['Positive_Threshold'].mean()\\n        self.negative_threshold = self.df['Negative_Threshold'].mean()\\n\\n    def _detect_market_regime(self):\\n        # Simple regime detection based on MVRV trend\\n        self.df['MVRV_Trend'] = np.where(\\n            self.df['MVRV_MA'] > self.df['MVRV_MA'].shift(self.ma_period),\\n            'uptrend', 'downtrend'\\n        )\\n\\n        # Adjust TP and SL factors based on regime\\n        self.df['Adjusted_TP_Factor'] = np.where(\\n            self.df['MVRV_Trend'] == 'uptrend',\\n            self.tp_factor * 1.5,  # More aggressive TP in uptrends\\n            self.tp_factor * 0.8   # More conservative TP in downtrends\\n        )\\n\\n        self.df['Adjusted_SL_Factor'] = np.where(\\n            self.df['MVRV_Trend'] == 'uptrend',\\n            self.sl_factor * 0.8,  # Tighter SL in uptrends\\n            self.sl_factor * 1.2   # Wider SL in downtrends\\n        )\\n\\n    def _calculate_mvrv_rsi(self, period=14):\\n        delta = self.df['7d_mvrv'].diff()\\n        gain = delta.where(delta > 0, 0)\\n        loss = -delta.where(delta < 0, 0)\\n\\n        avg_gain = gain.rolling(window=period).mean()\\n        avg_loss = loss.rolling(window=period).mean()\\n\\n        rs = avg_gain / avg_loss\\n        self.df['MVRV_RSI'] = 100 - (100 / (1 + rs))\\n\\n        # Use RSI to adjust thresholds further\\n        self.df['MVRV_Signal_Quality'] = np.where(\\n            (self.df['MVRV_RSI'] > 70) & (self.df['7d_mvrv'] > 0),  # Overbought MVRV\\n            'strong_sell',\\n            np.where(\\n                (self.df['MVRV_RSI'] < 30) & (self.df['7d_mvrv'] < 0),  # Oversold MVRV\\n                'strong_buy',\\n                'neutral'\\n            )\\n        )\\n\\n    def _calculate_adaptive_ma(self):\\n      # Calculate volatility percentile\\n      volatility = self.df['MVRV_Volatility']\\n      if not volatility.empty and not volatility.isna().all():\\n          # Fill NaN values before calculating percentiles\\n          filled_volatility = volatility.fillna(volatility.mean())\\n          vol_percentile = filled_volatility.rank(pct=True)\\n\\n          # Adjust MA period: shorter in high volatility, longer in low volatility\\n          min_period = 10\\n          max_period = 50\\n\\n          # Handle NaN values before converting to int\\n          period_float = min_period + ((max_period - min_period) * (1 - vol_percentile))\\n          self.df['Adaptive_MA_Period'] = period_float.fillna(self.ma_period).astype(int)\\n\\n          # Calculate adaptive MA (vectorized approach)\\n          self.df['MVRV_Adaptive_MA'] = np.nan\\n\\n          # This implementation handles each row individually\\n          for i in range(max_period, len(self.df)):\\n              if pd.notna(self.df['Adaptive_MA_Period'].iloc[i]):\\n                  period = self.df['Adaptive_MA_Period'].iloc[i]\\n                  self.df.loc[self.df.index[i], 'MVRV_Adaptive_MA'] = self.df['7d_mvrv'].iloc[i-period:i].mean()\\n      else:\\n          # Fallback to standard MA if we can't calculate volatility\\n          self.df['MVRV_Adaptive_MA'] = self.df['MVRV_MA']\\n          self.df['Adaptive_MA_Period'] = self.ma_period\\n\\n    def generate_signals(self):\\n      # Initialize signal columns\\n      self.df['Signal'] = 0  # 1 for buy, -1 for sell\\n      self.df['Position'] = 0\\n      self.df['Position_Size'] = 0.0\\n      self.df['Entry_Price'] = np.nan\\n      self.df['TP_Level'] = np.nan\\n      self.df['SL_Level'] = np.nan\\n      self.df['Trade_Result'] = np.nan\\n      self.df['Trade_Return'] = np.nan\\n      \\n      # Skip the first rows due to NaN values in indicators\\n      # Account for new indicators (Z-score uses up to 365 days)\\n      start_idx = max(self.ma_period, 14, 30, 365)  # RSI, divergence, Z-score\\n      if self.use_dynamic_ma:\\n          start_idx = max(start_idx, 50)  # Account for max adaptive MA period\\n      \\n      # Ensure start_idx is within dataframe bounds\\n      start_idx = min(start_idx, len(self.df) // 2)\\n      \\n      # Variables to track positions\\n      in_position = False\\n      entry_price = 0\\n      entry_mvrv = 0\\n      trade_type = None  # 'long' or 'short'\\n      tp_level = 0\\n      sl_level = 0\\n      position_size = 1.0  # Default full position size\\n      \\n      # Choose which MA to use\\n      ma_col = 'MVRV_Adaptive_MA' if self.use_dynamic_ma else 'MVRV_MA'\\n      \\n      # Iterate through the data to generate signals\\n      for i in range(start_idx, len(self.df) - 1):\\n          curr_price = self.df['Price'].iloc[i]\\n          curr_mvrv = self.df['7d_mvrv'].iloc[i]\\n          curr_ma = self.df[ma_col].iloc[i] if pd.notna(self.df[ma_col].iloc[i]) else self.df['MVRV_MA'].iloc[i]\\n          prev_mvrv = self.df['7d_mvrv'].iloc[i-1]\\n          prev_ma = self.df[ma_col].iloc[i-1] if pd.notna(self.df[ma_col].iloc[i-1]) else self.df['MVRV_MA'].iloc[i-1]\\n          \\n          # Get dynamic thresholds for current row if enabled\\n          pos_threshold = self.df['Positive_Threshold'].iloc[i]\\n          neg_threshold = self.df['Negative_Threshold'].iloc[i]\\n          \\n          # Get adjusted TP/SL factors if regime-based adjustment is enabled\\n          tp_factor = self.df['Adjusted_TP_Factor'].iloc[i] if self.use_regime_adjustment else self.tp_factor\\n          sl_factor = self.df['Adjusted_SL_Factor'].iloc[i] if self.use_regime_adjustment else self.sl_factor\\n          \\n          # Get values from new indicators\\n          z_score = self.df['MVRV_Z_Score'].iloc[i] if 'MVRV_Z_Score' in self.df.columns else 0\\n          mvrv_roc = self.df['MVRV_ROC'].iloc[i] if 'MVRV_ROC' in self.df.columns else 0\\n          \\n          # Check for extreme values and trend strength\\n          extreme_bullish = z_score < -1.0 if 'MVRV_Z_Score' in self.df.columns else False\\n          extreme_bearish = z_score > 1.0 if 'MVRV_Z_Score' in self.df.columns else False\\n          \\n          # Check for divergence\\n          bullish_divergence = False\\n          bearish_divergence = False\\n          if 'Price_MVRV_Divergence' in self.df.columns:\\n              # Bullish when price rises but MVRV doesn't rise as much\\n              lookback = 5\\n              if i >= lookback:\\n                  price_trend = self.df['Price'].iloc[i] - self.df['Price'].iloc[i-lookback]\\n                  mvrv_trend = self.df['7d_mvrv'].iloc[i] - self.df['7d_mvrv'].iloc[i-lookback]\\n                  div_value = self.df['Price_MVRV_Divergence'].iloc[i]\\n                  \\n                  bullish_divergence = div_value < -0.05 and price_trend > 0\\n                  bearish_divergence = div_value > 0.05 and price_trend < 0\\n          \\n          # Check for strong trend\\n          strong_trend = False\\n          if 'MVRV_Trend_Strength' in self.df.columns:\\n              strong_trend = self.df['MVRV_Trend_Strength'].iloc[i] > 25\\n          \\n          # Check if we're in a position\\n          if in_position:\\n              self.df['Position'].iloc[i] = 1 if trade_type == 'long' else -1\\n              self.df['Position_Size'].iloc[i] = position_size\\n              self.df['Entry_Price'].iloc[i] = entry_price\\n              self.df['TP_Level'].iloc[i] = tp_level\\n              self.df['SL_Level'].iloc[i] = sl_level\\n              \\n              # Check if take profit or stop loss hit\\n              if trade_type == 'long':\\n                  # For long positions\\n                  if curr_price >= tp_level:  # Take profit hit\\n                      self.df['Signal'].iloc[i] = -1  # Exit signal\\n                      self.df['Trade_Result'].iloc[i] = 'TP'\\n                      self.df['Trade_Return'].iloc[i] = (curr_price - entry_price) / entry_price * 100 * position_size\\n                      in_position = False\\n                  elif curr_price <= sl_level:  # Stop loss hit\\n                      self.df['Signal'].iloc[i] = -1  # Exit signal\\n                      self.df['Trade_Result'].iloc[i] = 'SL'\\n                      self.df['Trade_Return'].iloc[i] = (curr_price - entry_price) / entry_price * 100 * position_size\\n                      in_position = False\\n                  # Additional exit conditions with new indicators\\n                  elif curr_mvrv > pos_threshold and curr_mvrv < curr_ma and prev_mvrv > prev_ma:\\n                      # Original exit condition\\n                      self.df['Signal'].iloc[i] = -1  # Exit signal based on strategy\\n                      self.df['Trade_Result'].iloc[i] = 'Strategy'\\n                      self.df['Trade_Return'].iloc[i] = (curr_price - entry_price) / entry_price * 100 * position_size\\n                      in_position = False\\n                  # New exit condition: Z-score becomes extremely positive\\n                  elif extreme_bearish and mvrv_roc > 5:\\n                      self.df['Signal'].iloc[i] = -1  # Exit signal based on extreme Z-score\\n                      self.df['Trade_Result'].iloc[i] = 'Z-Score'\\n                      self.df['Trade_Return'].iloc[i] = (curr_price - entry_price) / entry_price * 100 * position_size\\n                      in_position = False\\n                  # New exit condition: Bearish divergence forms after being in profit\\n                  elif bearish_divergence and curr_price > entry_price * 1.05:\\n                      self.df['Signal'].iloc[i] = -1  # Exit signal based on divergence\\n                      self.df['Trade_Result'].iloc[i] = 'Divergence'\\n                      self.df['Trade_Return'].iloc[i] = (curr_price - entry_price) / entry_price * 100 * position_size\\n                      in_position = False\\n              else:\\n                  # For short positions\\n                  if curr_price <= tp_level:  # Take profit hit\\n                      self.df['Signal'].iloc[i] = 1  # Exit short signal\\n                      self.df['Trade_Result'].iloc[i] = 'TP'\\n                      self.df['Trade_Return'].iloc[i] = (entry_price - curr_price) / entry_price * 100 * position_size\\n                      in_position = False\\n                  elif curr_price >= sl_level:  # Stop loss hit\\n                      self.df['Signal'].iloc[i] = 1  # Exit short signal\\n                      self.df['Trade_Result'].iloc[i] = 'SL'\\n                      self.df['Trade_Return'].iloc[i] = (entry_price - curr_price) / entry_price * 100 * position_size\\n                      in_position = False\\n                  # Additional exit conditions with new indicators\\n                  elif curr_mvrv < neg_threshold and curr_mvrv > curr_ma and prev_mvrv < prev_ma:\\n                      # Original exit condition\\n                      self.df['Signal'].iloc[i] = 1  # Exit short signal based on strategy\\n                      self.df['Trade_Result'].iloc[i] = 'Strategy'\\n                      self.df['Trade_Return'].iloc[i] = (entry_price - curr_price) / entry_price * 100 * position_size\\n                      in_position = False\\n                  # New exit condition: Z-score becomes extremely negative\\n                  elif extreme_bullish and mvrv_roc < -5:\\n                      self.df['Signal'].iloc[i] = 1  # Exit short signal based on extreme Z-score\\n                      self.df['Trade_Result'].iloc[i] = 'Z-Score'\\n                      self.df['Trade_Return'].iloc[i] = (entry_price - curr_price) / entry_price * 100 * position_size\\n                      in_position = False\\n                  # New exit condition: Bullish divergence forms after being in profit\\n                  elif bullish_divergence and curr_price < entry_price * 0.95:\\n                      self.df['Signal'].iloc[i] = 1  # Exit short signal based on divergence\\n                      self.df['Trade_Result'].iloc[i] = 'Divergence'\\n                      self.df['Trade_Return'].iloc[i] = (entry_price - curr_price) / entry_price * 100 * position_size\\n                      in_position = False\\n          else:\\n              # Not in position, look for new signals\\n              \\n              # Buy signal: MVRV below negative threshold and crosses back above MA\\n              # If RSI is enabled, check for additional confirmation\\n              rsi_buy_confirm = True\\n              if self.use_mvrv_rsi:\\n                  rsi_buy_confirm = self.df['MVRV_RSI'].iloc[i] < 40  # More conservative threshold\\n              \\n              # Enhanced buy conditions with new indicators\\n              buy_condition = (\\n                  curr_mvrv < neg_threshold and \\\\n                  curr_mvrv > curr_ma and \\\\n                  prev_mvrv < prev_ma and \\\\n                  rsi_buy_confirm\\n              )\\n              \\n              # Add Z-score confirmation if available\\n              if 'MVRV_Z_Score' in self.df.columns:\\n                  # Change from requiring Z-score confirmation to just making it a boost\\n                  # Original: buy_condition = buy_condition and (z_score < 0)\\n                  # This made Z-score a requirement, potentially filtering good trades\\n                  z_score_favorable = z_score < 0.5  # More permissive threshold\\n                  # Use as a boosting factor for position sizing instead of a hard filter\\n                  z_score_boost = 1.0 if z_score_favorable else 0.8\\n              \\n              # Add trend strength confirmation if available\\n              if 'MVRV_Trend_Strength' in self.df.columns:\\n                  buy_condition = buy_condition and (strong_trend or extreme_bullish)\\n              \\n              # Add divergence confirmation if available\\n              if 'Price_MVRV_Divergence' in self.df.columns:\\n                  # Either bullish divergence or extreme condition\\n                  buy_condition = buy_condition and (bullish_divergence or extreme_bullish)\\n              \\n              if buy_condition:\\n                  # Calculate enhanced position size\\n                  if self.use_adaptive_position:\\n                      # Base conviction on multiple factors\\n                      mvrv_distance = abs(curr_mvrv)\\n                      mvrv_vol = max(0.01, self.df['MVRV_Volatility'].iloc[i])\\n                      \\n                      # Add Z-score to conviction calculation\\n                      z_conviction = min(abs(z_score) / 3.0, 0.5) if 'MVRV_Z_Score' in self.df.columns else 0\\n                      \\n                      # Add divergence to conviction calculation\\n                      div_conviction = 0.5 if bullish_divergence else 0\\n                      \\n                      # Combine all factors\\n                      base_conviction = min(mvrv_distance / mvrv_vol, 3.0)\\n                      # Original gave equal weight, now base gets 70%, Z-score 20%, divergence 10%\\n                      total_conviction = (0.7 * base_conviction + 0.2 * z_conviction + 0.1 * div_conviction) / 1.0\\n                      position_size = 0.2 + (0.8 * total_conviction)  # Scale from 20% to 100%\\n                  else:\\n                      position_size = 1.0\\n                  \\n                  self.df['Signal'].iloc[i] = 1  # Buy signal\\n                  in_position = True\\n                  trade_type = 'long'\\n                  entry_price = curr_price\\n                  entry_mvrv = curr_mvrv\\n                  \\n                  # Set dynamic TP and SL based on MVRV distance and adjusted factors\\n                  mvrv_distance = abs(entry_mvrv)\\n                  \\n                  # Adjust TP based on Z-score extremity\\n                  z_adjustment = 1.0\\n                  if 'MVRV_Z_Score' in self.df.columns:\\n                    # Original: z_adjustment = 1.0 + (abs(z_score) / 5.0)\\n                    # New: Less impact, capped lower\\n                    z_adjustment = 1.0 + min(abs(z_score) / 10.0, 0.2)\\n                  \\n                  price_change_pct = mvrv_distance * tp_factor * z_adjustment\\n                  tp_level = entry_price * (1 + price_change_pct/100)  # TP level\\n                  sl_level = entry_price * (1 - (mvrv_distance * sl_factor)/100)  # SL level\\n                  \\n                  self.df['Entry_Price'].iloc[i] = entry_price\\n                  self.df['TP_Level'].iloc[i] = tp_level\\n                  self.df['SL_Level'].iloc[i] = sl_level\\n                  self.df['Position'].iloc[i] = 1\\n                  self.df['Position_Size'].iloc[i] = position_size\\n              \\n              # Sell signal: MVRV above positive threshold and crosses back below MA\\n              # If RSI is enabled, check for additional confirmation\\n              rsi_sell_confirm = True\\n              if self.use_mvrv_rsi:\\n                  rsi_sell_confirm = self.df['MVRV_RSI'].iloc[i] > 60  # More conservative threshold\\n              \\n              # Enhanced sell conditions with new indicators - FIX: changed 'elif' to 'if'\\n              sell_condition = (\\n                  curr_mvrv > pos_threshold and \\\\n                  curr_mvrv < curr_ma and \\\\n                  prev_mvrv > prev_ma and \\\\n                  rsi_sell_confirm\\n              )\\n              \\n              # Add Z-score confirmation if available\\n              if 'MVRV_Z_Score' in self.df.columns:\\n                  # Change from hard requirement to boost\\n                  z_score_favorable = z_score > -0.5\\n                  z_score_boost = 1.0 if z_score_favorable else 0.8\\n              \\n              # Add trend strength confirmation if available\\n              if 'MVRV_Trend_Strength' in self.df.columns:\\n                  sell_condition = sell_condition and (strong_trend or extreme_bearish)\\n              \\n              # Add divergence confirmation if available\\n              if 'Price_MVRV_Divergence' in self.df.columns:\\n                  # Change this line:\\n                  # buy_condition = buy_condition and (bullish_divergence or extreme_bullish)\\n                  # To make it a soft factor instead of a hard requirement:\\n                  divergence_factor = 1.2 if (bullish_divergence or extreme_bullish) else 1.0\\n                  # Apply this factor to position sizing or TP level rather than filtering trades\\n              \\n              if sell_condition:  # Changed from 'elif' to 'if' to fix the bug\\n                  # Calculate enhanced position size\\n                  if self.use_adaptive_position:\\n                      # Base conviction on multiple factors\\n                      mvrv_distance = abs(curr_mvrv)\\n                      mvrv_vol = max(0.01, self.df['MVRV_Volatility'].iloc[i])\\n                      \\n                      # Add Z-score to conviction calculation\\n                      z_conviction = min(abs(z_score) / 2, 1.0) if 'MVRV_Z_Score' in self.df.columns else 0\\n                      \\n                      # Add divergence to conviction calculation\\n                      div_conviction = 0.5 if bearish_divergence else 0\\n                      \\n                      # Combine all factors\\n                      base_conviction = min(mvrv_distance / mvrv_vol, 3.0)\\n                      total_conviction = (base_conviction + z_conviction + div_conviction) / 5.0\\n                      position_size = 0.2 + (0.8 * total_conviction)  # Scale from 20% to 100%\\n                  else:\\n                      position_size = 1.0\\n                  \\n                  self.df['Signal'].iloc[i] = -1  # Sell signal (for short)\\n                  in_position = True\\n                  trade_type = 'short'\\n                  entry_price = curr_price\\n                  entry_mvrv = curr_mvrv\\n                  \\n                  # Set dynamic TP and SL based on MVRV distance and adjusted factors\\n                  mvrv_distance = abs(entry_mvrv)\\n                  \\n                  # Adjust TP based on Z-score extremity\\n                  z_adjustment = 1.0\\n                  if 'MVRV_Z_Score' in self.df.columns:\\n                      z_adjustment = 1.0 + (abs(z_score) / 5.0)  # More extreme = higher target\\n                  \\n                  price_change_pct = mvrv_distance * tp_factor * z_adjustment\\n                  tp_level = entry_price * (1 - price_change_pct/100)  # TP level for short\\n                  sl_level = entry_price * (1 + (mvrv_distance * sl_factor)/100)  # SL level for short\\n                  \\n                  self.df['Entry_Price'].iloc[i] = entry_price\\n                  self.df['TP_Level'].iloc[i] = tp_level\\n                  self.df['SL_Level'].iloc[i] = sl_level\\n                  self.df['Position'].iloc[i] = -1\\n                  self.df['Position_Size'].iloc[i] = position_size\\n      \\n      return self.df\\n\\n    def calculate_returns(self):\\n        signals_df = self.df.copy()\\n        signals_df['Strategy_Return'] = 0.0\\n\\n        # Filter out rows with actual trade returns\\n        trade_returns = signals_df[signals_df['Trade_Return'].notna()]['Trade_Return']\\n\\n        if not trade_returns.empty:\\n            valid_returns = trade_returns.dropna()\\n\\n            if len(valid_returns) > 0:\\n                # Calculate cumulative returns properly\\n                signals_df.loc[valid_returns.index, 'Cumulative_Return'] = (1 + valid_returns / 100).cumprod() - 1\\n\\n                # Forward fill the cumulative return\\n                signals_df['Cumulative_Return'] = signals_df['Cumulative_Return'].ffill()\\n\\n                # Calculate performance metrics\\n                last_return = signals_df['Cumulative_Return'].dropna().iloc[-1] if not signals_df['Cumulative_Return'].dropna().empty else 0\\n                win_trades = signals_df[signals_df['Trade_Return'] > 0]['Trade_Return'].count()\\n                loss_trades = signals_df[signals_df['Trade_Return'] < 0]['Trade_Return'].count()\\n                total_trades = win_trades + loss_trades\\n                win_rate = win_trades / total_trades if total_trades > 0 else 0\\n\\n                # Calculate average win/loss\\n                avg_win = signals_df[signals_df['Trade_Return'] > 0]['Trade_Return'].mean() if win_trades > 0 else 0\\n                avg_loss = signals_df[signals_df['Trade_Return'] < 0]['Trade_Return'].mean() if loss_trades > 0 else 0\\n\\n                # Calculate Sharpe ratio (simplified)\\n                if total_trades > 0:\\n                    returns_series = signals_df[signals_df['Trade_Return'].notna()]['Trade_Return']\\n                    sharpe = returns_series.mean() / (returns_series.std() + 1e-10) * np.sqrt(252 / total_trades)\\n                else:\\n                    sharpe = 0\\n\\n                # Store metrics\\n                self.performance = {\\n                    'Total Return': f\"{last_return*100:.2f}%\",\\n                    'Win Rate': f\"{win_rate*100:.2f}%\",\\n                    'Total Trades': total_trades,\\n                    'Win Trades': win_trades,\\n                    'Loss Trades': loss_trades,\\n                    'Average Win': f\"{avg_win:.2f}%\",\\n                    'Average Loss': f\"{avg_loss:.2f}%\",\\n                    'Sharpe Ratio': f\"{sharpe:.2f}\",\\n                    'Dynamic Features': self._get_active_features()\\n                }\\n            else:\\n                self._set_default_performance()\\n        else:\\n            self._set_default_performance()\\n\\n        return signals_df, self.performance\\n\\n    def _set_default_performance(self):\\n        self.performance = {\\n            'Total Return': \"0.00%\",\\n            'Win Rate': \"0.00%\",\\n            'Total Trades': 0,\\n            'Win Trades': 0,\\n            'Loss Trades': 0,\\n            'Average Win': \"0.00%\",\\n            'Average Loss': \"0.00%\",\\n            'Sharpe Ratio': \"0.00\",\\n            'Dynamic Features': self._get_active_features()\\n        }\\n\\n    def _get_active_features(self):\\n        features = []\\n        if self.use_dynamic_thresholds:\\n            features.append(\"Dynamic Thresholds\")\\n        if self.use_regime_adjustment:\\n            features.append(\"Regime Adjustment\")\\n        if self.use_mvrv_rsi:\\n            features.append(\"MVRV RSI\")\\n        if self.use_adaptive_position:\\n            features.append(\"Adaptive Position\")\\n        if self.use_dynamic_ma:\\n            features.append(\"Dynamic MA\")\\n\\n        if not features:\\n            return \"None (Static Strategy)\"\\n        return \", \".join(features)\\n    def backtest_with_capital(self, initial_capital=1000):\\n      # Generate signals if not already done\\n      if 'Signal' not in self.df.columns:\\n          self.generate_signals()\\n      \\n      # Get signals data\\n      signals_df = self.df.copy()\\n      \\n      # Initialize equity tracking as float64 to avoid dtype warning\\n      signals_df['Capital'] = float(initial_capital)\\n      signals_df['Equity'] = float(initial_capital)\\n      signals_df['Trade_Profit_Loss'] = np.nan\\n      \\n      # Track high water mark for drawdown calculation\\n      high_water_mark = initial_capital\\n      max_drawdown_pct = 0\\n      \\n      # Find rows with trades\\n      trade_rows = signals_df[signals_df['Trade_Return'].notna()]\\n      \\n      # Simulate equity curve\\n      current_capital = initial_capital\\n      for idx, row in trade_rows.iterrows():\\n          # Calculate trade profit/loss in dollars\\n          position_size = row['Position_Size'] if pd.notna(row['Position_Size']) else 1.0\\n          dollar_amount = current_capital * position_size\\n          profit_pct = row['Trade_Return'] / 100  # Convert percentage to decimal\\n          profit_dollars = dollar_amount * profit_pct\\n          \\n          # Update capital\\n          current_capital += profit_dollars\\n          \\n          # Record trade results\\n          signals_df.at[idx, 'Trade_Profit_Loss'] = profit_dollars\\n          signals_df.at[idx, 'Equity'] = current_capital\\n          \\n          # Update high water mark and drawdown\\n          if current_capital > high_water_mark:\\n              high_water_mark = current_capital\\n          \\n          drawdown_pct = (high_water_mark - current_capital) / high_water_mark * 100\\n          max_drawdown_pct = max(max_drawdown_pct, drawdown_pct)\\n      \\n      # Forward fill equity values (using newer pandas syntax)\\n      signals_df['Equity'] = signals_df['Equity'].ffill().fillna(initial_capital)\\n      \\n      # Calculate final metrics\\n      final_equity = signals_df['Equity'].iloc[-1]\\n      total_return_dollars = final_equity - initial_capital\\n      total_return_pct = (final_equity / initial_capital - 1) * 100\\n      \\n      # Calculate annualized return if date index is available\\n      annualized_return = None\\n      if isinstance(signals_df.index, pd.DatetimeIndex):\\n          days = (signals_df.index[-1] - signals_df.index[0]).days\\n          years = days / 365\\n          if years > 0:\\n              annualized_return = ((1 + total_return_pct/100) ** (1/years) - 1) * 100\\n      \\n      # Trade statistics\\n      num_trades = len(trade_rows)\\n      profitable_trades = len(trade_rows[trade_rows['Trade_Return'] > 0])\\n      win_rate = profitable_trades / num_trades if num_trades > 0 else 0\\n      \\n      # Calculate average profit/loss per trade\\n      avg_profit = trade_rows[trade_rows['Trade_Return'] > 0]['Trade_Return'].mean() if profitable_trades > 0 else 0\\n      avg_loss = trade_rows[trade_rows['Trade_Return'] < 0]['Trade_Return'].mean() if (num_trades - profitable_trades) > 0 else 0\\n      \\n      # Store results\\n      results = {\\n          'initial_capital': initial_capital,\\n          'final_equity': final_equity,\\n          'total_return_dollars': total_return_dollars,\\n          'total_return_pct': total_return_pct,\\n          'num_trades': num_trades,\\n          'win_rate': win_rate,\\n          'max_drawdown_pct': max_drawdown_pct,\\n          'avg_profit': avg_profit,\\n          'avg_loss': avg_loss\\n      }\\n      \\n      if annualized_return is not None:\\n          results['annualized_return'] = annualized_return\\n      \\n      # Print results\\n      print(\"\\n=== STRATEGY BACKTEST RESULTS ===\")\\n      print(f\"Starting with ${initial_capital:.2f}\")\\n      print(f\"Final Equity: ${final_equity:.2f}\")\\n      print(f\"Total Return: ${total_return_dollars:.2f} ({total_return_pct:.2f}%)\")\\n      print(f\"Number of Trades: {num_trades}\")\\n      print(f\"Win Rate: {win_rate*100:.2f}%\")\\n      print(f\"Max Drawdown: {max_drawdown_pct:.2f}%\")\\n      print(f\"Average Profit: {avg_profit:.2f}%\")\\n      print(f\"Average Loss: {avg_loss:.2f}%\")\\n      if annualized_return is not None:\\n          print(f\"Annualized Return: {annualized_return:.2f}%\")\\n      \\n      return signals_df, results\\n\\n    def plot_equity_curve(self, initial_capital=1000):\\n      # Run backtest\\n      equity_df, results = self.backtest_with_capital(initial_capital)\\n      \\n      # Create figure\\n      fig, ax = plt.subplots(figsize=(14, 8))\\n      \\n      # Plot equity curve\\n      ax.plot(equity_df.index, equity_df['Equity'], label='Portfolio Value', linewidth=2)\\n      \\n      # Add trade markers\\n      trades = equity_df[equity_df['Trade_Profit_Loss'].notna()]\\n      profits = trades[trades['Trade_Profit_Loss'] > 0]\\n      losses = trades[trades['Trade_Profit_Loss'] < 0]\\n      \\n      ax.scatter(profits.index, profits['Equity'], marker='^', color='green', s=100, \\\\n                label='Profitable Trade')\\n      ax.scatter(losses.index, losses['Equity'], marker='v', color='red', s=100, \\\\n                label='Losing Trade')\\n      \\n      # Add initial capital reference line\\n      ax.axhline(y=initial_capital, color='gray', linestyle='--', alpha=0.7, \\\\n                label=f'Initial Capital ({initial_capital})')\\n      \\n      # Style the plot - Avoiding any dollar signs in title\\n      ax.set_title(f'Strategy Equity Curve Starting with {initial_capital} Initial Capital\\\\n' + \\\\n                  f\"Final Equity: {results['final_equity']:.2f} \" + \\\\n                  f\"(Return: {results['total_return_pct']:.2f}%, \" + \\\\n                  f\"Drawdown: {results['max_drawdown_pct']:.2f}%)\")\\n      \\n      ax.set_ylabel('Portfolio Value')\\n      ax.set_xlabel('Date')\\n      ax.grid(True, alpha=0.3)\\n      ax.legend()\\n      \\n      # Add summary info as text box without dollar signs\\n      props = dict(boxstyle='round', facecolor='white', alpha=0.7)\\n      text_data = [\\n          f\"Initial Capital: {results['initial_capital']:.2f}\",\\n          f\"Final Equity: {results['final_equity']:.2f}\",\\n          f\"Total Return: {results['total_return_dollars']:.2f} ({results['total_return_pct']:.2f}%)\",\\n          f\"Number of Trades: {results['num_trades']}\",\\n          f\"Win Rate: {results['win_rate']*100:.2f}%\",\\n          f\"Max Drawdown: {results['max_drawdown_pct']:.2f}%\",\\n          f\"Average Profit: {results['avg_profit']:.2f}%\",\\n          f\"Average Loss: {results['avg_loss']:.2f}%\"\\n      ]\\n      \\n      if 'annualized_return' in results:\\n          text_data.append(f\"Annualized Return: {results['annualized_return']:.2f}%\")\\n      \\n      summary = '\\\\n'.join(text_data)\\n      ax.text(0.02, 0.97, summary, transform=ax.transAxes, fontsize=10,\\\\n              verticalalignment='top', bbox=props)\\n      \\n      plt.tight_layout()\\n      plt.show()\\n      \\n      return fig\\n\\n    def plot_strategy(self):\\n        signals_df, performance = self.calculate_returns()\\n\\n        # Create a figure with subplots\\n        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(16, 18), gridspec_kw={'height_ratios': [2, 1, 1]})\\n\\n        # Plot price chart\\n        ax1.plot(signals_df.index, signals_df['Price'], label='Price', color='black', alpha=0.7)\\n        ax1.set_title(f'Dynamic MVRV Strategy: Price with Signals\\\\nActive features: {self._get_active_features()}')\\n        ax1.set_ylabel('Price')\\n        ax1.grid(True, alpha=0.3)\\n\\n        # Plot buy signals\\n        buy_signals = signals_df[signals_df['Signal'] == 1]\\n        ax1.scatter(buy_signals.index, buy_signals['Price'], marker='^', color='green', s=100, label='Buy Signal')\\n\\n        # Plot sell signals\\n        sell_signals = signals_df[signals_df['Signal'] == -1]\\n        ax1.scatter(sell_signals.index, sell_signals['Price'], marker='v', color='red', s=100, label='Sell Signal')\\n\\n        # Plot take profit and stop loss levels where applicable\\n        entry_points = signals_df[(signals_df['Entry_Price'].notna()) & (signals_df['Signal'] != 0)]\\n        for idx, row in entry_points.iterrows():\\n            if pd.notna(row['TP_Level']) and pd.notna(row['SL_Level']):\\n                if row['Position'] == 1:  # Long position\\n                    ax1.axhline(y=row['TP_Level'], color='green', linestyle='--', alpha=0.5,\\\\n                               xmin=mdates.date2num(idx)/mdates.date2num(signals_df.index[-1]))\\n                    ax1.axhline(y=row['SL_Level'], color='red', linestyle='--', alpha=0.5,\\\\n                               xmin=mdates.date2num(idx)/mdates.date2num(signals_df.index[-1]))\\n                elif row['Position'] == -1:  # Short position\\n                    ax1.axhline(y=row['TP_Level'], color='green', linestyle='--', alpha=0.5,\\\\n                               xmin=mdates.date2num(idx)/mdates.date2num(signals_df.index[-1]))\\n                    ax1.axhline(y=row['SL_Level'], color='red', linestyle='--', alpha=0.5,\\\\n                               xmin=mdates.date2num(idx)/mdates.date2num(signals_df.index[-1]))\\n\\n        # Plot MVRV chart\\n        ax2.plot(signals_df.index, signals_df['7d_mvrv'], label='7D MVRV', color='blue')\\n\\n        # Choose which MA to plot\\n        ma_col = 'MVRV_Adaptive_MA' if self.use_dynamic_ma else 'MVRV_MA'\\n        ma_label = 'Adaptive MA' if self.use_dynamic_ma else f'{self.ma_period}-period MA'\\n        ax2.plot(signals_df.index, signals_df[ma_col], label=ma_label, color='orange')\\n\\n        # Plot thresholds\\n        ax2.plot(signals_df.index, signals_df['Positive_Threshold'], color='red',\\\\n                linestyle='-', alpha=0.7,\\\\n                label='Dynamic Positive Threshold' if self.use_dynamic_thresholds else f'Positive Threshold ({self.positive_quantile} quantile)')\\n\\n        ax2.plot(signals_df.index, signals_df['Negative_Threshold'], color='green',\\\\n                linestyle='-', alpha=0.7,\\\\n                label='Dynamic Negative Threshold' if self.use_dynamic_thresholds else f'Negative Threshold ({self.negative_quantile} quantile)')\\n\\n        ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\\n        ax2.set_title('MVRV and Moving Average')\\n        ax2.set_ylabel('MVRV Value')\\n        ax2.grid(True, alpha=0.3)\\n        ax2.legend()\\n\\n        # Plot additional indicators if enabled\\n        if self.use_mvrv_rsi:\\n            ax4 = ax2.twinx()\\n            ax4.plot(signals_df.index, signals_df['MVRV_RSI'], color='purple', alpha=0.5, label='MVRV RSI')\\n            ax4.set_ylabel('RSI', color='purple')\\n            ax4.tick_params(axis='y', labelcolor='purple')\\n            ax4.set_ylim(0, 100)\\n            ax4.axhline(y=70, color='red', linestyle='--', alpha=0.3)\\n            ax4.axhline(y=30, color='green', linestyle='--', alpha=0.3)\\n            ax4.legend(loc='upper right')\\n\\n        # Plot cumulative returns if available\\n        if 'Cumulative_Return' in signals_df.columns and not signals_df['Cumulative_Return'].empty:\\n            ax3.plot(signals_df.index, signals_df['Cumulative_Return'] * 100, label='Cumulative Return (%)', color='purple')\\n            ax3.set_title('Strategy Cumulative Returns (%)')\\n            ax3.set_ylabel('Return (%)')\\n            ax3.grid(True, alpha=0.3)\\n\\n            # Add a horizontal line at y=0\\n            ax3.axhline(y=0, color='black', linestyle='-', alpha=0.3)\\n\\n            # Add performance statistics as text\\n            stats_text = '\\\\n'.join([f\"{k}: {v}\" for k, v in performance.items()])\\n            ax3.text(0.02, 0.95, stats_text, transform=ax3.transAxes,\\\\n                    fontsize=12, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\\n        else:\\n            ax3.text(0.5, 0.5, 'No trades completed to calculate returns',\\\\n                    horizontalalignment='center', verticalalignment='center', transform=ax3.transAxes)\\n\\n        # Format x-axis for all subplots\\n        for ax in [ax1, ax2, ax3]:\\n            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\\n            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\\n\\n        ax1.legend()\\n        plt.tight_layout()\\n        plt.show()\\n\\n        return fig"
        }
      }
    ],
    "Edit Fields1": [
      {
        "json": {
          "output": "Okay, StrategyIntegrator is initiating the end-to-end verification process.\n\n**Ingesting Inputs:**\n\n1.  **QuantAI Design Doc (Implicit):** Requirements derived from the user prompt describing QuantAI's recommended improvements: fix look-forward bias, correct Z-score window (365 days / 105,120 5-min intervals), simplify exits, add 10% drawdown halt, correct Sharpe annualization (sqrt(105,120)), add ATR SL/TP, improve position sizing. Includes flags for dynamic features.\n2.  **PyStrategist Python Code:** Received the `dynamic_mvrv_strategy.py` script containing configuration, data loading, indicator calculations, signal generation, risk management (including drawdown logic, SL/TP calculation), backtesting engine, metrics, and plotting, structured into functions.\n3.  **StrategyAuditor Audit Report:** Received report highlighting key issues, with Top 3 being: Look-ahead bias in ATR, Extreme risk in default position sizing (100%), Drawdown halt logic timing flaw.\n\n**Performing Core Responsibilities:**\n\n1.  **Alignment Check:** Verifying design requirements against PyStrategist code.\n2.  **Audit Resolution:** Checking if PyStrategist code addresses StrategyAuditor's high-severity findings.\n3.  **Consistency Validation:** Checking names, parameters across code and config.\n4.  **End-to-End Test Verification:** Assessing test presence and coverage (based on PyStrategist notes).\n5.  **Production Readiness:** Checking PEP8 (visually), docstrings/hints, performance notes, error handling, reproducibility elements.\n\n---\n\n## A. Alignment Matrix Report\n\n| Requirement                     | File:Function/Section             | Status   | Notes                                                                                                                                                              |\n| :------------------------------ | :-------------------------------- | :------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Fix Look-forward Bias (General) | `calculate_indicators`            | âœ…        | `.shift(1)` applied systematically before rolling calculations (MA, Vol, Z-Score, ROC, Divergence, Trend Str, RSI, ATR).                                               |\n| Look-forward Bias (ATR)         | `calculate_indicators`            | âœ…        | ATR's TR calculation uses `Close.shift(1)`. Final ATR series is also shifted `.shift(1)`. **Resolves Audit Finding #1.**                                         |\n| Z-Score Window (365d / 105k)    | `calculate_indicators`, `CONFIG`  | âœ…        | `intervals_per_year` = 105120, `z_score_lookback_years` used correctly, lookback capped by data length.                                                            |\n| Simplified Exit Logic           | `run_backtest`                    | âœ…        | Prioritizes SL/TP, then optional configurable exits (MA Cross, Z-Score). Clear structure.                                                                          |\n| Hard 10% Drawdown Halt          | `run_backtest`, `CONFIG`          | âœ…        | `max_drawdown_pct`=10.0 used. Check occurs *before* bar processing, based on prior equity. Force exit implemented if halted while in position. **Resolves Audit Finding #3.** |\n| Sharpe Annualization (âˆš105,120) | `calculate_metrics`, `CONFIG`     | âœ…        | Uses `math.sqrt(config['intervals_per_year'])` with `intervals_per_year`=105120. Applied to std dev of interval returns.                                          |\n| Volatility (ATR) SL/TP          | `calculate_sl_tp`, `CONFIG`       | âœ…        | `use_volatility_stops` flag triggers ATR-based calculation using configured multipliers. Integrated into backtest.                                                 |\n| Position Sizing Logic           | `calculate_position_size`         | âš ï¸        | Function exists, `use_adaptive_position` flag exists but logic is placeholder. **Default still 1.0 (100% equity), Audit Finding #2 NOT fully resolved.**        |\n| Dynamic Thresholds Option       | `calculate_indicators`, `CONFIG`  | âœ…        | `use_dynamic_thresholds` flag implemented correctly using shifted MA/Volatility.                                                                                   |\n| Regime Adjustment Option        | `calculate_indicators`, `CONFIG`  | âœ…        | `use_regime_adjustment` flag implemented, adjusts TP/SL factors based on MVRV trend.                                                                               |\n| MVRV RSI Option                 | `calculate_indicators`, `CONFIG`  | âœ…        | `use_mvrv_rsi` flag implemented, calculation shifted, used as optional signal filter.                                                                            |\n| Adaptive Position Size Option   | `calculate_position_size`, `CONFIG` | âœ…        | Flag `use_adaptive_position` is present as required, but logic is explicitly a placeholder.                                                                        |\n| Dynamic MA Option               | `calculate_indicators`, `CONFIG`  | âœ…        | Flag `use_dynamic_ma` is present as required, but logic is explicitly a placeholder with warning.                                                                    |\n| Consistency (Vars, Params)      | Entire script                     | âœ…        | Consistent naming (`df`, `config`, indicators). Config parameters used correctly.                                                                                  |\n| Docstrings / Type Hints         | Entire script                     | âœ…        | Generally well-documented with docstrings and type hints.                                                                                                          |\n| PEP8 Compliance                 | Entire script                     | âœ…        | Code structure and formatting appear compliant (visual inspection).                                                                                                |\n| Error Handling                  | `load_and_preprocess_data`, `main`| âœ…        | Basic file/value/key errors handled. Main execution wrapped in try/except.                                                                                         |\n| Reproducibility Elements        | `CONFIG`, `main`                  | âš ï¸        | `random_seed` present but commented out. Requires `requirements.txt` for version pinning.                                                                          |\n| Unit Test Coverage              | `main` (comment block)            | âŒ        | Placeholder comments exist, but **no actual unit tests** were provided or implemented by PyStrategist. Critical gap.                                               |\n\n---\n\n## B. Outstanding Issues\n\n1.  **CRITICAL: Default Position Sizing Risk:** The `calculate_position_size` function defaults to returning `1.0`, representing 100% equity allocation per trade. While the *option* for adaptive sizing exists (`use_adaptive_position`), its logic is only a placeholder. This retains the extreme risk highlighted by **Audit Finding #2**.\n    *   **Next Step:** Implement sensible default position sizing (e.g., fixed fractional 1-5% of equity, or volatility-based risk parity) OR complete the `use_adaptive_position` logic immediately. This must be addressed before production.\n2.  **CRITICAL: Missing Unit Tests:** The PyStrategist code includes comments listing potential unit tests but provides no implementation. Without tests, verifying correctness, preventing regressions, and ensuring reliability for production is impossible.\n    *   **Next Step:** Implement comprehensive unit tests covering data loading edge cases, indicator calculations (especially look-ahead prevention), signal logic, SL/TP calculation, drawdown halt mechanism, and metric calculations. Target critical functions like `calculate_indicators`, `calculate_sl_tp`, `run_backtest`, `calculate_metrics`.\n3.  **HIGH: Missing Requirements File:** No `requirements.txt` is provided, hindering reproducibility.\n    *   **Next Step:** Generate a `requirements.txt` file listing exact versions of pandas, numpy, matplotlib used.\n4.  **MEDIUM: Placeholder Logic:** The features `use_adaptive_position` and `use_dynamic_ma` are controlled by flags but lack functional implementation (as acknowledged by PyStrategist comments). If these flags are intended to be usable, the logic needs to be built.\n    *   **Next Step:** Implement the actual logic for these features or disable/remove the flags if they are not intended for use in the initial production version.\n5.  **LOW: Random Seed:** The `random_seed` in `CONFIG` is commented out. While the current logic seems deterministic, uncommenting it is good practice for future-proofing if any stochastic elements are added.\n    *   **Next Step:** Uncomment the seed lines in `main()` if reproducibility needs to be strictly enforced for potential future random elements.\n\n---\n\n## C. Final Verdict\n\n**Requires Action**\n\nThe strategy code structure is sound, incorporates many design requirements, and crucially addresses the look-ahead bias and drawdown halt timing issues identified by the auditor. However, **two critical gaps** prevent production readiness:\n\n1.  The default **100% position sizing** presents unacceptable risk (Audit Finding #2).\n2.  The complete **absence of unit tests** makes the code unverifiable and fragile.\n\nThese issues must be resolved before deployment.\n\n**Prioritized Tasks:**\n\n1.  **Implement Safe Position Sizing:** Modify `calculate_position_size` immediately.\n2.  **Develop Unit Tests:** Create a test suite covering critical logic.\n3.  **Generate `requirements.txt`:** Ensure dependency pinning.\n4.  **Address Placeholders:** Implement or remove non-functional feature flags (`use_adaptive_position`, `use_dynamic_ma`).\n5.  **Uncomment Random Seed:** Minor but good practice.\n\n---\n\n## D. Final Python Code Bundle\n\nThe following code reflects the verified state from PyStrategist, incorporating fixes for look-ahead bias and drawdown timing, but *still requires the actions listed above* (especially position sizing and unit tests) before being truly production-ready.\n\n```python\n# --- File: config.py ---\n\"\"\"\nConfiguration settings for the Dynamic MVRV Strategy.\n\"\"\"\nimport math\n\nCONFIG = {\n    # Data & General\n    \"csv_path\": \"path/to/your/btc_5min_data.csv\", # <--- USER: PLEASE UPDATE THIS PATH\n    \"start_date\": \"2020-01-01\", # Optional: Filter data >= start_date\n    \"end_date\": \"2023-12-31\",   # Optional: Filter data <= end_date\n    \"price_col\": \"Close\", # Column name for BTC price (usually 'Close' or 'Price')\n    \"mvrv_col\": \"7d_mvrv\", # Column name for 7-day MVRV\n    \"ohlc_cols\": [\"Open\", \"High\", \"Low\", \"Close\"], # Ensure these exist for ATR\n    \"volume_col\": \"Volume\", # Optional, not used in core logic yet\n    \"timestamp_col\": \"timestamp\", # Column name for timestamp\n\n    # MVRV Base Strategy\n    \"ma_period\": 30 * 12 * 24, # Default MA period (e.g., 30 days for 5-min data)\n    \"negative_quantile\": 0.25, # For static threshold calculation\n    \"positive_quantile\": 0.75, # For static threshold calculation\n\n    # Feature Flags (Enable/Disable Enhancements)\n    \"use_dynamic_thresholds\": True, # Use MVRV_MA +/- Volatility * factor\n    \"dynamic_threshold_factor\": 2.0, # Factor for dynamic thresholds\n    \"use_regime_adjustment\": False, # Adjust TP/SL based on MVRV trend\n    \"regime_ma_period_factor\": 1.0, # Multiplier for base ma_period for trend calc\n    \"regime_uptrend_tp_mult\": 1.5,\n    \"regime_uptrend_sl_mult\": 0.8,\n    \"regime_downtrend_tp_mult\": 0.8,\n    \"regime_downtrend_sl_mult\": 1.2,\n    \"use_mvrv_rsi\": False, # Use MVRV RSI for signal confirmation/filtering\n    \"mvrv_rsi_period\": 14 * 12 * 24, # e.g., 14 days for 5-min data\n    \"mvrv_rsi_buy_threshold\": 40.0,\n    \"mvrv_rsi_sell_threshold\": 60.0,\n    \"use_adaptive_position\": False, # Size positions based on conviction (PLACEHOLDER LOGIC)\n    \"use_dynamic_ma\": False, # Adapt MA period based on MVRV volatility (PLACEHOLDER LOGIC)\n    \"dynamic_ma_min_period\": 10 * 12 * 24, # e.g., 10 days\n    \"dynamic_ma_max_period\": 50 * 12 * 24, # e.g., 50 days\n\n    # Complementary Indicators Configuration\n    \"z_score_lookback_years\": 1, # Lookback for Z-score calculation (in years)\n    \"roc_period\": 7 * 12 * 24,   # Rate of Change period (e.g., 7 days)\n    \"divergence_norm_window\": 30 * 12 * 24, # Normalization window for divergence (e.g., 30 days)\n    \"divergence_lookback\": 5 * 12 * 24,     # Lookback period for detecting divergence (e.g., 5 days)\n    \"trend_strength_period\": 14 * 12 * 24, # Period for MVRV trend strength (e.g., 14 days)\n\n    # Risk Management\n    \"initial_capital\": 10000.0,\n    \"max_drawdown_pct\": 10.0, # Hard stop if equity drops this % from peak\n    \"drawdown_recovery_pct\": 5.0, # Resume trading if drawdown recovers to < this %\n    \"use_volatility_stops\": True, # Use ATR for SL/TP calculation\n    \"atr_period\": 14 * 12 * 24,  # ATR lookback period (e.g., 14 days)\n    \"atr_tp_multiplier\": 3.0, # Take Profit = entry +/- ATR * multiplier\n    \"atr_sl_multiplier\": 1.5, # Stop Loss = entry -/+ ATR * multiplier\n    \"use_mvrv_stops\": False, # Alternative: Use MVRV distance for SL/TP (Requires careful calibration)\n    \"mvrv_tp_factor\": 1.0, # Multiplier for MVRV distance proxy for TP\n    \"mvrv_sl_factor\": 0.5, # Multiplier for MVRV distance proxy for SL\n\n    # Position Sizing (CRITICAL: Needs review/modification)\n    \"position_sizing_fraction\": 1.0, # Default fraction of equity to risk (1.0 = 100%, VERY HIGH RISK)\n\n    # Exit Logic Configuration\n    \"exit_on_zscore_extreme\": False, # Exit if MVRV Z-score becomes extreme\n    \"zscore_extreme_threshold\": 2.0,\n    \"exit_on_divergence\": False, # Exit if adverse divergence forms after entry\n    \"exit_on_ma_cross\": True, # Original core exit logic (MVRV crosses back over MA)\n\n    # Backtest & Metrics\n    \"intervals_per_year\": (60 // 5) * 24 * 365, # 105,120 for 5-min data (24/7 crypto)\n    \"risk_free_rate\": 0.0, # For Sharpe/Sortino calculation\n\n    # Plotting\n    \"plot_results\": True,\n    \"plot_equity\": True,\n\n    # Reproducibility\n    \"random_seed\": 42,\n}\n\n# Calculate intervals per year for easier access\nCONFIG['intervals_per_year'] = (60 // 5) * 24 * 365\nCONFIG['annualization_factor'] = math.sqrt(CONFIG['intervals_per_year'])\n\n```\n\n```python\n# --- File: data_loader.py ---\n\"\"\"\nData loading and preprocessing functionality.\n\"\"\"\nimport pandas as pd\nfrom typing import Dict, Any\n\n# Suppress pandas SettingWithCopyWarning (use with caution)\npd.options.mode.chained_assignment = None  # default='warn'\n\ndef load_and_preprocess_data(config: Dict[str, Any]) -> pd.DataFrame:\n    \"\"\"Loads data from CSV, validates, converts timestamp, and filters dates.\"\"\"\n    print(f\"Loading data from: {config['csv_path']}\")\n    try:\n        df = pd.read_csv(config['csv_path'])\n    except FileNotFoundError:\n        print(f\"ERROR: CSV file not found at {config['csv_path']}\")\n        print(\"Please update the 'csv_path' in the CONFIG dictionary.\")\n        raise\n\n    print(f\"Initial data shape: {df.shape}\")\n\n    # --- Validation ---\n    ts_col = config['timestamp_col']\n    price_col = config['price_col']\n    mvrv_col = config['mvrv_col']\n    required_cols = [ts_col, price_col, mvrv_col]\n    if config['use_volatility_stops']:\n        required_cols.extend(config['ohlc_cols']) # Need OHLC for ATR\n\n    missing_cols = [col for col in required_cols if col not in df.columns]\n    if missing_cols:\n        raise ValueError(f\"Missing required columns: {missing_cols}\")\n\n    # --- Timestamp Handling ---\n    if ts_col not in df.columns:\n         raise ValueError(f\"DataFrame must contain the timestamp column: '{ts_col}'\")\n    # Try inferring format, common ones first\n    try:\n        # Attempt numeric conversion first (common for Unix timestamps)\n        df[ts_col] = pd.to_numeric(df[ts_col], errors='coerce')\n        # Check magnitude to guess unit (simple heuristic)\n        if df[ts_col].max() > 1e12: # Likely milliseconds\n             df['timestamp'] = pd.to_datetime(df[ts_col], unit='ms', errors='coerce')\n        else: # Likely seconds\n             df['timestamp'] = pd.to_datetime(df[ts_col], unit='s', errors='coerce')\n    except Exception: # Fallback to general datetime parsing if numeric fails or leads to errors\n         try:\n              df['timestamp'] = pd.to_datetime(df[ts_col], errors='coerce') # Standard formats\n         except Exception as e:\n              raise ValueError(f\"Could not parse '{ts_col}' column. Error: {e}. Ensure it's Unix time (s or ms) or a standard datetime format.\")\n\n    # Rename parsed timestamp column and set as index\n    df = df.rename(columns={'timestamp': 'datetime'}) # Avoid clash if original was 'timestamp'\n    df = df.dropna(subset=['datetime']) # Drop rows where timestamp parsing failed\n    df = df.set_index('datetime')\n    df = df.sort_index()\n\n    # Check for duplicate timestamps\n    if df.index.duplicated().any():\n        print(\"Warning: Duplicate timestamps found. Keeping the first occurrence.\")\n        df = df[~df.index.duplicated(keep='first')]\n\n    # --- Data Type Conversion & Cleaning ---\n    cols_to_numeric = [price_col, mvrv_col]\n    if config['use_volatility_stops']:\n         cols_to_numeric.extend(config['ohlc_cols'])\n    if config.get('volume_col') in df.columns:\n         cols_to_numeric.append(config['volume_col'])\n\n    for col in cols_to_numeric:\n        if col in df.columns:\n             df[col] = pd.to_numeric(df[col], errors='coerce')\n\n    initial_len = len(df)\n    required_numeric_cols = [price_col, mvrv_col] # Core requirements for strategy logic\n    if config['use_volatility_stops']:\n         required_numeric_cols.extend(config['ohlc_cols'])\n    df = df.dropna(subset=required_numeric_cols) # Drop rows with NaNs in essential numeric columns\n    if initial_len > len(df):\n        print(f\"Warning: Dropped {initial_len - len(df)} rows due to NaNs in required numeric columns.\")\n\n    # Rename columns for consistency within the strategy code\n    rename_map = {}\n    if price_col != 'Price':\n        rename_map[price_col] = 'Price'\n    if mvrv_col != '7d_mvrv':\n        rename_map[mvrv_col] = '7d_mvrv'\n    if config['use_volatility_stops']:\n         ohlc_map = {cfg_col: target for cfg_col, target in zip(config['ohlc_cols'], ['Open', 'High', 'Low', 'Close']) if cfg_col != target}\n         rename_map.update(ohlc_map)\n\n    if rename_map:\n        df = df.rename(columns=rename_map)\n        print(f\"Renamed columns: {rename_map}\")\n\n    # --- Date Filtering ---\n    if config.get(\"start_date\"):\n        df = df[df.index >= pd.to_datetime(config[\"start_date\"])]\n    if config.get(\"end_date\"):\n        df = df[df.index <= pd.to_datetime(config[\"end_date\"])]\n\n    # Check if data remains\n    if df.empty:\n        raise ValueError(\"No data remaining after preprocessing and date filtering.\")\n\n    print(f\"Preprocessed data shape: {df.shape}, from {df.index.min()} to {df.index.max()}\")\n    return df\n```\n\n```python\n# --- File: indicators.py ---\n\"\"\"\nFunctions for calculating technical and on-chain indicators.\nEnsures no look-ahead bias by using .shift(1) appropriately.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom typing import Dict, Any\nimport warnings\n\ndef _calculate_atr(df: pd.DataFrame, config: Dict[str, Any]) -> pd.Series:\n    \"\"\"Calculates Average True Range (ATR). Internal helper.\"\"\"\n    if not all(col in df.columns for col in ['High', 'Low', 'Close']):\n         raise ValueError(\"Missing High, Low, or Close columns required for ATR\")\n\n    high_low = df['High'] - df['Low']\n    # Ensure use of PREVIOUS close for ATR calculation to prevent look-ahead\n    high_close = (df['High'] - df['Close'].shift(1)).abs()\n    low_close = (df['Low'] - df['Close'].shift(1)).abs()\n\n    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n    atr = tr.rolling(window=config['atr_period'], min_periods=config['atr_period'] // 2).mean()\n    return atr\n\ndef calculate_indicators(df: pd.DataFrame, config: Dict[str, Any]) -> pd.DataFrame:\n    \"\"\"Calculates all required indicators, ensuring no look-ahead bias.\"\"\"\n    print(\"Calculating indicators...\")\n    df_out = df.copy()\n\n    # --- Base MVRV Indicators (Shifted) ---\n    # Use .shift(1) before rolling ensures value at time `t` uses data up to `t-1`.\n    mvrv_shifted = df_out['7d_mvrv'].shift(1)\n    price_shifted = df_out['Price'].shift(1)\n\n    df_out['MVRV_MA'] = mvrv_shifted.rolling(window=config['ma_period'], min_periods=config['ma_period'] // 2).mean()\n    df_out['MVRV_Volatility'] = mvrv_shifted.rolling(window=config['ma_period'], min_periods=config['ma_period'] // 2).std()\n\n    # --- Volatility Stops Indicator (ATR) ---\n    if config['use_volatility_stops']:\n        # ATR calculation uses shifted close internally.\n        atr_raw = _calculate_atr(df_out, config)\n        # Shift final ATR series so value at `t` is based on calculations up to `t-1`.\n        df_out['ATR'] = atr_raw.shift(1)\n\n    # --- Complementary Indicators (Shifted) ---\n    # 1. MVRV Z-Score\n    intervals_per_year = config['intervals_per_year']\n    z_score_lookback_intervals = int(config['z_score_lookback_years'] * intervals_per_year)\n    lookback_z = min(z_score_lookback_intervals, len(df_out) - 1)\n    min_z_periods = max(10, lookback_z // 2) # Ensure a minimum reasonable period\n\n    if lookback_z < intervals_per_year / 12: # Less than ~a month's worth\n        print(f\"Warning: Insufficient data for {config['z_score_lookback_years']}-year Z-score. Using {lookback_z} intervals (~{lookback_z / (12*24):.1f} days)\")\n\n    rolling_mean_z = mvrv_shifted.rolling(window=lookback_z, min_periods=min_z_periods).mean()\n    rolling_std_z = mvrv_shifted.rolling(window=lookback_z, min_periods=min_z_periods).std()\n    df_out['MVRV_Z_Score'] = (mvrv_shifted - rolling_mean_z) / (rolling_std_z + 1e-10)\n\n    # 2. MVRV Rate of Change (ROC)\n    # pct_change inherently looks back `periods`. Shift the result to align.\n    df_out['MVRV_ROC'] = df_out['7d_mvrv'].pct_change(periods=config['roc_period']).shift(1) * 100\n\n    # 3. Price/MVRV Divergence\n    norm_window = config['divergence_norm_window']\n    min_norm_periods = norm_window // 2\n    price_norm = price_shifted / price_shifted.rolling(norm_window, min_periods=min_norm_periods).mean() - 1\n    mvrv_norm = mvrv_shifted / mvrv_shifted.rolling(norm_window, min_periods=min_norm_periods).mean() - 1\n    df_out['Price_MVRV_Divergence'] = price_norm - mvrv_norm # Based on shifted inputs\n\n    # 4. MVRV Trend Strength (DI+/- concept)\n    period_trend = config['trend_strength_period']\n    min_trend_periods = period_trend // 2\n    mvrv_diff = df_out['7d_mvrv'].diff() # Based on t vs t-1\n\n    dm_plus = pd.Series(np.where(mvrv_diff > 0, mvrv_diff, 0), index=df_out.index)\n    dm_minus = pd.Series(np.where(mvrv_diff < 0, -mvrv_diff, 0), index=df_out.index)\n\n    dm_plus_smooth = dm_plus.rolling(period_trend, min_periods=min_trend_periods).mean()\n    dm_minus_smooth = dm_minus.rolling(period_trend, min_periods=min_trend_periods).mean()\n\n    trend_strength_raw = (dm_plus_smooth - dm_minus_smooth).abs() / (dm_plus_smooth + dm_minus_smooth + 1e-10) * 100\n    df_out['MVRV_Trend_Strength'] = trend_strength_raw.shift(1) # Shift result\n\n    # --- Feature-Flagged Indicators ---\n\n    # Dynamic Thresholds (based on shifted MA/Vol)\n    if config['use_dynamic_thresholds']:\n        df_out['Positive_Threshold'] = df_out['MVRV_MA'] + (df_out['MVRV_Volatility'] * config['dynamic_threshold_factor'])\n        df_out['Negative_Threshold'] = df_out['MVRV_MA'] - (df_out['MVRV_Volatility'] * config['dynamic_threshold_factor'])\n    else:\n        # Static thresholds (calculated once based on historical non-shifted MVRV)\n        min_data_for_quantile = max(100, config['ma_period'])\n        if len(df_out) > min_data_for_quantile:\n            positive_mvrv = df_out.loc[df_out['7d_mvrv'] > 0, '7d_mvrv']\n            negative_mvrv = df_out.loc[df_out['7d_mvrv'] < 0, '7d_mvrv']\n            pos_thresh = positive_mvrv.quantile(config['positive_quantile']) if not positive_mvrv.empty else 0.05\n            neg_thresh = negative_mvrv.quantile(config['negative_quantile']) if not negative_mvrv.empty else -0.05\n        else:\n            warnings.warn(\"Not enough data for historical quantile thresholds, using defaults.\")\n            pos_thresh = 0.05\n            neg_thresh = -0.05\n        df_out['Positive_Threshold'] = pos_thresh\n        df_out['Negative_Threshold'] = neg_thresh\n\n    # Regime Detection (based on shifted MA)\n    if config['use_regime_adjustment']:\n        regime_ma_period = int(config['ma_period'] * config['regime_ma_period_factor'])\n        df_out['MVRV_Trend'] = np.where(\n            df_out['MVRV_MA'] > df_out['MVRV_MA'].shift(regime_ma_period), 'uptrend', 'downtrend'\n        )\n        df_out['MVRV_Trend'] = df_out['MVRV_Trend'].ffill().bfill() # Fill NaNs robustly\n\n        # Adjust MVRV Stop factors\n        df_out['Adjusted_TP_Factor'] = np.where(\n            df_out['MVRV_Trend'] == 'uptrend', config['mvrv_tp_factor'] * config['regime_uptrend_tp_mult'],\n            config['mvrv_tp_factor'] * config['regime_downtrend_tp_mult']\n        )\n        df_out['Adjusted_SL_Factor'] = np.where(\n            df_out['MVRV_Trend'] == 'uptrend', config['mvrv_sl_factor'] * config['regime_uptrend_sl_mult'],\n            config['mvrv_sl_factor'] * config['regime_downtrend_sl_mult']\n        )\n        # Adjust ATR Stop multipliers\n        df_out['Adjusted_ATR_TP_Multiplier'] = np.where(\n             df_out['MVRV_Trend'] == 'uptrend', config['atr_tp_multiplier'] * config['regime_uptrend_tp_mult'],\n             config['atr_tp_multiplier'] * config['regime_downtrend_tp_mult']\n        )\n        df_out['Adjusted_ATR_SL_Multiplier'] = np.where(\n             df_out['MVRV_Trend'] == 'uptrend', config['atr_sl_multiplier'] * config['regime_uptrend_sl_mult'],\n             config['atr_sl_multiplier'] * config['regime_downtrend_sl_mult']\n        )\n    else:\n        # Set defaults if regime adjustment is off\n        df_out['Adjusted_TP_Factor'] = config['mvrv_tp_factor']\n        df_out['Adjusted_SL_Factor'] = config['mvrv_sl_factor']\n        df_out['Adjusted_ATR_TP_Multiplier'] = config['atr_tp_multiplier']\n        df_out['Adjusted_ATR_SL_Multiplier'] = config['atr_sl_multiplier']\n\n    # MVRV RSI (shifted)\n    if config['use_mvrv_rsi']:\n        period_rsi = config['mvrv_rsi_period']\n        min_rsi_periods = period_rsi // 2\n        delta_rsi = df_out['7d_mvrv'].diff()\n        gain = delta_rsi.where(delta_rsi > 0, 0).fillna(0)\n        loss = -delta_rsi.where(delta_rsi < 0, 0).fillna(0)\n\n        avg_gain = gain.ewm(com=period_rsi - 1, min_periods=min_rsi_periods).mean()\n        avg_loss = loss.ewm(com=period_rsi - 1, min_periods=min_rsi_periods).mean()\n\n        rs = avg_gain / (avg_loss + 1e-10)\n        rsi_raw = 100 - (100 / (1 + rs))\n        df_out['MVRV_RSI'] = rsi_raw.shift(1) # Shift result\n\n    # Dynamic MA (Placeholder Logic)\n    if config['use_dynamic_ma']:\n         warnings.warn(\"Dynamic MA calculation is complex; using standard MA as fallback.\", UserWarning)\n         df_out['MVRV_Adaptive_MA'] = df_out['MVRV_MA'] # Fallback\n         df_out['Adaptive_MA_Period'] = config['ma_period'] # Fallback\n         # Proper implementation would require iterative or advanced vectorization\n\n    # --- Final Cleanup ---\n    # Drop initial rows with NaNs generated by the longest rolling calculation + shift\n    # Determine required columns based on config\n    required_indicator_cols = ['MVRV_MA', 'MVRV_Volatility', 'MVRV_Z_Score', 'MVRV_ROC', 'Price_MVRV_Divergence', 'MVRV_Trend_Strength']\n    if config['use_volatility_stops']: required_indicator_cols.append('ATR')\n    if config['use_mvrv_rsi']: required_indicator_cols.append('MVRV_RSI')\n\n    # Find the first index where ALL required indicators are non-NaN\n    first_valid_idx = df_out.dropna(subset=required_indicator_cols).index.min()\n\n    if pd.isna(first_valid_idx):\n        raise ValueError(\"Could not calculate indicators, likely insufficient data for lookback periods.\")\n\n    print(f\"Indicator calculation complete. Dropping initial rows before {first_valid_idx} due to indicator warmup.\")\n    df_out = df_out.loc[first_valid_idx:]\n\n    if df_out.empty:\n         raise ValueError(\"No data remaining after indicator calculation warmup.\")\n\n    return df_out\n\n```\n\n```python\n# --- File: signals.py ---\n\"\"\"\nGenerates trading entry signals based on calculated indicators.\n\"\"\"\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, Any\n\ndef generate_signals(df: pd.DataFrame, config: Dict[str, Any]) -> pd.DataFrame:\n    \"\"\"Generates buy (1) and sell (-1) signals.\"\"\"\n    print(\"Generating signals...\")\n    df_out = df.copy()\n    df_out['Signal'] = 0\n\n    # Define MA column to use based on config\n    ma_col = 'MVRV_Adaptive_MA' if config['use_dynamic_ma'] else 'MVRV_MA'\n\n    # Vectorized conditions where possible (more complex logic might still need iteration)\n    # Note: Using shifted indicators means df['Indicator'].iloc[i] gives value calculated before bar i\n\n    # Base Entry Conditions using shifted values for comparison at time t\n    # Accessing .shift() again here applies shift relative to the current index `i`\n    mvrv_t = df_out['7d_mvrv']\n    mvrv_t_minus_1 = df_out['7d_mvrv'].shift(1)\n    mvrv_ma_t = df_out[ma_col] # Already shifted in calculation phase\n    neg_threshold_t = df_out['Negative_Threshold'] # Already shifted if dynamic\n    pos_threshold_t = df_out['Positive_Threshold'] # Already shifted if dynamic\n\n    buy_condition = (mvrv_t_minus_1 < neg_threshold_t) & (mvrv_t > mvrv_ma_t) & (mvrv_t_minus_1 < mvrv_ma_t)\n    sell_condition = (mvrv_t_minus_1 > pos_threshold_t) & (mvrv_t < mvrv_ma_t) & (mvrv_t_minus_1 > mvrv_ma_t)\n\n    # Apply Filters/Confirmations\n    if config['use_mvrv_rsi']:\n        mvrv_rsi_t = df_out['MVRV_RSI'] # Already shifted\n        buy_condition = buy_condition & (mvrv_rsi_t < config['mvrv_rsi_buy_threshold'])\n        sell_condition = sell_condition & (mvrv_rsi_t > config['mvrv_rsi_sell_threshold'])\n\n    # Add other filter conditions here if needed, e.g.:\n    # if config['require_zscore_filter']:\n    #     mvrv_z_score_t = df_out['MVRV_Z_Score'] # Already shifted\n    #     buy_condition = buy_condition & (mvrv_z_score_t < 0)\n    #     sell_condition = sell_condition & (mvrv_z_score_t > 0)\n\n    # Assign Signals\n    df_out.loc[buy_condition, 'Signal'] = 1\n    df_out.loc[sell_condition, 'Signal'] = -1 # Use -1 for short signals\n\n    print(f\"Generated {len(df_out[df_out['Signal'] != 0])} potential entry signals.\")\n    return df_out\n\n```\n\n```python\n# --- File: risk.py ---\n\"\"\"\nRisk management functions: position sizing, SL/TP calculation.\n\"\"\"\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, Any, Tuple, Optional\nimport warnings\n\ndef calculate_position_size(current_equity: float, config: Dict[str, Any], df_row: Optional[pd.Series] = None) -> float:\n    \"\"\"\n    Calculates position size as a fraction of equity.\n    CRITICAL: Default logic uses 100% equity - VERY HIGH RISK. Needs modification.\n    \"\"\"\n    if config['use_adaptive_position'] and df_row is not None:\n        # --- PLACEHOLDER for Adaptive Logic ---\n        # Example: Scale size based on absolute Z-score deviation (needs calibration)\n        # base_fraction = 0.02 # Risk 2% by default\n        # max_fraction = 0.10 # Max risk 10%\n        # z_score = df_row.get('MVRV_Z_Score', 0)\n        # conviction = min(abs(z_score) / 3.0, 1.0) # Normalize Z-score effect (0 to 1)\n        # size_fraction = base_fraction + (max_fraction - base_fraction) * conviction\n        # return min(size_fraction, max_fraction) # Ensure ceiling\n        # --- END PLACEHOLDER ---\n        warnings.warn(\"Adaptive position sizing logic is a placeholder. Using fixed fraction.\", UserWarning)\n        # Fallback to fixed fraction if adaptive logic not implemented\n        return config['position_sizing_fraction'] # CRITICAL: Default 1.0 (100%)\n    else:\n        # Fixed fractional sizing\n        return config['position_sizing_fraction'] # CRITICAL: Default 1.0 (100%)\n\ndef calculate_sl_tp(entry_price: float, signal: int, config: Dict[str, Any], df_row: pd.Series) -> Tuple[Optional[float], Optional[float]]:\n    \"\"\"Calculates Stop Loss and Take Profit levels based on config.\"\"\"\n    tp_level = None\n    sl_level = None\n\n    if config['use_volatility_stops']:\n        # ATR stops require 'ATR' and adjusted multipliers in the row\n        atr = df_row.get('ATR')\n        if pd.isna(atr) or atr <= 0: # Check ATR validity\n            warnings.warn(f\"ATR is NaN or non-positive at {df_row.name}. Cannot set volatility stops.\", UserWarning)\n            return None, None # Abort if ATR invalid\n\n        tp_mult = df_row.get('Adjusted_ATR_TP_Multiplier', config['atr_tp_multiplier'])\n        sl_mult = df_row.get('Adjusted_ATR_SL_Multiplier', config['atr_sl_multiplier'])\n\n        if signal == 1: # Long\n            tp_level = entry_price + atr * tp_mult\n            sl_level = entry_price - atr * sl_mult\n        elif signal == -1: # Short\n            tp_level = entry_price - atr * tp_mult\n            sl_level = entry_price + atr * sl_mult\n\n    elif config['use_mvrv_stops']:\n        # MVRV stops require MVRV, MA, and adjusted factors\n        entry_mvrv = df_row.get('7d_mvrv')\n        mvrv_ma = df_row.get('MVRV_MA') # Already shifted\n        if pd.isna(entry_mvrv) or pd.isna(mvrv_ma):\n             warnings.warn(f\"MVRV or MVRV_MA is NaN at {df_row.name}. Cannot set MVRV stops.\", UserWarning)\n             return None, None # Abort if values invalid\n\n        tp_factor = df_row.get('Adjusted_TP_Factor', config['mvrv_tp_factor'])\n        sl_factor = df_row.get('Adjusted_SL_Factor', config['mvrv_sl_factor'])\n\n        # Simple proxy: Use price % change proportional to MVRV distance from MA\n        # This is a heuristic and needs careful validation/calibration.\n        mvrv_distance_pct = abs(entry_mvrv - mvrv_ma) # Absolute MVRV distance\n\n        if signal == 1: # Long\n            price_change_tp = entry_price * (mvrv_distance_pct * tp_factor) # Assume direct proportionality\n            price_change_sl = entry_price * (mvrv_distance_pct * sl_factor)\n            tp_level = entry_price + price_change_tp\n            sl_level = entry_price - price_change_sl\n        elif signal == -1: # Short\n            price_change_tp = entry_price * (mvrv_distance_pct * tp_factor)\n            price_change_sl = entry_price * (mvrv_distance_pct * sl_factor)\n            tp_level = entry_price - price_change_tp\n            sl_level = entry_price + price_change_sl\n    else:\n        # No stops defined if both flags are false\n        pass\n\n    # --- Sanity Checks ---\n    # Ensure SL is logical (e.g., below entry for long, above for short)\n    if signal == 1 and sl_level is not None and sl_level >= entry_price:\n        warnings.warn(f\"Calculated SL ({sl_level:.2f}) >= entry ({entry_price:.2f}) for long trade at {df_row.name}. Check ATR/factors. Setting fallback SL.\", UserWarning)\n        sl_level = entry_price * (1 - 0.005) # Small fallback SL (e.g., 0.5%)\n    if signal == -1 and sl_level is not None and sl_level <= entry_price:\n        warnings.warn(f\"Calculated SL ({sl_level:.2f}) <= entry ({entry_price:.2f}) for short trade at {df_row.name}. Check ATR/factors. Setting fallback SL.\", UserWarning)\n        sl_level = entry_price * (1 + 0.005) # Small fallback SL\n\n    # Ensure TP is logical\n    if signal == 1 and tp_level is not None and tp_level <= entry_price:\n         warnings.warn(f\"Calculated TP ({tp_level:.2f}) <= entry ({entry_price:.2f}) for long trade at {df_row.name}. Check ATR/factors. Setting TP to None.\", UserWarning)\n         tp_level = None # Invalidate illogical TP\n    if signal == -1 and tp_level is not None and tp_level >= entry_price:\n         warnings.warn(f\"Calculated TP ({tp_level:.2f}) >= entry ({entry_price:.2f}) for short trade at {df_row.name}. Check ATR/factors. Setting TP to None.\", UserWarning)\n         tp_level = None # Invalidate illogical TP\n\n    return sl_level, tp_level\n\n```\n\n```python\n# --- File: backtest.py ---\n\"\"\"\nBacktesting engine simulating strategy execution and applying risk rules.\n\"\"\"\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, Any, Tuple, List\nfrom risk import calculate_position_size, calculate_sl_tp # Import from risk module\n\ndef run_backtest(df: pd.DataFrame, config: Dict[str, Any]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"Runs the backtest simulation loop.\"\"\"\n    print(\"Running backtest...\")\n    df_results = df.copy()\n\n    # Initialize backtest state columns\n    df_results['Position'] = 0          # 1: long, -1: short, 0: flat\n    df_results['Entry_Price'] = np.nan\n    df_results['Exit_Price'] = np.nan\n    df_results['SL_Level'] = np.nan\n    df_results['TP_Level'] = np.nan\n    df_results['Trade_Return'] = np.nan # Pct return for the closed trade\n    df_results['Equity'] = config['initial_capital']\n    df_results['Peak_Equity'] = config['initial_capital']\n    df_results['Drawdown'] = 0.0        # Drawdown percentage\n    df_results['Trading_Halted'] = False # Track drawdown halt status\n\n    # Simulation state variables\n    in_position = 0 # Current position state\n    entry_price = 0.0\n    current_equity = config['initial_capital']\n    peak_equity = config['initial_capital']\n    position_size_fraction = 1.0 # Fraction of equity risked per trade\n    sl_level = None\n    tp_level = None\n    trade_entry_index = None\n    trading_halted = False # Internal state flag for drawdown halt\n\n    max_drawdown_limit = config['max_drawdown_pct'] / 100.0\n    drawdown_recovery_target = config['drawdown_recovery_pct'] / 100.0\n\n    trade_log: List[Dict[str, Any]] = []\n\n    # Define MA column to use based on config (for MA cross exit)\n    ma_col = 'MVRV_Adaptive_MA' if config['use_dynamic_ma'] else 'MVRV_MA'\n\n    # --- Simulation Loop ---\n    for i in range(len(df_results)):\n        current_dt = df_results.index[i]\n        current_row = df_results.iloc[i]\n        # Use Close price for calculations, but consider using Open for entry/exit simulation if preferred\n        current_price = current_row['Price']\n        # Use High/Low for more realistic SL/TP checks within the bar if available\n        current_high = current_row.get('High', current_price)\n        current_low = current_row.get('Low', current_price)\n\n        # --- Update Equity and Drawdown based on PREVIOUS state ---\n        # Equity reflects the close of the *last* bar processed or initial capital\n        df_results['Equity'].iloc[i] = current_equity\n        peak_equity = max(peak_equity, current_equity)\n        df_results['Peak_Equity'].iloc[i] = peak_equity\n        current_drawdown = (peak_equity - current_equity) / peak_equity if peak_equity > 0 else 0\n        df_results['Drawdown'].iloc[i] = current_drawdown * 100\n\n        # --- Drawdown Halt Check (based on state BEFORE current bar actions) ---\n        if trading_halted:\n            df_results['Trading_Halted'].iloc[i] = True\n            # Check for recovery\n            if current_drawdown < drawdown_recovery_target:\n                 trading_halted = False\n                 df_results['Trading_Halted'].iloc[i] = False # Mark recovery\n                 print(f\"{current_dt}: Trading RESUMED. Drawdown {current_drawdown*100:.2f}% < {drawdown_recovery_target*100:.1f}% target.\")\n            # else: remain halted\n\n        elif current_drawdown >= max_drawdown_limit:\n            # Drawdown limit breached based on previous bar's close equity\n            trading_halted = True\n            df_results['Trading_Halted'].iloc[i] = True\n            print(f\"{current_dt}: Trading HALTED. Drawdown {current_drawdown*100:.2f}% >= {max_drawdown_limit*100:.1f}% limit.\")\n            # Force exit IF currently in a position\n            if in_position != 0:\n                 exit_price = current_price # Exit at current bar's price (e.g., Close)\n                 print(f\"Force exiting position at {exit_price:.2f} due to drawdown halt.\")\n                 # Calculate PnL for the forced exit\n                 if in_position == 1: # Long\n                     trade_return = (exit_price - entry_price) / entry_price\n                 else: # Short\n                     trade_return = (entry_price - exit_price) / entry_price\n\n                 trade_pnl = current_equity * position_size_fraction * trade_return\n                 current_equity += trade_pnl # Update equity immediately\n\n                 # Log the forced trade exit\n                 trade_log.append({\n                    'entry_dt': trade_entry_index, 'exit_dt': current_dt,\n                    'entry_price': entry_price, 'exit_price': exit_price,\n                    'position_type': 'long' if in_position == 1 else 'short',\n                    'size_fraction': position_size_fraction,\n                    'return_pct': trade_return * 100, 'pnl': trade_pnl,\n                    'exit_reason': 'Drawdown Halt Force Exit', 'sl_level': sl_level, 'tp_level': tp_level\n                 })\n                 # Update DataFrame for the closed trade period\n                 df_results.loc[trade_entry_index:current_dt, 'Position'] = 0\n                 df_results.loc[current_dt, 'Exit_Price'] = exit_price\n                 df_results.loc[current_dt, 'Trade_Return'] = trade_return * 100\n\n                 # Reset position state\n                 in_position = 0\n                 sl_level = None\n                 tp_level = None\n                 trade_entry_index = None\n\n\n        # --- Process Exits (Only if NOT halted and IN a position) ---\n        exit_signal = 0 # 1: exit long, -1: exit short\n        exit_reason = None\n        exit_price = current_price # Default exit price\n\n        if in_position != 0 and not trading_halted:\n            # Determine price points for checks within the bar\n            check_price_sl = current_low if in_position == 1 else current_high\n            check_price_tp = current_high if in_position == 1 else current_low\n\n            # Check SL first (using High/Low for intra-bar check)\n            if sl_level is not None:\n                 if (in_position == 1 and check_price_sl <= sl_level) or \\\n                    (in_position == -1 and check_price_sl >= sl_level):\n                    exit_signal = -in_position # Signal to exit the current position type\n                    exit_reason = \"SL\"\n                    exit_price = sl_level # Assume SL filled at SL price\n\n            # Check TP (only if SL not hit)\n            if exit_signal == 0 and tp_level is not None:\n                if (in_position == 1 and check_price_tp >= tp_level) or \\\n                   (in_position == -1 and check_price_tp <= tp_level):\n                    exit_signal = -in_position\n                    exit_reason = \"TP\"\n                    exit_price = tp_level # Assume TP filled at TP price\n\n            # Check MA Cross Exit (if enabled and SL/TP not hit)\n            if exit_signal == 0 and config['exit_on_ma_cross']:\n                 mvrv_val = current_row['7d_mvrv']\n                 ma_val = current_row[ma_col]\n                 if (in_position == 1 and mvrv_val < ma_val) or \\\n                    (in_position == -1 and mvrv_val > ma_val):\n                      exit_signal = -in_position\n                      exit_reason = \"MA Cross\"\n                      exit_price = current_price # Exit at bar's close\n\n            # Check optional Z-Score Exit (if enabled and SL/TP/MA not hit)\n            if exit_signal == 0 and config['exit_on_zscore_extreme']:\n                 z_score = current_row.get('MVRV_Z_Score')\n                 z_thresh = config['zscore_extreme_threshold']\n                 if pd.notna(z_score):\n                     if (in_position == 1 and z_score > z_thresh) or \\\n                        (in_position == -1 and z_score < -z_thresh):\n                          exit_signal = -in_position\n                          exit_reason = \"Z-Score Extreme\"\n                          exit_price = current_price # Exit at bar's close\n\n            # Check optional Divergence Exit (Add logic here if needed)\n            # if exit_signal == 0 and config['exit_on_divergence']:\n            #      ... check divergence condition ...\n            #      exit_signal = -in_position\n            #      exit_reason = \"Divergence Exit\"\n            #      exit_price = current_price\n\n            # Process Exit If Triggered\n            if exit_signal != 0:\n                # Calculate PnL based on exit price\n                if in_position == 1: # Exiting long\n                    trade_return = (exit_price - entry_price) / entry_price\n                else: # Exiting short\n                    trade_return = (entry_price - exit_price) / entry_price\n\n                trade_pnl = current_equity * position_size_fraction * trade_return\n                current_equity += trade_pnl # Update equity immediately\n\n                # Log trade\n                trade_log.append({\n                    'entry_dt': trade_entry_index, 'exit_dt': current_dt,\n                    'entry_price': entry_price, 'exit_price': exit_price,\n                    'position_type': 'long' if in_position == 1 else 'short',\n                    'size_fraction': position_size_fraction,\n                    'return_pct': trade_return * 100, 'pnl': trade_pnl,\n                    'exit_reason': exit_reason, 'sl_level': sl_level, 'tp_level': tp_level\n                })\n\n                # Update DataFrame state for this trade\n                df_results.loc[trade_entry_index:current_dt, 'Position'] = 0 # Mark period as flat\n                df_results.loc[current_dt, 'Exit_Price'] = exit_price\n                df_results.loc[current_dt, 'Trade_Return'] = trade_return * 100 # Store trade return at exit bar\n\n                # Reset state\n                in_position = 0\n                sl_level = None\n                tp_level = None\n                trade_entry_index = None\n\n\n        # --- Process Entries (Only if flat and NOT halted) ---\n        entry_signal = current_row['Signal']\n        if in_position == 0 and entry_signal != 0 and not trading_halted:\n            # Attempt to enter a trade\n            entry_price = current_price # Assume entry at current bar's close (can use Open[i+1] for next bar entry)\n            position_type = 'long' if entry_signal == 1 else 'short'\n\n            # Calculate position size (CRITICAL: review implementation in risk.py)\n            position_size_fraction = calculate_position_size(current_equity, config, current_row)\n\n            # Calculate SL/TP based on entry price and current row's indicators (e.g., ATR)\n            sl_level, tp_level = calculate_sl_tp(entry_price, entry_signal, config, current_row)\n\n            # Check if stops are required but couldn't be calculated\n            stops_required = config['use_volatility_stops'] or config['use_mvrv_stops']\n            stops_calculated = sl_level is not None or tp_level is not None # At least one stop needed if required\n\n            if stops_required and not stops_calculated:\n                 print(f\"Warning: Could not calculate required SL/TP for signal at {current_dt}. Skipping entry.\")\n            else:\n                # Enter position\n                in_position = entry_signal\n                trade_entry_index = current_dt # Log entry time\n\n                # Update DataFrame state for the new trade\n                df_results.loc[current_dt, 'Position'] = in_position\n                df_results.loc[current_dt, 'Entry_Price'] = entry_price\n                df_results.loc[current_dt, 'SL_Level'] = sl_level\n                df_results.loc[current_dt, 'TP_Level'] = tp_level\n\n                sl_str = f\"{sl_level:.2f}\" if sl_level else \"None\"\n                tp_str = f\"{tp_level:.2f}\" if tp_level else \"None\"\n                print(f\"{current_dt}: Enter {position_type} @ {entry_price:.2f} | Size: {position_size_fraction:.2f} | SL: {sl_str} | TP: {tp_str}\")\n\n\n        # --- Propagate State for Bars Held Within a Trade ---\n        # Update position, entry, SL/TP for bars where the position is held open\n        if in_position != 0 and trade_entry_index is not None:\n             # Ensure we don't overwrite the entry bar's info if i == entry_loc\n             entry_loc = df_results.index.get_loc(trade_entry_index)\n             if i > entry_loc:\n                 df_results['Position'].iloc[i] = in_position\n                 df_results['Entry_Price'].iloc[i] = entry_price # Carry forward for reference\n                 df_results['SL_Level'].iloc[i] = sl_level       # Carry forward SL\n                 df_results['TP_Level'].iloc[i] = tp_level       # Carry forward TP\n\n\n    print(\"Backtest simulation finished.\")\n    # Convert trade log to DataFrame for easier analysis\n    trades_df = pd.DataFrame(trade_log)\n    if not trades_df.empty:\n         trades_df['entry_dt'] = pd.to_datetime(trades_df['entry_dt'])\n         trades_df['exit_dt'] = pd.to_datetime(trades_df['exit_dt'])\n         trades_df = trades_df.set_index('entry_dt', drop=False) # Optional: Index by entry time\n\n    return df_results, trades_df\n```\n\n```python\n# --- File: metrics.py ---\n\"\"\"\nCalculates performance metrics from backtest results.\n\"\"\"\nimport pandas as pd\nimport numpy as np\nimport math\nfrom typing import Dict, Any\n\ndef calculate_metrics(df_results: pd.DataFrame, trades_df: pd.DataFrame, config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Calculates performance metrics for the backtest.\"\"\"\n    print(\"Calculating performance metrics...\")\n    metrics = {}\n\n    initial_capital = config['initial_capital']\n    final_equity = df_results['Equity'].iloc[-1]\n\n    metrics['Initial Capital'] = initial_capital\n    metrics['Final Equity'] = final_equity\n    metrics['Total Return (%)'] = (final_equity / initial_capital - 1) * 100 if initial_capital > 0 else 0\n\n    # Time-based metrics\n    start_date = df_results.index.min()\n    end_date = df_results.index.max()\n    duration_days = (end_date - start_date).days\n    duration_years = duration_days / 365.25\n    metrics['Start Date'] = start_date.strftime('%Y-%m-%d %H:%M')\n    metrics['End Date'] = end_date.strftime('%Y-%m-%d %H:%M')\n    metrics['Duration (Years)'] = duration_years\n\n    if duration_years > 0 and metrics['Total Return (%)'] is not None:\n         # Calculate CAGR using Decimal for precision if needed, simple float here\n         total_return_factor = 1 + metrics['Total Return (%)'] / 100\n         # Handle potential negative returns correctly for CAGR calculation\n         if total_return_factor > 0:\n             metrics['Annualized Return (CAGR %)'] = (total_return_factor**(1 / duration_years) - 1) * 100\n         else:\n              metrics['Annualized Return (CAGR %)'] = -100.0 # Total loss\n    else:\n        metrics['Annualized Return (CAGR %)'] = 0\n\n    # Drawdown metrics\n    metrics['Max Drawdown (%)'] = df_results['Drawdown'].max() # Already stored as %\n    max_dd_date = df_results['Drawdown'].idxmax()\n    metrics['Max Drawdown Date'] = max_dd_date.strftime('%Y-%m-%d %H:%M') if pd.notna(max_dd_date) else \"N/A\"\n\n    # Calculate Calmar Ratio (Annualized Return / Max Drawdown)\n    if metrics['Max Drawdown (%)'] is not None and metrics['Max Drawdown (%)'] > 0:\n         metrics['Calmar Ratio'] = metrics['Annualized Return (CAGR %)'] / metrics['Max Drawdown (%)']\n    else:\n         metrics['Calmar Ratio'] = np.inf if metrics['Annualized Return (CAGR %)'] > 0 else 0.0\n\n\n    # Trade metrics\n    num_trades = len(trades_df)\n    metrics['Total Trades'] = num_trades\n\n    if num_trades > 0:\n        metrics['Wins'] = len(trades_df[trades_df['return_pct'] > 0])\n        metrics['Losses'] = len(trades_df[trades_df['return_pct'] <= 0]) # Include breakeven as loss\n        metrics['Win Rate (%)'] = (metrics['Wins'] / num_trades) * 100 if num_trades > 0 else 0\n        metrics['Avg Trade Return (%)'] = trades_df['return_pct'].mean()\n        metrics['Avg Win (%)'] = trades_df.loc[trades_df['return_pct'] > 0, 'return_pct'].mean()\n        metrics['Avg Loss (%)'] = trades_df.loc[trades_df['return_pct'] <= 0, 'return_pct'].mean()\n\n        # Profit Factor\n        total_gross_profit = trades_df.loc[trades_df['return_pct'] > 0, 'pnl'].sum()\n        total_gross_loss = abs(trades_df.loc[trades_df['return_pct'] <= 0, 'pnl'].sum())\n        metrics['Profit Factor'] = total_gross_profit / total_gross_loss if total_gross_loss > 0 else np.inf\n\n        # Sharpe & Sortino Ratios (Annualized, using interval returns)\n        interval_returns = df_results['Equity'].pct_change().dropna()\n        if len(interval_returns) > 1: # Need at least 2 returns for std dev\n             avg_interval_return = interval_returns.mean()\n             std_interval_return = interval_returns.std()\n\n             annualization_factor = config.get('annualization_factor', math.sqrt(252)) # Use pre-calculated factor\n\n             # Sharpe Ratio\n             if std_interval_return > 1e-9:\n                 sharpe_ratio = (avg_interval_return * config['intervals_per_year'] - config['risk_free_rate']) / (std_interval_return * annualization_factor + 1e-9)\n                 metrics['Annualized Sharpe Ratio'] = sharpe_ratio\n             else:\n                 metrics['Annualized Sharpe Ratio'] = 0.0\n\n             # Sortino Ratio\n             negative_returns = interval_returns[interval_returns < 0]\n             if len(negative_returns) > 1: # Need at least 2 negative returns for downside std dev\n                 downside_std = negative_returns.std()\n                 if downside_std > 1e-9:\n                     sortino_ratio = (avg_interval_return * config['intervals_per_year'] - config['risk_free_rate']) / (downside_std * annualization_factor + 1e-9)\n                     metrics['Annualized Sortino Ratio'] = sortino_ratio\n                 else:\n                     metrics['Annualized Sortino Ratio'] = np.inf # No downside deviation\n             else:\n                 metrics['Annualized Sortino Ratio'] = np.inf # No downside deviation (or only 1)\n        else:\n            metrics['Annualized Sharpe Ratio'] = 0.0\n            metrics['Annualized Sortino Ratio'] = 0.0\n\n    else:\n        # Default values if no trades\n        metrics.update({\n            'Wins': 0, 'Losses': 0, 'Win Rate (%)': 0, 'Avg Trade Return (%)': 0,\n            'Avg Win (%)': 0, 'Avg Loss (%)': 0, 'Profit Factor': 0,\n            'Annualized Sharpe Ratio': 0, 'Annualized Sortino Ratio': 0, 'Calmar Ratio': 0\n        })\n\n    # Add active features to metrics summary\n    active_features = []\n    if config['use_dynamic_thresholds']: active_features.append(\"Dyn Thresh\")\n    if config['use_regime_adjustment']: active_features.append(\"Regime Adj\")\n    if config['use_mvrv_rsi']: active_features.append(\"MVRV RSI\")\n    if config['use_adaptive_position']: active_features.append(\"Adapt Pos (Placeholder)\")\n    if config['use_dynamic_ma']: active_features.append(\"Dyn MA (Placeholder)\")\n    if config['use_volatility_stops']: active_features.append(\"ATR Stops\")\n    if config['use_mvrv_stops']: active_features.append(\"MVRV Stops\")\n    if config['exit_on_zscore_extreme']: active_features.append(\"Z-Score Exit\")\n    if config['exit_on_divergence']: active_features.append(\"Div Exit\")\n    if config['exit_on_ma_cross']: active_features.append(\"MA Cross Exit\")\n    metrics['Active Features'] = \", \".join(active_features) if active_features else \"Base (Static Thresh, No Stops/Filters)\"\n\n    print(\"Metrics calculation complete.\")\n    return metrics\n\n```\n\n```python\n# --- File: plotting.py ---\n\"\"\"\nPlotting functions for visualizing backtest results.\n\"\"\"\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom typing import Dict, Any\n\ndef plot_results(df_results: pd.DataFrame, trades_df: pd.DataFrame, metrics: Dict[str, Any], config: Dict[str, Any]):\n    \"\"\"Plots the equity curve, drawdown, signals, and indicators.\"\"\"\n    print(\"Generating plots...\")\n\n    num_plots = 4 # Default plots\n    # Conditionally add plots based on data/config\n    plot_mvrv_rsi = config['use_mvrv_rsi'] and 'MVRV_RSI' in df_results.columns\n    plot_z_score = 'MVRV_Z_Score' in df_results.columns\n\n    if plot_mvrv_rsi: num_plots += 1\n    if plot_z_score: num_plots +=1\n\n    fig, axes = plt.subplots(num_plots, 1, figsize=(16, 5 * num_plots), sharex=True,\n                              gridspec_kw={'height_ratios': [3, 1, 2, 2] + ([1] * (num_plots - 4))})\n    # Ensure axes is always a list/array even if num_plots=1\n    if num_plots == 1: axes = [axes]\n\n    fig.suptitle(f\"Dynamic MVRV Strategy Backtest Results\\n({metrics.get('Active Features', 'N/A')})\", fontsize=16)\n    plot_idx = 0\n\n    # --- 1. Equity Curve and Drawdown ---\n    ax1 = axes[plot_idx]\n    ax1b = ax1.twinx() # For drawdown\n    ax1.set_title('Equity Curve & Drawdown')\n\n    ax1.plot(df_results.index, df_results['Equity'], label='Equity Curve', color='blue', linewidth=2)\n    ax1.set_ylabel('Equity ($)', color='blue')\n    ax1.tick_params(axis='y', labelcolor='blue')\n    ax1.grid(True, axis='y', linestyle='--', alpha=0.7)\n\n    ax1b.plot(df_results.index, -df_results['Drawdown'], label='Drawdown (%)', color='red', linestyle=':', linewidth=1.5)\n    ax1b.fill_between(df_results.index, -df_results['Drawdown'], 0, color='red', alpha=0.2)\n    ax1b.set_ylabel('Drawdown (%)', color='red')\n    ax1b.tick_params(axis='y', labelcolor='red')\n    max_dd_val = metrics.get('Max Drawdown (%)', 100)\n    ax1b.set_ylim(bottom=min(-100, -max_dd_val * 1.2))\n\n    # Highlight Halted Periods\n    halted = df_results[df_results['Trading_Halted']]\n    if not halted.empty:\n        # Find start/end blocks of halted periods\n        halt_starts = halted.index[halted['Trading_Halted'] & ~halted['Trading_Halted'].shift(1).fillna(False)]\n        halt_ends = halted.index[halted['Trading_Halted'] & ~halted['Trading_Halted'].shift(-1).fillna(False)]\n        # Ensure equal length\n        min_len = min(len(halt_starts), len(halt_ends))\n        for start, end in zip(halt_starts[:min_len], halt_ends[:min_len]):\n             ax1.axvspan(start, end, color='grey', alpha=0.3, label='_nolegend_') # Use _nolegend_ if adding label in loop\n        # Add a single legend entry\n        if not halt_starts.empty:\n            ax1.axvspan(halt_starts[0], halt_starts[0], color='grey', alpha=0.3, label='Trading Halted')\n\n\n    # Combine legends\n    lines, labels = ax1.get_legend_handles_labels()\n    lines2, labels2 = ax1b.get_legend_handles_labels()\n    # Add halted label if present\n    halt_handles, halt_labels = [], []\n    for handle in ax1.get_legend().legendHandles:\n         if handle.get_label() == 'Trading Halted':\n              halt_handles.append(handle)\n              halt_labels.append('Trading Halted')\n              break # Only need one entry\n    ax1b.legend(lines + lines2 + halt_handles, labels + labels2 + halt_labels, loc='upper left')\n    plot_idx += 1\n\n\n    # --- 2. Price Chart and Trades ---\n    ax2 = axes[plot_idx]\n    ax2.set_title('Price and Trades')\n    ax2.plot(df_results.index, df_results['Price'], label='Price', color='black', alpha=0.8, linewidth=1)\n    ax2.set_ylabel('Price ($)')\n\n    if not trades_df.empty:\n         long_wins = trades_df[(trades_df['position_type'] == 'long') & (trades_df['return_pct'] > 0)]\n         long_losses = trades_df[(trades_df['position_type'] == 'long') & (trades_df['return_pct'] <= 0)]\n         short_wins = trades_df[(trades_df['position_type'] == 'short') & (trades_df['return_pct'] > 0)]\n         short_losses = trades_df[(trades_df['position_type'] == 'short') & (trades_df['return_pct'] <= 0)]\n\n         # Plot entry markers\n         ax2.scatter(long_wins['entry_dt'], long_wins['entry_price'], marker='^', color='lime', s=80, label='Long Win Entry', edgecolors='black', zorder=5)\n         ax2.scatter(long_losses['entry_dt'], long_losses['entry_price'], marker='^', color='red', s=80, label='Long Loss Entry', edgecolors='black', zorder=5)\n         ax2.scatter(short_wins['entry_dt'], short_wins['entry_price'], marker='v', color='lime', s=80, label='Short Win Entry', edgecolors='black', zorder=5)\n         ax2.scatter(short_losses['entry_dt'], short_losses['entry_price'], marker='v', color='red', s=80, label='Short Loss Entry', edgecolors='black', zorder=5)\n\n         # Plot exit markers (can be less prominent)\n         # ax2.scatter(trades_df['exit_dt'], trades_df['exit_price'], marker='o', color='grey', s=30, label='Exit', zorder=4)\n\n         # Plot lines connecting entry/exit for each trade\n         for _, trade in trades_df.iterrows():\n             color = 'green' if trade['return_pct'] > 0 else 'red'\n             ax2.plot([trade['entry_dt'], trade['exit_dt']], [trade['entry_price'], trade['exit_price']],\n                      color=color, linestyle='--', linewidth=0.8, alpha=0.7, zorder=3)\n\n    ax2.legend(fontsize='small', loc='upper left')\n    ax2.grid(True, axis='y', linestyle='--', alpha=0.5)\n    plot_idx += 1\n\n    # --- 3. MVRV Indicator ---\n    ax3 = axes[plot_idx]\n    ax3.set_title('MVRV Indicator and Thresholds')\n    ax3.plot(df_results.index, df_results['7d_mvrv'], label='7d MVRV', color='purple', linewidth=1.5)\n    ma_col = 'MVRV_Adaptive_MA' if config['use_dynamic_ma'] else 'MVRV_MA'\n    ax3.plot(df_results.index, df_results[ma_col], label=f'{ma_col}', color='orange', linestyle='--', linewidth=1)\n    ax3.plot(df_results.index, df_results['Positive_Threshold'], label='Upper Threshold', color='red', linestyle=':', alpha=0.8)\n    ax3.plot(df_results.index, df_results['Negative_Threshold'], label='Lower Threshold', color='green', linestyle=':', alpha=0.8)\n    ax3.axhline(0, color='grey', linestyle='-', linewidth=0.5)\n    ax3.set_ylabel('MVRV Value')\n    ax3.legend(fontsize='small', loc='upper left')\n    ax3.grid(True, axis='y', linestyle='--', alpha=0.5)\n    plot_idx += 1\n\n\n    # --- 4. MVRV Z-Score ---\n    if plot_z_score:\n        ax_z = axes[plot_idx]\n        ax_z.set_title('MVRV Z-Score')\n        ax_z.plot(df_results.index, df_results['MVRV_Z_Score'], label='MVRV Z-Score', color='teal', linewidth=1)\n        z_thresh = config.get('zscore_extreme_threshold', 2.0)\n        ax_z.axhline(z_thresh, color='red', linestyle=':', alpha=0.5, label=f'Z-Score Extreme ({z_thresh:.1f})')\n        ax_z.axhline(-z_thresh, color='red', linestyle=':', alpha=0.5)\n        ax_z.axhline(0, color='grey', linestyle='-', linewidth=0.5)\n        ax_z.set_ylabel('Z-Score')\n        ax_z.legend(fontsize='small', loc='upper left')\n        ax_z.grid(True, axis='y', linestyle='--', alpha=0.5)\n        plot_idx += 1\n\n    # --- 5. MVRV RSI ---\n    if plot_mvrv_rsi:\n        ax_rsi = axes[plot_idx]\n        ax_rsi.set_title('MVRV RSI')\n        ax_rsi.plot(df_results.index, df_results['MVRV_RSI'], label='MVRV RSI', color='magenta', linewidth=1)\n        rsi_buy_thresh = config['mvrv_rsi_buy_threshold']\n        rsi_sell_thresh = config['mvrv_rsi_sell_threshold']\n        ax_rsi.axhline(rsi_sell_thresh, color='red', linestyle=':', alpha=0.5, label=f'RSI Sell Thresh ({rsi_sell_thresh:.0f})')\n        ax_rsi.axhline(rsi_buy_thresh, color='green', linestyle=':', alpha=0.5, label=f'RSI Buy Thresh ({rsi_buy_thresh:.0f})')\n        ax_rsi.axhline(50, color='grey', linestyle='-', linewidth=0.5)\n        ax_rsi.set_ylabel('RSI')\n        ax_rsi.legend(fontsize='small', loc='upper left')\n        ax_rsi.grid(True, axis='y', linestyle='--', alpha=0.5)\n        plot_idx += 1\n\n\n    # --- Final Formatting ---\n    axes[-1].set_xlabel('Date') # Set xlabel only on the last plot\n    # Improve date formatting on x-axis\n    for ax in axes:\n        ax.xaxis.set_major_locator(mdates.AutoDateLocator(minticks=5, maxticks=12))\n        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n        plt.setp(ax.xaxis.get_majorticklabels(), rotation=30, ha='right')\n\n    plt.tight_layout(rect=[0, 0.03, 1, 0.96]) # Adjust layout\n    plt.show()\n    print(\"Plots generated.\")\n\n```\n\n```python\n# --- File: main.py ---\n\"\"\"\nMain execution script for the Dynamic MVRV Strategy backtest.\n\"\"\"\nimport pandas as pd\nimport numpy as np\nimport random\nimport warnings\n\n# Import strategy components\nfrom config import CONFIG\nfrom data_loader import load_and_preprocess_data\nfrom indicators import calculate_indicators\nfrom signals import generate_signals\nfrom backtest import run_backtest\nfrom metrics import calculate_metrics\nfrom plotting import plot_results\n\ndef main():\n    \"\"\"Main function to run the strategy workflow.\"\"\"\n    # Set seed for reproducibility (Uncomment if needed)\n    # np.random.seed(CONFIG['random_seed'])\n    # random.seed(CONFIG['random_seed'])\n\n    print(\"--- Starting Dynamic MVRV Strategy Backtest ---\")\n\n    try:\n        # 1. Load Configuration\n        cfg = CONFIG\n        active_features_str = calculate_metrics(pd.DataFrame(), pd.DataFrame(), cfg)['Active Features'] # Hacky way to get feature string\n        print(f\"Configuration loaded: {active_features_str} features active.\")\n        if cfg['position_sizing_fraction'] > 0.1: # Check for risky default\n             warnings.warn(f\"CRITICAL RISK: 'position_sizing_fraction' is {cfg['position_sizing_fraction']:.2f} ( > 10%). Modify risk.py or config.py before production.\", UserWarning)\n\n\n        # 2. Load Data\n        df_raw = load_and_preprocess_data(cfg)\n\n        # 3. Calculate Indicators\n        df_indicators = calculate_indicators(df_raw, cfg)\n\n        # 4. Generate Signals\n        df_signals = generate_signals(df_indicators, cfg)\n\n        # 5. Run Backtest (includes risk management)\n        df_results, trades_df = run_backtest(df_signals, cfg)\n\n        # 6. Calculate Metrics\n        metrics = calculate_metrics(df_results, trades_df, cfg)\n\n        # 7. Output Results Summary\n        print(\"\\n--- Backtest Performance Metrics ---\")\n        for key, value in metrics.items():\n            if isinstance(value, float):\n                # Format percentages and ratios nicely\n                if \" (%)\" in key or \"Rate\" in key or \"Factor\" in key or \"Ratio\" in key:\n                     print(f\"{key:<28}: {value:.2f}\")\n                else:\n                     print(f\"{key:<28}: {value:,.2f}\") # Format currency/equity\n            else:\n                print(f\"{key:<28}: {value}\")\n        print(\"------------------------------------\")\n\n        # Print Trade Log Summary\n        if not trades_df.empty:\n            print(\"\\n--- Trade Log Summary ---\")\n            print(f\"Total Trades: {len(trades_df)}\")\n            print(f\"Exit Reasons:\\n{trades_df['exit_reason'].value_counts().to_string()}\")\n            # print(trades_df[['exit_dt', 'position_type', 'return_pct', 'pnl', 'exit_reason']].head()) # Example columns\n            print(\"-------------------------\")\n        else:\n             print(\"\\n--- No trades executed ---\")\n\n\n        # 8. Plot Results\n        if cfg['plot_results'] and not df_results.empty:\n             plot_results(df_results, trades_df, metrics, cfg)\n\n    except (FileNotFoundError, ValueError, KeyError, IndexError) as e: # Added IndexError\n        print(f\"\\n--- STRATEGY EXECUTION ERROR ---\")\n        print(f\"An error occurred: {e}\")\n        print(\"Please check the configuration, data file integrity, and logic (e.g., sufficient data for lookbacks).\")\n        print(\"----------------------------------\")\n        # Optionally re-raise for debugging\n        # raise e\n    except Exception as e:\n         print(f\"\\n--- UNEXPECTED SYSTEM ERROR ---\")\n         print(f\"An unexpected error occurred: {type(e).__name__}: {e}\")\n         import traceback\n         traceback.print_exc()\n         print(\"-----------------------------\")\n\n\n    print(\"\\n--- Backtest Workflow Finished ---\")\n\n\nif __name__ == \"__main__\":\n    main()\n\n```\n\n```markdown\n# --- File: README.md ---\n\n# Dynamic MVRV Trading Strategy\n\n## Overview\n\nThis package implements and backtests a trading strategy based on Bitcoin's Market Value to Realized Value (MVRV) ratio, specifically the 7-day MVRV Z-Score and its relationship to a moving average. The strategy aims to identify potential undervaluation (buy signals) and overvaluation (sell signals) zones.\n\nIt includes configurable features such as:\n*   Dynamic vs. Static MVRV thresholds\n*   Market regime adjustments (experimental)\n*   MVRV RSI filtering (experimental)\n*   ATR-based volatility stops (Stop Loss / Take Profit)\n*   A hard drawdown limit for risk management.\n\n**Disclaimer:** This is for educational and research purposes only. Trading cryptocurrencies involves significant risk. Do not use this strategy with real capital without thorough validation, understanding, and adaptation to your own risk tolerance.\n\n## Structure\n\n*   `config.py`: Contains all strategy hyperparameters and settings.\n*   `data_loader.py`: Handles loading and preprocessing of CSV data.\n*   `indicators.py`: Calculates MVRV-based and technical indicators (ATR, RSI, etc.).\n*   `signals.py`: Generates entry signals based on indicator conditions.\n*   `risk.py`: Implements position sizing (CRITICAL: Review default!) and SL/TP calculations.\n*   `backtest.py`: Runs the event-driven backtest simulation loop.\n*   `metrics.py`: Calculates performance statistics (Sharpe, Sortino, Drawdown, etc.).\n*   `plotting.py`: Visualizes the equity curve, trades, and indicators.\n*   `main.py`: The main script to execute the backtest workflow.\n*   `requirements.txt`: Lists necessary Python packages and their versions.\n*   `tests/`: (Placeholder) Directory intended for unit tests. **CRITICAL: TESTS NEED TO BE IMPLEMENTED.**\n\n## Setup\n\n1.  **Clone the repository:**\n    ```bash\n    git clone <repository-url>\n    cd <repository-directory>\n    ```\n2.  **Create a virtual environment (recommended):**\n    ```bash\n    python -m venv venv\n    source venv/bin/activate  # On Windows use `venv\\Scripts\\activate`\n    ```\n3.  **Install dependencies:**\n    ```bash\n    pip install -r requirements.txt\n    ```\n4.  **Prepare Data:**\n    *   Obtain 5-minute Bitcoin OHLCV data including a `7d_mvrv` column (or adjust column names in `config.py`).\n    *   Ensure the data has a `timestamp` column (Unix seconds/milliseconds or standard datetime format).\n    *   Save the data as a CSV file.\n5.  **Configure:**\n    *   **CRITICAL:** Open `config.py` and update `\"csv_path\"` to point to your data file.\n    *   **CRITICAL:** Review the `\"position_sizing_fraction\"` in `config.py` or `risk.py`. The default of `1.0` (100% equity) is extremely risky and **must** be lowered for any realistic simulation or use. A value between 0.01 (1%) and 0.05 (5%) is more conventional.\n    *   Adjust other parameters like date ranges, feature flags (`use_...`), indicator periods, and risk settings as needed.\n\n## Usage\n\nRun the main script from the terminal:\n\n```bash\npython main.py\n```\n\nThe script will:\n1.  Load and preprocess the data according to the configuration.\n2.  Calculate indicators.\n3.  Generate trading signals.\n4.  Execute the backtest simulation.\n5.  Calculate and print performance metrics.\n6.  Display plots visualizing the results (if `plot_results` is `True` in `config.py`).\n\n## Development & Testing\n\n**Unit tests are currently missing and are essential for validating the strategy's correctness and robustness.** A `tests/` directory should be created containing test files (e.g., `test_indicators.py`, `test_risk.py`, `test_backtest.py`) using a framework like `pytest`.\n\n**Example Test Areas (Not Implemented):**\n*   Verification of look-ahead bias prevention in all indicators.\n*   Correct calculation of ATR, Z-Score, RSI.\n*   Correct SL/TP level calculation for both long/short trades under different configurations (ATR vs MVRV stops, regime adjustments).\n*   Validation that the drawdown halt triggers correctly and forces exits.\n*   Validation that trading resumes after drawdown recovery.\n*   Correct calculation of Sharpe, Sortino, and other metrics given known inputs.\n*   Edge case handling in data loading (missing columns, bad data, duplicates).\n\n```\n\n```text\n# --- File: requirements.txt ---\n# CRITICAL: Generate this file based on the actual environment used.\n# Example:\n# pandas==2.1.4\n# numpy==1.26.3\n# matplotlib==3.8.2\n\n# To generate automatically (after installing packages):\n# pip freeze > requirements.txt\n```\n\n```text\n# --- Directory: tests/ ---\n# (Empty - Needs Test Implementation Files)\n# Example files to create:\n# __init__.py (can be empty)\n# test_data_loader.py\n# test_indicators.py\n# test_risk.py\n# test_backtest.py\n# test_metrics.py\n```"
        }
      }
    ],
    "Edit Fields2": [
      {
        "json": {
          "output": "Okay, StrategyIntegrator is initiating the end-to-end verification process.\n\n**Ingesting Inputs:**\n\n1.  **QuantAI Design Doc (Implicit):** Requirements derived from the user prompt describing QuantAI's recommended improvements: fix look-forward bias, correct Z-score window (365 days / 105,120 5-min intervals), simplify exits, add 10% drawdown halt, correct Sharpe annualization (sqrt(105,120)), add ATR SL/TP, improve position sizing. Includes flags for dynamic features.\n2.  **PyStrategist Python Code:** Received the `dynamic_mvrv_strategy.py` script containing configuration, data loading, indicator calculations, signal generation, risk management (including drawdown logic, SL/TP calculation), backtesting engine, metrics, and plotting, structured into functions.\n3.  **StrategyAuditor Audit Report:** Received report highlighting key issues, with Top 3 being: Look-ahead bias in ATR, Extreme risk in default position sizing (100%), Drawdown halt logic timing flaw.\n\n**Performing Core Responsibilities:**\n\n1.  **Alignment Check:** Verifying design requirements against PyStrategist code.\n2.  **Audit Resolution:** Checking if PyStrategist code addresses StrategyAuditor's high-severity findings.\n3.  **Consistency Validation:** Checking names, parameters across code and config.\n4.  **End-to-End Test Verification:** Assessing test presence and coverage (based on PyStrategist notes).\n5.  **Production Readiness:** Checking PEP8 (visually), docstrings/hints, performance notes, error handling, reproducibility elements.\n\n---\n\n## A. Alignment Matrix Report\n\n| Requirement                     | File:Function/Section             | Status   | Notes                                                                                                                                                              |\n| :------------------------------ | :-------------------------------- | :------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Fix Look-forward Bias (General) | `calculate_indicators`            | âœ…        | `.shift(1)` applied systematically before rolling calculations (MA, Vol, Z-Score, ROC, Divergence, Trend Str, RSI, ATR).                                               |\n| Look-forward Bias (ATR)         | `calculate_indicators`            | âœ…        | ATR's TR calculation uses `Close.shift(1)`. Final ATR series is also shifted `.shift(1)`. **Resolves Audit Finding #1.**                                         |\n| Z-Score Window (365d / 105k)    | `calculate_indicators`, `CONFIG`  | âœ…        | `intervals_per_year` = 105120, `z_score_lookback_years` used correctly, lookback capped by data length.                                                            |\n| Simplified Exit Logic           | `run_backtest`                    | âœ…        | Prioritizes SL/TP, then optional configurable exits (MA Cross, Z-Score). Clear structure.                                                                          |\n| Hard 10% Drawdown Halt          | `run_backtest`, `CONFIG`          | âœ…        | `max_drawdown_pct`=10.0 used. Check occurs *before* bar processing, based on prior equity. Force exit implemented if halted while in position. **Resolves Audit Finding #3.** |\n| Sharpe Annualization (âˆš105,120) | `calculate_metrics`, `CONFIG`     | âœ…        | Uses `math.sqrt(config['intervals_per_year'])` with `intervals_per_year`=105120. Applied to std dev of interval returns.                                          |\n| Volatility (ATR) SL/TP          | `calculate_sl_tp`, `CONFIG`       | âœ…        | `use_volatility_stops` flag triggers ATR-based calculation using configured multipliers. Integrated into backtest.                                                 |\n| Position Sizing Logic           | `calculate_position_size`         | âš ï¸        | Function exists, `use_adaptive_position` flag exists but logic is placeholder. **Default still 1.0 (100% equity), Audit Finding #2 NOT fully resolved.**        |\n| Dynamic Thresholds Option       | `calculate_indicators`, `CONFIG`  | âœ…        | `use_dynamic_thresholds` flag implemented correctly using shifted MA/Volatility.                                                                                   |\n| Regime Adjustment Option        | `calculate_indicators`, `CONFIG`  | âœ…        | `use_regime_adjustment` flag implemented, adjusts TP/SL factors based on MVRV trend.                                                                               |\n| MVRV RSI Option                 | `calculate_indicators`, `CONFIG`  | âœ…        | `use_mvrv_rsi` flag implemented, calculation shifted, used as optional signal filter.                                                                            |\n| Adaptive Position Size Option   | `calculate_position_size`, `CONFIG` | âœ…        | Flag `use_adaptive_position` is present as required, but logic is explicitly a placeholder.                                                                        |\n| Dynamic MA Option               | `calculate_indicators`, `CONFIG`  | âœ…        | Flag `use_dynamic_ma` is present as required, but logic is explicitly a placeholder with warning.                                                                    |\n| Consistency (Vars, Params)      | Entire script                     | âœ…        | Consistent naming (`df`, `config`, indicators). Config parameters used correctly.                                                                                  |\n| Docstrings / Type Hints         | Entire script                     | âœ…        | Generally well-documented with docstrings and type hints.                                                                                                          |\n| PEP8 Compliance                 | Entire script                     | âœ…        | Code structure and formatting appear compliant (visual inspection).                                                                                                |\n| Error Handling                  | `load_and_preprocess_data`, `main`| âœ…        | Basic file/value/key errors handled. Main execution wrapped in try/except.                                                                                         |\n| Reproducibility Elements        | `CONFIG`, `main`                  | âš ï¸        | `random_seed` present but commented out. Requires `requirements.txt` for version pinning.                                                                          |\n| Unit Test Coverage              | `main` (comment block)            | âŒ        | Placeholder comments exist, but **no actual unit tests** were provided or implemented by PyStrategist. Critical gap.                                               |\n\n---\n\n## B. Outstanding Issues\n\n1.  **CRITICAL: Default Position Sizing Risk:** The `calculate_position_size` function defaults to returning `1.0`, representing 100% equity allocation per trade. While the *option* for adaptive sizing exists (`use_adaptive_position`), its logic is only a placeholder. This retains the extreme risk highlighted by **Audit Finding #2**.\n    *   **Next Step:** Implement sensible default position sizing (e.g., fixed fractional 1-5% of equity, or volatility-based risk parity) OR complete the `use_adaptive_position` logic immediately. This must be addressed before production.\n2.  **CRITICAL: Missing Unit Tests:** The PyStrategist code includes comments listing potential unit tests but provides no implementation. Without tests, verifying correctness, preventing regressions, and ensuring reliability for production is impossible.\n    *   **Next Step:** Implement comprehensive unit tests covering data loading edge cases, indicator calculations (especially look-ahead prevention), signal logic, SL/TP calculation, drawdown halt mechanism, and metric calculations. Target critical functions like `calculate_indicators`, `calculate_sl_tp`, `run_backtest`, `calculate_metrics`.\n3.  **HIGH: Missing Requirements File:** No `requirements.txt` is provided, hindering reproducibility.\n    *   **Next Step:** Generate a `requirements.txt` file listing exact versions of pandas, numpy, matplotlib used.\n4.  **MEDIUM: Placeholder Logic:** The features `use_adaptive_position` and `use_dynamic_ma` are controlled by flags but lack functional implementation (as acknowledged by PyStrategist comments). If these flags are intended to be usable, the logic needs to be built.\n    *   **Next Step:** Implement the actual logic for these features or disable/remove the flags if they are not intended for use in the initial production version.\n5.  **LOW: Random Seed:** The `random_seed` in `CONFIG` is commented out. While the current logic seems deterministic, uncommenting it is good practice for future-proofing if any stochastic elements are added.\n    *   **Next Step:** Uncomment the seed lines in `main()` if reproducibility needs to be strictly enforced for potential future random elements.\n\n---\n\n## C. Final Verdict\n\n**Requires Action**\n\nThe strategy code structure is sound, incorporates many design requirements, and crucially addresses the look-ahead bias and drawdown halt timing issues identified by the auditor. However, **two critical gaps** prevent production readiness:\n\n1.  The default **100% position sizing** presents unacceptable risk (Audit Finding #2).\n2.  The complete **absence of unit tests** makes the code unverifiable and fragile.\n\nThese issues must be resolved before deployment.\n\n**Prioritized Tasks:**\n\n1.  **Implement Safe Position Sizing:** Modify `calculate_position_size` immediately.\n2.  **Develop Unit Tests:** Create a test suite covering critical logic.\n3.  **Generate `requirements.txt`:** Ensure dependency pinning.\n4.  **Address Placeholders:** Implement or remove non-functional feature flags (`use_adaptive_position`, `use_dynamic_ma`).\n5.  **Uncomment Random Seed:** Minor but good practice.\n\n---\n\n## D. Final Python Code Bundle\n\nThe following code reflects the verified state from PyStrategist, incorporating fixes for look-ahead bias and drawdown timing, but *still requires the actions listed above* (especially position sizing and unit tests) before being truly production-ready.\n\n```python\n# --- File: config.py ---\n\"\"\"\nConfiguration settings for the Dynamic MVRV Strategy.\n\"\"\"\nimport math\n\nCONFIG = {\n    # Data & General\n    \"csv_path\": \"path/to/your/btc_5min_data.csv\", # <--- USER: PLEASE UPDATE THIS PATH\n    \"start_date\": \"2020-01-01\", # Optional: Filter data >= start_date\n    \"end_date\": \"2023-12-31\",   # Optional: Filter data <= end_date\n    \"price_col\": \"Close\", # Column name for BTC price (usually 'Close' or 'Price')\n    \"mvrv_col\": \"7d_mvrv\", # Column name for 7-day MVRV\n    \"ohlc_cols\": [\"Open\", \"High\", \"Low\", \"Close\"], # Ensure these exist for ATR\n    \"volume_col\": \"Volume\", # Optional, not used in core logic yet\n    \"timestamp_col\": \"timestamp\", # Column name for timestamp\n\n    # MVRV Base Strategy\n    \"ma_period\": 30 * 12 * 24, # Default MA period (e.g., 30 days for 5-min data)\n    \"negative_quantile\": 0.25, # For static threshold calculation\n    \"positive_quantile\": 0.75, # For static threshold calculation\n\n    # Feature Flags (Enable/Disable Enhancements)\n    \"use_dynamic_thresholds\": True, # Use MVRV_MA +/- Volatility * factor\n    \"dynamic_threshold_factor\": 2.0, # Factor for dynamic thresholds\n    \"use_regime_adjustment\": False, # Adjust TP/SL based on MVRV trend\n    \"regime_ma_period_factor\": 1.0, # Multiplier for base ma_period for trend calc\n    \"regime_uptrend_tp_mult\": 1.5,\n    \"regime_uptrend_sl_mult\": 0.8,\n    \"regime_downtrend_tp_mult\": 0.8,\n    \"regime_downtrend_sl_mult\": 1.2,\n    \"use_mvrv_rsi\": False, # Use MVRV RSI for signal confirmation/filtering\n    \"mvrv_rsi_period\": 14 * 12 * 24, # e.g., 14 days for 5-min data\n    \"mvrv_rsi_buy_threshold\": 40.0,\n    \"mvrv_rsi_sell_threshold\": 60.0,\n    \"use_adaptive_position\": False, # Size positions based on conviction (PLACEHOLDER LOGIC)\n    \"use_dynamic_ma\": False, # Adapt MA period based on MVRV volatility (PLACEHOLDER LOGIC)\n    \"dynamic_ma_min_period\": 10 * 12 * 24, # e.g., 10 days\n    \"dynamic_ma_max_period\": 50 * 12 * 24, # e.g., 50 days\n\n    # Complementary Indicators Configuration\n    \"z_score_lookback_years\": 1, # Lookback for Z-score calculation (in years)\n    \"roc_period\": 7 * 12 * 24,   # Rate of Change period (e.g., 7 days)\n    \"divergence_norm_window\": 30 * 12 * 24, # Normalization window for divergence (e.g., 30 days)\n    \"divergence_lookback\": 5 * 12 * 24,     # Lookback period for detecting divergence (e.g., 5 days)\n    \"trend_strength_period\": 14 * 12 * 24, # Period for MVRV trend strength (e.g., 14 days)\n\n    # Risk Management\n    \"initial_capital\": 10000.0,\n    \"max_drawdown_pct\": 10.0, # Hard stop if equity drops this % from peak\n    \"drawdown_recovery_pct\": 5.0, # Resume trading if drawdown recovers to < this %\n    \"use_volatility_stops\": True, # Use ATR for SL/TP calculation\n    \"atr_period\": 14 * 12 * 24,  # ATR lookback period (e.g., 14 days)\n    \"atr_tp_multiplier\": 3.0, # Take Profit = entry +/- ATR * multiplier\n    \"atr_sl_multiplier\": 1.5, # Stop Loss = entry -/+ ATR * multiplier\n    \"use_mvrv_stops\": False, # Alternative: Use MVRV distance for SL/TP (Requires careful calibration)\n    \"mvrv_tp_factor\": 1.0, # Multiplier for MVRV distance proxy for TP\n    \"mvrv_sl_factor\": 0.5, # Multiplier for MVRV distance proxy for SL\n\n    # Position Sizing (CRITICAL: Needs review/modification)\n    \"position_sizing_fraction\": 1.0, # Default fraction of equity to risk (1.0 = 100%, VERY HIGH RISK)\n\n    # Exit Logic Configuration\n    \"exit_on_zscore_extreme\": False, # Exit if MVRV Z-score becomes extreme\n    \"zscore_extreme_threshold\": 2.0,\n    \"exit_on_divergence\": False, # Exit if adverse divergence forms after entry\n    \"exit_on_ma_cross\": True, # Original core exit logic (MVRV crosses back over MA)\n\n    # Backtest & Metrics\n    \"intervals_per_year\": (60 // 5) * 24 * 365, # 105,120 for 5-min data (24/7 crypto)\n    \"risk_free_rate\": 0.0, # For Sharpe/Sortino calculation\n\n    # Plotting\n    \"plot_results\": True,\n    \"plot_equity\": True,\n\n    # Reproducibility\n    \"random_seed\": 42,\n}\n\n# Calculate intervals per year for easier access\nCONFIG['intervals_per_year'] = (60 // 5) * 24 * 365\nCONFIG['annualization_factor'] = math.sqrt(CONFIG['intervals_per_year'])\n\n```\n\n```python\n# --- File: data_loader.py ---\n\"\"\"\nData loading and preprocessing functionality.\n\"\"\"\nimport pandas as pd\nfrom typing import Dict, Any\n\n# Suppress pandas SettingWithCopyWarning (use with caution)\npd.options.mode.chained_assignment = None  # default='warn'\n\ndef load_and_preprocess_data(config: Dict[str, Any]) -> pd.DataFrame:\n    \"\"\"Loads data from CSV, validates, converts timestamp, and filters dates.\"\"\"\n    print(f\"Loading data from: {config['csv_path']}\")\n    try:\n        df = pd.read_csv(config['csv_path'])\n    except FileNotFoundError:\n        print(f\"ERROR: CSV file not found at {config['csv_path']}\")\n        print(\"Please update the 'csv_path' in the CONFIG dictionary.\")\n        raise\n\n    print(f\"Initial data shape: {df.shape}\")\n\n    # --- Validation ---\n    ts_col = config['timestamp_col']\n    price_col = config['price_col']\n    mvrv_col = config['mvrv_col']\n    required_cols = [ts_col, price_col, mvrv_col]\n    if config['use_volatility_stops']:\n        required_cols.extend(config['ohlc_cols']) # Need OHLC for ATR\n\n    missing_cols = [col for col in required_cols if col not in df.columns]\n    if missing_cols:\n        raise ValueError(f\"Missing required columns: {missing_cols}\")\n\n    # --- Timestamp Handling ---\n    if ts_col not in df.columns:\n         raise ValueError(f\"DataFrame must contain the timestamp column: '{ts_col}'\")\n    # Try inferring format, common ones first\n    try:\n        # Attempt numeric conversion first (common for Unix timestamps)\n        df[ts_col] = pd.to_numeric(df[ts_col], errors='coerce')\n        # Check magnitude to guess unit (simple heuristic)\n        if df[ts_col].max() > 1e12: # Likely milliseconds\n             df['timestamp'] = pd.to_datetime(df[ts_col], unit='ms', errors='coerce')\n        else: # Likely seconds\n             df['timestamp'] = pd.to_datetime(df[ts_col], unit='s', errors='coerce')\n    except Exception: # Fallback to general datetime parsing if numeric fails or leads to errors\n         try:\n              df['timestamp'] = pd.to_datetime(df[ts_col], errors='coerce') # Standard formats\n         except Exception as e:\n              raise ValueError(f\"Could not parse '{ts_col}' column. Error: {e}. Ensure it's Unix time (s or ms) or a standard datetime format.\")\n\n    # Rename parsed timestamp column and set as index\n    df = df.rename(columns={'timestamp': 'datetime'}) # Avoid clash if original was 'timestamp'\n    df = df.dropna(subset=['datetime']) # Drop rows where timestamp parsing failed\n    df = df.set_index('datetime')\n    df = df.sort_index()\n\n    # Check for duplicate timestamps\n    if df.index.duplicated().any():\n        print(\"Warning: Duplicate timestamps found. Keeping the first occurrence.\")\n        df = df[~df.index.duplicated(keep='first')]\n\n    # --- Data Type Conversion & Cleaning ---\n    cols_to_numeric = [price_col, mvrv_col]\n    if config['use_volatility_stops']:\n         cols_to_numeric.extend(config['ohlc_cols'])\n    if config.get('volume_col') in df.columns:\n         cols_to_numeric.append(config['volume_col'])\n\n    for col in cols_to_numeric:\n        if col in df.columns:\n             df[col] = pd.to_numeric(df[col], errors='coerce')\n\n    initial_len = len(df)\n    required_numeric_cols = [price_col, mvrv_col] # Core requirements for strategy logic\n    if config['use_volatility_stops']:\n         required_numeric_cols.extend(config['ohlc_cols'])\n    df = df.dropna(subset=required_numeric_cols) # Drop rows with NaNs in essential numeric columns\n    if initial_len > len(df):\n        print(f\"Warning: Dropped {initial_len - len(df)} rows due to NaNs in required numeric columns.\")\n\n    # Rename columns for consistency within the strategy code\n    rename_map = {}\n    if price_col != 'Price':\n        rename_map[price_col] = 'Price'\n    if mvrv_col != '7d_mvrv':\n        rename_map[mvrv_col] = '7d_mvrv'\n    if config['use_volatility_stops']:\n         ohlc_map = {cfg_col: target for cfg_col, target in zip(config['ohlc_cols'], ['Open', 'High', 'Low', 'Close']) if cfg_col != target}\n         rename_map.update(ohlc_map)\n\n    if rename_map:\n        df = df.rename(columns=rename_map)\n        print(f\"Renamed columns: {rename_map}\")\n\n    # --- Date Filtering ---\n    if config.get(\"start_date\"):\n        df = df[df.index >= pd.to_datetime(config[\"start_date\"])]\n    if config.get(\"end_date\"):\n        df = df[df.index <= pd.to_datetime(config[\"end_date\"])]\n\n    # Check if data remains\n    if df.empty:\n        raise ValueError(\"No data remaining after preprocessing and date filtering.\")\n\n    print(f\"Preprocessed data shape: {df.shape}, from {df.index.min()} to {df.index.max()}\")\n    return df\n```\n\n```python\n# --- File: indicators.py ---\n\"\"\"\nFunctions for calculating technical and on-chain indicators.\nEnsures no look-ahead bias by using .shift(1) appropriately.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom typing import Dict, Any\nimport warnings\n\ndef _calculate_atr(df: pd.DataFrame, config: Dict[str, Any]) -> pd.Series:\n    \"\"\"Calculates Average True Range (ATR). Internal helper.\"\"\"\n    if not all(col in df.columns for col in ['High', 'Low', 'Close']):\n         raise ValueError(\"Missing High, Low, or Close columns required for ATR\")\n\n    high_low = df['High'] - df['Low']\n    # Ensure use of PREVIOUS close for ATR calculation to prevent look-ahead\n    high_close = (df['High'] - df['Close'].shift(1)).abs()\n    low_close = (df['Low'] - df['Close'].shift(1)).abs()\n\n    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n    atr = tr.rolling(window=config['atr_period'], min_periods=config['atr_period'] // 2).mean()\n    return atr\n\ndef calculate_indicators(df: pd.DataFrame, config: Dict[str, Any]) -> pd.DataFrame:\n    \"\"\"Calculates all required indicators, ensuring no look-ahead bias.\"\"\"\n    print(\"Calculating indicators...\")\n    df_out = df.copy()\n\n    # --- Base MVRV Indicators (Shifted) ---\n    # Use .shift(1) before rolling ensures value at time `t` uses data up to `t-1`.\n    mvrv_shifted = df_out['7d_mvrv'].shift(1)\n    price_shifted = df_out['Price'].shift(1)\n\n    df_out['MVRV_MA'] = mvrv_shifted.rolling(window=config['ma_period'], min_periods=config['ma_period'] // 2).mean()\n    df_out['MVRV_Volatility'] = mvrv_shifted.rolling(window=config['ma_period'], min_periods=config['ma_period'] // 2).std()\n\n    # --- Volatility Stops Indicator (ATR) ---\n    if config['use_volatility_stops']:\n        # ATR calculation uses shifted close internally.\n        atr_raw = _calculate_atr(df_out, config)\n        # Shift final ATR series so value at `t` is based on calculations up to `t-1`.\n        df_out['ATR'] = atr_raw.shift(1)\n\n    # --- Complementary Indicators (Shifted) ---\n    # 1. MVRV Z-Score\n    intervals_per_year = config['intervals_per_year']\n    z_score_lookback_intervals = int(config['z_score_lookback_years'] * intervals_per_year)\n    lookback_z = min(z_score_lookback_intervals, len(df_out) - 1)\n    min_z_periods = max(10, lookback_z // 2) # Ensure a minimum reasonable period\n\n    if lookback_z < intervals_per_year / 12: # Less than ~a month's worth\n        print(f\"Warning: Insufficient data for {config['z_score_lookback_years']}-year Z-score. Using {lookback_z} intervals (~{lookback_z / (12*24):.1f} days)\")\n\n    rolling_mean_z = mvrv_shifted.rolling(window=lookback_z, min_periods=min_z_periods).mean()\n    rolling_std_z = mvrv_shifted.rolling(window=lookback_z, min_periods=min_z_periods).std()\n    df_out['MVRV_Z_Score'] = (mvrv_shifted - rolling_mean_z) / (rolling_std_z + 1e-10)\n\n    # 2. MVRV Rate of Change (ROC)\n    # pct_change inherently looks back `periods`. Shift the result to align.\n    df_out['MVRV_ROC'] = df_out['7d_mvrv'].pct_change(periods=config['roc_period']).shift(1) * 100\n\n    # 3. Price/MVRV Divergence\n    norm_window = config['divergence_norm_window']\n    min_norm_periods = norm_window // 2\n    price_norm = price_shifted / price_shifted.rolling(norm_window, min_periods=min_norm_periods).mean() - 1\n    mvrv_norm = mvrv_shifted / mvrv_shifted.rolling(norm_window, min_periods=min_norm_periods).mean() - 1\n    df_out['Price_MVRV_Divergence'] = price_norm - mvrv_norm # Based on shifted inputs\n\n    # 4. MVRV Trend Strength (DI+/- concept)\n    period_trend = config['trend_strength_period']\n    min_trend_periods = period_trend // 2\n    mvrv_diff = df_out['7d_mvrv'].diff() # Based on t vs t-1\n\n    dm_plus = pd.Series(np.where(mvrv_diff > 0, mvrv_diff, 0), index=df_out.index)\n    dm_minus = pd.Series(np.where(mvrv_diff < 0, -mvrv_diff, 0), index=df_out.index)\n\n    dm_plus_smooth = dm_plus.rolling(period_trend, min_periods=min_trend_periods).mean()\n    dm_minus_smooth = dm_minus.rolling(period_trend, min_periods=min_trend_periods).mean()\n\n    trend_strength_raw = (dm_plus_smooth - dm_minus_smooth).abs() / (dm_plus_smooth + dm_minus_smooth + 1e-10) * 100\n    df_out['MVRV_Trend_Strength'] = trend_strength_raw.shift(1) # Shift result\n\n    # --- Feature-Flagged Indicators ---\n\n    # Dynamic Thresholds (based on shifted MA/Vol)\n    if config['use_dynamic_thresholds']:\n        df_out['Positive_Threshold'] = df_out['MVRV_MA'] + (df_out['MVRV_Volatility'] * config['dynamic_threshold_factor'])\n        df_out['Negative_Threshold'] = df_out['MVRV_MA'] - (df_out['MVRV_Volatility'] * config['dynamic_threshold_factor'])\n    else:\n        # Static thresholds (calculated once based on historical non-shifted MVRV)\n        min_data_for_quantile = max(100, config['ma_period'])\n        if len(df_out) > min_data_for_quantile:\n            positive_mvrv = df_out.loc[df_out['7d_mvrv'] > 0, '7d_mvrv']\n            negative_mvrv = df_out.loc[df_out['7d_mvrv'] < 0, '7d_mvrv']\n            pos_thresh = positive_mvrv.quantile(config['positive_quantile']) if not positive_mvrv.empty else 0.05\n            neg_thresh = negative_mvrv.quantile(config['negative_quantile']) if not negative_mvrv.empty else -0.05\n        else:\n            warnings.warn(\"Not enough data for historical quantile thresholds, using defaults.\")\n            pos_thresh = 0.05\n            neg_thresh = -0.05\n        df_out['Positive_Threshold'] = pos_thresh\n        df_out['Negative_Threshold'] = neg_thresh\n\n    # Regime Detection (based on shifted MA)\n    if config['use_regime_adjustment']:\n        regime_ma_period = int(config['ma_period'] * config['regime_ma_period_factor'])\n        df_out['MVRV_Trend'] = np.where(\n            df_out['MVRV_MA'] > df_out['MVRV_MA'].shift(regime_ma_period), 'uptrend', 'downtrend'\n        )\n        df_out['MVRV_Trend'] = df_out['MVRV_Trend'].ffill().bfill() # Fill NaNs robustly\n\n        # Adjust MVRV Stop factors\n        df_out['Adjusted_TP_Factor'] = np.where(\n            df_out['MVRV_Trend'] == 'uptrend', config['mvrv_tp_factor'] * config['regime_uptrend_tp_mult'],\n            config['mvrv_tp_factor'] * config['regime_downtrend_tp_mult']\n        )\n        df_out['Adjusted_SL_Factor'] = np.where(\n            df_out['MVRV_Trend'] == 'uptrend', config['mvrv_sl_factor'] * config['regime_uptrend_sl_mult'],\n            config['mvrv_sl_factor'] * config['regime_downtrend_sl_mult']\n        )\n        # Adjust ATR Stop multipliers\n        df_out['Adjusted_ATR_TP_Multiplier'] = np.where(\n             df_out['MVRV_Trend'] == 'uptrend', config['atr_tp_multiplier'] * config['regime_uptrend_tp_mult'],\n             config['atr_tp_multiplier'] * config['regime_downtrend_tp_mult']\n        )\n        df_out['Adjusted_ATR_SL_Multiplier'] = np.where(\n             df_out['MVRV_Trend'] == 'uptrend', config['atr_sl_multiplier'] * config['regime_uptrend_sl_mult'],\n             config['atr_sl_multiplier'] * config['regime_downtrend_sl_mult']\n        )\n    else:\n        # Set defaults if regime adjustment is off\n        df_out['Adjusted_TP_Factor'] = config['mvrv_tp_factor']\n        df_out['Adjusted_SL_Factor'] = config['mvrv_sl_factor']\n        df_out['Adjusted_ATR_TP_Multiplier'] = config['atr_tp_multiplier']\n        df_out['Adjusted_ATR_SL_Multiplier'] = config['atr_sl_multiplier']\n\n    # MVRV RSI (shifted)\n    if config['use_mvrv_rsi']:\n        period_rsi = config['mvrv_rsi_period']\n        min_rsi_periods = period_rsi // 2\n        delta_rsi = df_out['7d_mvrv'].diff()\n        gain = delta_rsi.where(delta_rsi > 0, 0).fillna(0)\n        loss = -delta_rsi.where(delta_rsi < 0, 0).fillna(0)\n\n        avg_gain = gain.ewm(com=period_rsi - 1, min_periods=min_rsi_periods).mean()\n        avg_loss = loss.ewm(com=period_rsi - 1, min_periods=min_rsi_periods).mean()\n\n        rs = avg_gain / (avg_loss + 1e-10)\n        rsi_raw = 100 - (100 / (1 + rs))\n        df_out['MVRV_RSI'] = rsi_raw.shift(1) # Shift result\n\n    # Dynamic MA (Placeholder Logic)\n    if config['use_dynamic_ma']:\n         warnings.warn(\"Dynamic MA calculation is complex; using standard MA as fallback.\", UserWarning)\n         df_out['MVRV_Adaptive_MA'] = df_out['MVRV_MA'] # Fallback\n         df_out['Adaptive_MA_Period'] = config['ma_period'] # Fallback\n         # Proper implementation would require iterative or advanced vectorization\n\n    # --- Final Cleanup ---\n    # Drop initial rows with NaNs generated by the longest rolling calculation + shift\n    # Determine required columns based on config\n    required_indicator_cols = ['MVRV_MA', 'MVRV_Volatility', 'MVRV_Z_Score', 'MVRV_ROC', 'Price_MVRV_Divergence', 'MVRV_Trend_Strength']\n    if config['use_volatility_stops']: required_indicator_cols.append('ATR')\n    if config['use_mvrv_rsi']: required_indicator_cols.append('MVRV_RSI')\n\n    # Find the first index where ALL required indicators are non-NaN\n    first_valid_idx = df_out.dropna(subset=required_indicator_cols).index.min()\n\n    if pd.isna(first_valid_idx):\n        raise ValueError(\"Could not calculate indicators, likely insufficient data for lookback periods.\")\n\n    print(f\"Indicator calculation complete. Dropping initial rows before {first_valid_idx} due to indicator warmup.\")\n    df_out = df_out.loc[first_valid_idx:]\n\n    if df_out.empty:\n         raise ValueError(\"No data remaining after indicator calculation warmup.\")\n\n    return df_out\n\n```\n\n```python\n# --- File: signals.py ---\n\"\"\"\nGenerates trading entry signals based on calculated indicators.\n\"\"\"\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, Any\n\ndef generate_signals(df: pd.DataFrame, config: Dict[str, Any]) -> pd.DataFrame:\n    \"\"\"Generates buy (1) and sell (-1) signals.\"\"\"\n    print(\"Generating signals...\")\n    df_out = df.copy()\n    df_out['Signal'] = 0\n\n    # Define MA column to use based on config\n    ma_col = 'MVRV_Adaptive_MA' if config['use_dynamic_ma'] else 'MVRV_MA'\n\n    # Vectorized conditions where possible (more complex logic might still need iteration)\n    # Note: Using shifted indicators means df['Indicator'].iloc[i] gives value calculated before bar i\n\n    # Base Entry Conditions using shifted values for comparison at time t\n    # Accessing .shift() again here applies shift relative to the current index `i`\n    mvrv_t = df_out['7d_mvrv']\n    mvrv_t_minus_1 = df_out['7d_mvrv'].shift(1)\n    mvrv_ma_t = df_out[ma_col] # Already shifted in calculation phase\n    neg_threshold_t = df_out['Negative_Threshold'] # Already shifted if dynamic\n    pos_threshold_t = df_out['Positive_Threshold'] # Already shifted if dynamic\n\n    buy_condition = (mvrv_t_minus_1 < neg_threshold_t) & (mvrv_t > mvrv_ma_t) & (mvrv_t_minus_1 < mvrv_ma_t)\n    sell_condition = (mvrv_t_minus_1 > pos_threshold_t) & (mvrv_t < mvrv_ma_t) & (mvrv_t_minus_1 > mvrv_ma_t)\n\n    # Apply Filters/Confirmations\n    if config['use_mvrv_rsi']:\n        mvrv_rsi_t = df_out['MVRV_RSI'] # Already shifted\n        buy_condition = buy_condition & (mvrv_rsi_t < config['mvrv_rsi_buy_threshold'])\n        sell_condition = sell_condition & (mvrv_rsi_t > config['mvrv_rsi_sell_threshold'])\n\n    # Add other filter conditions here if needed, e.g.:\n    # if config['require_zscore_filter']:\n    #     mvrv_z_score_t = df_out['MVRV_Z_Score'] # Already shifted\n    #     buy_condition = buy_condition & (mvrv_z_score_t < 0)\n    #     sell_condition = sell_condition & (mvrv_z_score_t > 0)\n\n    # Assign Signals\n    df_out.loc[buy_condition, 'Signal'] = 1\n    df_out.loc[sell_condition, 'Signal'] = -1 # Use -1 for short signals\n\n    print(f\"Generated {len(df_out[df_out['Signal'] != 0])} potential entry signals.\")\n    return df_out\n\n```\n\n```python\n# --- File: risk.py ---\n\"\"\"\nRisk management functions: position sizing, SL/TP calculation.\n\"\"\"\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, Any, Tuple, Optional\nimport warnings\n\ndef calculate_position_size(current_equity: float, config: Dict[str, Any], df_row: Optional[pd.Series] = None) -> float:\n    \"\"\"\n    Calculates position size as a fraction of equity.\n    CRITICAL: Default logic uses 100% equity - VERY HIGH RISK. Needs modification.\n    \"\"\"\n    if config['use_adaptive_position'] and df_row is not None:\n        # --- PLACEHOLDER for Adaptive Logic ---\n        # Example: Scale size based on absolute Z-score deviation (needs calibration)\n        # base_fraction = 0.02 # Risk 2% by default\n        # max_fraction = 0.10 # Max risk 10%\n        # z_score = df_row.get('MVRV_Z_Score', 0)\n        # conviction = min(abs(z_score) / 3.0, 1.0) # Normalize Z-score effect (0 to 1)\n        # size_fraction = base_fraction + (max_fraction - base_fraction) * conviction\n        # return min(size_fraction, max_fraction) # Ensure ceiling\n        # --- END PLACEHOLDER ---\n        warnings.warn(\"Adaptive position sizing logic is a placeholder. Using fixed fraction.\", UserWarning)\n        # Fallback to fixed fraction if adaptive logic not implemented\n        return config['position_sizing_fraction'] # CRITICAL: Default 1.0 (100%)\n    else:\n        # Fixed fractional sizing\n        return config['position_sizing_fraction'] # CRITICAL: Default 1.0 (100%)\n\ndef calculate_sl_tp(entry_price: float, signal: int, config: Dict[str, Any], df_row: pd.Series) -> Tuple[Optional[float], Optional[float]]:\n    \"\"\"Calculates Stop Loss and Take Profit levels based on config.\"\"\"\n    tp_level = None\n    sl_level = None\n\n    if config['use_volatility_stops']:\n        # ATR stops require 'ATR' and adjusted multipliers in the row\n        atr = df_row.get('ATR')\n        if pd.isna(atr) or atr <= 0: # Check ATR validity\n            warnings.warn(f\"ATR is NaN or non-positive at {df_row.name}. Cannot set volatility stops.\", UserWarning)\n            return None, None # Abort if ATR invalid\n\n        tp_mult = df_row.get('Adjusted_ATR_TP_Multiplier', config['atr_tp_multiplier'])\n        sl_mult = df_row.get('Adjusted_ATR_SL_Multiplier', config['atr_sl_multiplier'])\n\n        if signal == 1: # Long\n            tp_level = entry_price + atr * tp_mult\n            sl_level = entry_price - atr * sl_mult\n        elif signal == -1: # Short\n            tp_level = entry_price - atr * tp_mult\n            sl_level = entry_price + atr * sl_mult\n\n    elif config['use_mvrv_stops']:\n        # MVRV stops require MVRV, MA, and adjusted factors\n        entry_mvrv = df_row.get('7d_mvrv')\n        mvrv_ma = df_row.get('MVRV_MA') # Already shifted\n        if pd.isna(entry_mvrv) or pd.isna(mvrv_ma):\n             warnings.warn(f\"MVRV or MVRV_MA is NaN at {df_row.name}. Cannot set MVRV stops.\", UserWarning)\n             return None, None # Abort if values invalid\n\n        tp_factor = df_row.get('Adjusted_TP_Factor', config['mvrv_tp_factor'])\n        sl_factor = df_row.get('Adjusted_SL_Factor', config['mvrv_sl_factor'])\n\n        # Simple proxy: Use price % change proportional to MVRV distance from MA\n        # This is a heuristic and needs careful validation/calibration.\n        mvrv_distance_pct = abs(entry_mvrv - mvrv_ma) # Absolute MVRV distance\n\n        if signal == 1: # Long\n            price_change_tp = entry_price * (mvrv_distance_pct * tp_factor) # Assume direct proportionality\n            price_change_sl = entry_price * (mvrv_distance_pct * sl_factor)\n            tp_level = entry_price + price_change_tp\n            sl_level = entry_price - price_change_sl\n        elif signal == -1: # Short\n            price_change_tp = entry_price * (mvrv_distance_pct * tp_factor)\n            price_change_sl = entry_price * (mvrv_distance_pct * sl_factor)\n            tp_level = entry_price - price_change_tp\n            sl_level = entry_price + price_change_sl\n    else:\n        # No stops defined if both flags are false\n        pass\n\n    # --- Sanity Checks ---\n    # Ensure SL is logical (e.g., below entry for long, above for short)\n    if signal == 1 and sl_level is not None and sl_level >= entry_price:\n        warnings.warn(f\"Calculated SL ({sl_level:.2f}) >= entry ({entry_price:.2f}) for long trade at {df_row.name}. Check ATR/factors. Setting fallback SL.\", UserWarning)\n        sl_level = entry_price * (1 - 0.005) # Small fallback SL (e.g., 0.5%)\n    if signal == -1 and sl_level is not None and sl_level <= entry_price:\n        warnings.warn(f\"Calculated SL ({sl_level:.2f}) <= entry ({entry_price:.2f}) for short trade at {df_row.name}. Check ATR/factors. Setting fallback SL.\", UserWarning)\n        sl_level = entry_price * (1 + 0.005) # Small fallback SL\n\n    # Ensure TP is logical\n    if signal == 1 and tp_level is not None and tp_level <= entry_price:\n         warnings.warn(f\"Calculated TP ({tp_level:.2f}) <= entry ({entry_price:.2f}) for long trade at {df_row.name}. Check ATR/factors. Setting TP to None.\", UserWarning)\n         tp_level = None # Invalidate illogical TP\n    if signal == -1 and tp_level is not None and tp_level >= entry_price:\n         warnings.warn(f\"Calculated TP ({tp_level:.2f}) >= entry ({entry_price:.2f}) for short trade at {df_row.name}. Check ATR/factors. Setting TP to None.\", UserWarning)\n         tp_level = None # Invalidate illogical TP\n\n    return sl_level, tp_level\n\n```\n\n```python\n# --- File: backtest.py ---\n\"\"\"\nBacktesting engine simulating strategy execution and applying risk rules.\n\"\"\"\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, Any, Tuple, List\nfrom risk import calculate_position_size, calculate_sl_tp # Import from risk module\n\ndef run_backtest(df: pd.DataFrame, config: Dict[str, Any]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"Runs the backtest simulation loop.\"\"\"\n    print(\"Running backtest...\")\n    df_results = df.copy()\n\n    # Initialize backtest state columns\n    df_results['Position'] = 0          # 1: long, -1: short, 0: flat\n    df_results['Entry_Price'] = np.nan\n    df_results['Exit_Price'] = np.nan\n    df_results['SL_Level'] = np.nan\n    df_results['TP_Level'] = np.nan\n    df_results['Trade_Return'] = np.nan # Pct return for the closed trade\n    df_results['Equity'] = config['initial_capital']\n    df_results['Peak_Equity'] = config['initial_capital']\n    df_results['Drawdown'] = 0.0        # Drawdown percentage\n    df_results['Trading_Halted'] = False # Track drawdown halt status\n\n    # Simulation state variables\n    in_position = 0 # Current position state\n    entry_price = 0.0\n    current_equity = config['initial_capital']\n    peak_equity = config['initial_capital']\n    position_size_fraction = 1.0 # Fraction of equity risked per trade\n    sl_level = None\n    tp_level = None\n    trade_entry_index = None\n    trading_halted = False # Internal state flag for drawdown halt\n\n    max_drawdown_limit = config['max_drawdown_pct'] / 100.0\n    drawdown_recovery_target = config['drawdown_recovery_pct'] / 100.0\n\n    trade_log: List[Dict[str, Any]] = []\n\n    # Define MA column to use based on config (for MA cross exit)\n    ma_col = 'MVRV_Adaptive_MA' if config['use_dynamic_ma'] else 'MVRV_MA'\n\n    # --- Simulation Loop ---\n    for i in range(len(df_results)):\n        current_dt = df_results.index[i]\n        current_row = df_results.iloc[i]\n        # Use Close price for calculations, but consider using Open for entry/exit simulation if preferred\n        current_price = current_row['Price']\n        # Use High/Low for more realistic SL/TP checks within the bar if available\n        current_high = current_row.get('High', current_price)\n        current_low = current_row.get('Low', current_price)\n\n        # --- Update Equity and Drawdown based on PREVIOUS state ---\n        # Equity reflects the close of the *last* bar processed or initial capital\n        df_results['Equity'].iloc[i] = current_equity\n        peak_equity = max(peak_equity, current_equity)\n        df_results['Peak_Equity'].iloc[i] = peak_equity\n        current_drawdown = (peak_equity - current_equity) / peak_equity if peak_equity > 0 else 0\n        df_results['Drawdown'].iloc[i] = current_drawdown * 100\n\n        # --- Drawdown Halt Check (based on state BEFORE current bar actions) ---\n        if trading_halted:\n            df_results['Trading_Halted'].iloc[i] = True\n            # Check for recovery\n            if current_drawdown < drawdown_recovery_target:\n                 trading_halted = False\n                 df_results['Trading_Halted'].iloc[i] = False # Mark recovery\n                 print(f\"{current_dt}: Trading RESUMED. Drawdown {current_drawdown*100:.2f}% < {drawdown_recovery_target*100:.1f}% target.\")\n            # else: remain halted\n\n        elif current_drawdown >= max_drawdown_limit:\n            # Drawdown limit breached based on previous bar's close equity\n            trading_halted = True\n            df_results['Trading_Halted'].iloc[i] = True\n            print(f\"{current_dt}: Trading HALTED. Drawdown {current_drawdown*100:.2f}% >= {max_drawdown_limit*100:.1f}% limit.\")\n            # Force exit IF currently in a position\n            if in_position != 0:\n                 exit_price = current_price # Exit at current bar's price (e.g., Close)\n                 print(f\"Force exiting position at {exit_price:.2f} due to drawdown halt.\")\n                 # Calculate PnL for the forced exit\n                 if in_position == 1: # Long\n                     trade_return = (exit_price - entry_price) / entry_price\n                 else: # Short\n                     trade_return = (entry_price - exit_price) / entry_price\n\n                 trade_pnl = current_equity * position_size_fraction * trade_return\n                 current_equity += trade_pnl # Update equity immediately\n\n                 # Log the forced trade exit\n                 trade_log.append({\n                    'entry_dt': trade_entry_index, 'exit_dt': current_dt,\n                    'entry_price': entry_price, 'exit_price': exit_price,\n                    'position_type': 'long' if in_position == 1 else 'short',\n                    'size_fraction': position_size_fraction,\n                    'return_pct': trade_return * 100, 'pnl': trade_pnl,\n                    'exit_reason': 'Drawdown Halt Force Exit', 'sl_level': sl_level, 'tp_level': tp_level\n                 })\n                 # Update DataFrame for the closed trade period\n                 df_results.loc[trade_entry_index:current_dt, 'Position'] = 0\n                 df_results.loc[current_dt, 'Exit_Price'] = exit_price\n                 df_results.loc[current_dt, 'Trade_Return'] = trade_return * 100\n\n                 # Reset position state\n                 in_position = 0\n                 sl_level = None\n                 tp_level = None\n                 trade_entry_index = None\n\n\n        # --- Process Exits (Only if NOT halted and IN a position) ---\n        exit_signal = 0 # 1: exit long, -1: exit short\n        exit_reason = None\n        exit_price = current_price # Default exit price\n\n        if in_position != 0 and not trading_halted:\n            # Determine price points for checks within the bar\n            check_price_sl = current_low if in_position == 1 else current_high\n            check_price_tp = current_high if in_position == 1 else current_low\n\n            # Check SL first (using High/Low for intra-bar check)\n            if sl_level is not None:\n                 if (in_position == 1 and check_price_sl <= sl_level) or \\\n                    (in_position == -1 and check_price_sl >= sl_level):\n                    exit_signal = -in_position # Signal to exit the current position type\n                    exit_reason = \"SL\"\n                    exit_price = sl_level # Assume SL filled at SL price\n\n            # Check TP (only if SL not hit)\n            if exit_signal == 0 and tp_level is not None:\n                if (in_position == 1 and check_price_tp >= tp_level) or \\\n                   (in_position == -1 and check_price_tp <= tp_level):\n                    exit_signal = -in_position\n                    exit_reason = \"TP\"\n                    exit_price = tp_level # Assume TP filled at TP price\n\n            # Check MA Cross Exit (if enabled and SL/TP not hit)\n            if exit_signal == 0 and config['exit_on_ma_cross']:\n                 mvrv_val = current_row['7d_mvrv']\n                 ma_val = current_row[ma_col]\n                 if (in_position == 1 and mvrv_val < ma_val) or \\\n                    (in_position == -1 and mvrv_val > ma_val):\n                      exit_signal = -in_position\n                      exit_reason = \"MA Cross\"\n                      exit_price = current_price # Exit at bar's close\n\n            # Check optional Z-Score Exit (if enabled and SL/TP/MA not hit)\n            if exit_signal == 0 and config['exit_on_zscore_extreme']:\n                 z_score = current_row.get('MVRV_Z_Score')\n                 z_thresh = config['zscore_extreme_threshold']\n                 if pd.notna(z_score):\n                     if (in_position == 1 and z_score > z_thresh) or \\\n                        (in_position == -1 and z_score < -z_thresh):\n                          exit_signal = -in_position\n                          exit_reason = \"Z-Score Extreme\"\n                          exit_price = current_price # Exit at bar's close\n\n            # Check optional Divergence Exit (Add logic here if needed)\n            # if exit_signal == 0 and config['exit_on_divergence']:\n            #      ... check divergence condition ...\n            #      exit_signal = -in_position\n            #      exit_reason = \"Divergence Exit\"\n            #      exit_price = current_price\n\n            # Process Exit If Triggered\n            if exit_signal != 0:\n                # Calculate PnL based on exit price\n                if in_position == 1: # Exiting long\n                    trade_return = (exit_price - entry_price) / entry_price\n                else: # Exiting short\n                    trade_return = (entry_price - exit_price) / entry_price\n\n                trade_pnl = current_equity * position_size_fraction * trade_return\n                current_equity += trade_pnl # Update equity immediately\n\n                # Log trade\n                trade_log.append({\n                    'entry_dt': trade_entry_index, 'exit_dt': current_dt,\n                    'entry_price': entry_price, 'exit_price': exit_price,\n                    'position_type': 'long' if in_position == 1 else 'short',\n                    'size_fraction': position_size_fraction,\n                    'return_pct': trade_return * 100, 'pnl': trade_pnl,\n                    'exit_reason': exit_reason, 'sl_level': sl_level, 'tp_level': tp_level\n                })\n\n                # Update DataFrame state for this trade\n                df_results.loc[trade_entry_index:current_dt, 'Position'] = 0 # Mark period as flat\n                df_results.loc[current_dt, 'Exit_Price'] = exit_price\n                df_results.loc[current_dt, 'Trade_Return'] = trade_return * 100 # Store trade return at exit bar\n\n                # Reset state\n                in_position = 0\n                sl_level = None\n                tp_level = None\n                trade_entry_index = None\n\n\n        # --- Process Entries (Only if flat and NOT halted) ---\n        entry_signal = current_row['Signal']\n        if in_position == 0 and entry_signal != 0 and not trading_halted:\n            # Attempt to enter a trade\n            entry_price = current_price # Assume entry at current bar's close (can use Open[i+1] for next bar entry)\n            position_type = 'long' if entry_signal == 1 else 'short'\n\n            # Calculate position size (CRITICAL: review implementation in risk.py)\n            position_size_fraction = calculate_position_size(current_equity, config, current_row)\n\n            # Calculate SL/TP based on entry price and current row's indicators (e.g., ATR)\n            sl_level, tp_level = calculate_sl_tp(entry_price, entry_signal, config, current_row)\n\n            # Check if stops are required but couldn't be calculated\n            stops_required = config['use_volatility_stops'] or config['use_mvrv_stops']\n            stops_calculated = sl_level is not None or tp_level is not None # At least one stop needed if required\n\n            if stops_required and not stops_calculated:\n                 print(f\"Warning: Could not calculate required SL/TP for signal at {current_dt}. Skipping entry.\")\n            else:\n                # Enter position\n                in_position = entry_signal\n                trade_entry_index = current_dt # Log entry time\n\n                # Update DataFrame state for the new trade\n                df_results.loc[current_dt, 'Position'] = in_position\n                df_results.loc[current_dt, 'Entry_Price'] = entry_price\n                df_results.loc[current_dt, 'SL_Level'] = sl_level\n                df_results.loc[current_dt, 'TP_Level'] = tp_level\n\n                sl_str = f\"{sl_level:.2f}\" if sl_level else \"None\"\n                tp_str = f\"{tp_level:.2f}\" if tp_level else \"None\"\n                print(f\"{current_dt}: Enter {position_type} @ {entry_price:.2f} | Size: {position_size_fraction:.2f} | SL: {sl_str} | TP: {tp_str}\")\n\n\n        # --- Propagate State for Bars Held Within a Trade ---\n        # Update position, entry, SL/TP for bars where the position is held open\n        if in_position != 0 and trade_entry_index is not None:\n             # Ensure we don't overwrite the entry bar's info if i == entry_loc\n             entry_loc = df_results.index.get_loc(trade_entry_index)\n             if i > entry_loc:\n                 df_results['Position'].iloc[i] = in_position\n                 df_results['Entry_Price'].iloc[i] = entry_price # Carry forward for reference\n                 df_results['SL_Level'].iloc[i] = sl_level       # Carry forward SL\n                 df_results['TP_Level'].iloc[i] = tp_level       # Carry forward TP\n\n\n    print(\"Backtest simulation finished.\")\n    # Convert trade log to DataFrame for easier analysis\n    trades_df = pd.DataFrame(trade_log)\n    if not trades_df.empty:\n         trades_df['entry_dt'] = pd.to_datetime(trades_df['entry_dt'])\n         trades_df['exit_dt'] = pd.to_datetime(trades_df['exit_dt'])\n         trades_df = trades_df.set_index('entry_dt', drop=False) # Optional: Index by entry time\n\n    return df_results, trades_df\n```\n\n```python\n# --- File: metrics.py ---\n\"\"\"\nCalculates performance metrics from backtest results.\n\"\"\"\nimport pandas as pd\nimport numpy as np\nimport math\nfrom typing import Dict, Any\n\ndef calculate_metrics(df_results: pd.DataFrame, trades_df: pd.DataFrame, config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Calculates performance metrics for the backtest.\"\"\"\n    print(\"Calculating performance metrics...\")\n    metrics = {}\n\n    initial_capital = config['initial_capital']\n    final_equity = df_results['Equity'].iloc[-1]\n\n    metrics['Initial Capital'] = initial_capital\n    metrics['Final Equity'] = final_equity\n    metrics['Total Return (%)'] = (final_equity / initial_capital - 1) * 100 if initial_capital > 0 else 0\n\n    # Time-based metrics\n    start_date = df_results.index.min()\n    end_date = df_results.index.max()\n    duration_days = (end_date - start_date).days\n    duration_years = duration_days / 365.25\n    metrics['Start Date'] = start_date.strftime('%Y-%m-%d %H:%M')\n    metrics['End Date'] = end_date.strftime('%Y-%m-%d %H:%M')\n    metrics['Duration (Years)'] = duration_years\n\n    if duration_years > 0 and metrics['Total Return (%)'] is not None:\n         # Calculate CAGR using Decimal for precision if needed, simple float here\n         total_return_factor = 1 + metrics['Total Return (%)'] / 100\n         # Handle potential negative returns correctly for CAGR calculation\n         if total_return_factor > 0:\n             metrics['Annualized Return (CAGR %)'] = (total_return_factor**(1 / duration_years) - 1) * 100\n         else:\n              metrics['Annualized Return (CAGR %)'] = -100.0 # Total loss\n    else:\n        metrics['Annualized Return (CAGR %)'] = 0\n\n    # Drawdown metrics\n    metrics['Max Drawdown (%)'] = df_results['Drawdown'].max() # Already stored as %\n    max_dd_date = df_results['Drawdown'].idxmax()\n    metrics['Max Drawdown Date'] = max_dd_date.strftime('%Y-%m-%d %H:%M') if pd.notna(max_dd_date) else \"N/A\"\n\n    # Calculate Calmar Ratio (Annualized Return / Max Drawdown)\n    if metrics['Max Drawdown (%)'] is not None and metrics['Max Drawdown (%)'] > 0:\n         metrics['Calmar Ratio'] = metrics['Annualized Return (CAGR %)'] / metrics['Max Drawdown (%)']\n    else:\n         metrics['Calmar Ratio'] = np.inf if metrics['Annualized Return (CAGR %)'] > 0 else 0.0\n\n\n    # Trade metrics\n    num_trades = len(trades_df)\n    metrics['Total Trades'] = num_trades\n\n    if num_trades > 0:\n        metrics['Wins'] = len(trades_df[trades_df['return_pct'] > 0])\n        metrics['Losses'] = len(trades_df[trades_df['return_pct'] <= 0]) # Include breakeven as loss\n        metrics['Win Rate (%)'] = (metrics['Wins'] / num_trades) * 100 if num_trades > 0 else 0\n        metrics['Avg Trade Return (%)'] = trades_df['return_pct'].mean()\n        metrics['Avg Win (%)'] = trades_df.loc[trades_df['return_pct'] > 0, 'return_pct'].mean()\n        metrics['Avg Loss (%)'] = trades_df.loc[trades_df['return_pct'] <= 0, 'return_pct'].mean()\n\n        # Profit Factor\n        total_gross_profit = trades_df.loc[trades_df['return_pct'] > 0, 'pnl'].sum()\n        total_gross_loss = abs(trades_df.loc[trades_df['return_pct'] <= 0, 'pnl'].sum())\n        metrics['Profit Factor'] = total_gross_profit / total_gross_loss if total_gross_loss > 0 else np.inf\n\n        # Sharpe & Sortino Ratios (Annualized, using interval returns)\n        interval_returns = df_results['Equity'].pct_change().dropna()\n        if len(interval_returns) > 1: # Need at least 2 returns for std dev\n             avg_interval_return = interval_returns.mean()\n             std_interval_return = interval_returns.std()\n\n             annualization_factor = config.get('annualization_factor', math.sqrt(252)) # Use pre-calculated factor\n\n             # Sharpe Ratio\n             if std_interval_return > 1e-9:\n                 sharpe_ratio = (avg_interval_return * config['intervals_per_year'] - config['risk_free_rate']) / (std_interval_return * annualization_factor + 1e-9)\n                 metrics['Annualized Sharpe Ratio'] = sharpe_ratio\n             else:\n                 metrics['Annualized Sharpe Ratio'] = 0.0\n\n             # Sortino Ratio\n             negative_returns = interval_returns[interval_returns < 0]\n             if len(negative_returns) > 1: # Need at least 2 negative returns for downside std dev\n                 downside_std = negative_returns.std()\n                 if downside_std > 1e-9:\n                     sortino_ratio = (avg_interval_return * config['intervals_per_year'] - config['risk_free_rate']) / (downside_std * annualization_factor + 1e-9)\n                     metrics['Annualized Sortino Ratio'] = sortino_ratio\n                 else:\n                     metrics['Annualized Sortino Ratio'] = np.inf # No downside deviation\n             else:\n                 metrics['Annualized Sortino Ratio'] = np.inf # No downside deviation (or only 1)\n        else:\n            metrics['Annualized Sharpe Ratio'] = 0.0\n            metrics['Annualized Sortino Ratio'] = 0.0\n\n    else:\n        # Default values if no trades\n        metrics.update({\n            'Wins': 0, 'Losses': 0, 'Win Rate (%)': 0, 'Avg Trade Return (%)': 0,\n            'Avg Win (%)': 0, 'Avg Loss (%)': 0, 'Profit Factor': 0,\n            'Annualized Sharpe Ratio': 0, 'Annualized Sortino Ratio': 0, 'Calmar Ratio': 0\n        })\n\n    # Add active features to metrics summary\n    active_features = []\n    if config['use_dynamic_thresholds']: active_features.append(\"Dyn Thresh\")\n    if config['use_regime_adjustment']: active_features.append(\"Regime Adj\")\n    if config['use_mvrv_rsi']: active_features.append(\"MVRV RSI\")\n    if config['use_adaptive_position']: active_features.append(\"Adapt Pos (Placeholder)\")\n    if config['use_dynamic_ma']: active_features.append(\"Dyn MA (Placeholder)\")\n    if config['use_volatility_stops']: active_features.append(\"ATR Stops\")\n    if config['use_mvrv_stops']: active_features.append(\"MVRV Stops\")\n    if config['exit_on_zscore_extreme']: active_features.append(\"Z-Score Exit\")\n    if config['exit_on_divergence']: active_features.append(\"Div Exit\")\n    if config['exit_on_ma_cross']: active_features.append(\"MA Cross Exit\")\n    metrics['Active Features'] = \", \".join(active_features) if active_features else \"Base (Static Thresh, No Stops/Filters)\"\n\n    print(\"Metrics calculation complete.\")\n    return metrics\n\n```\n\n```python\n# --- File: plotting.py ---\n\"\"\"\nPlotting functions for visualizing backtest results.\n\"\"\"\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom typing import Dict, Any\n\ndef plot_results(df_results: pd.DataFrame, trades_df: pd.DataFrame, metrics: Dict[str, Any], config: Dict[str, Any]):\n    \"\"\"Plots the equity curve, drawdown, signals, and indicators.\"\"\"\n    print(\"Generating plots...\")\n\n    num_plots = 4 # Default plots\n    # Conditionally add plots based on data/config\n    plot_mvrv_rsi = config['use_mvrv_rsi'] and 'MVRV_RSI' in df_results.columns\n    plot_z_score = 'MVRV_Z_Score' in df_results.columns\n\n    if plot_mvrv_rsi: num_plots += 1\n    if plot_z_score: num_plots +=1\n\n    fig, axes = plt.subplots(num_plots, 1, figsize=(16, 5 * num_plots), sharex=True,\n                              gridspec_kw={'height_ratios': [3, 1, 2, 2] + ([1] * (num_plots - 4))})\n    # Ensure axes is always a list/array even if num_plots=1\n    if num_plots == 1: axes = [axes]\n\n    fig.suptitle(f\"Dynamic MVRV Strategy Backtest Results\\n({metrics.get('Active Features', 'N/A')})\", fontsize=16)\n    plot_idx = 0\n\n    # --- 1. Equity Curve and Drawdown ---\n    ax1 = axes[plot_idx]\n    ax1b = ax1.twinx() # For drawdown\n    ax1.set_title('Equity Curve & Drawdown')\n\n    ax1.plot(df_results.index, df_results['Equity'], label='Equity Curve', color='blue', linewidth=2)\n    ax1.set_ylabel('Equity ($)', color='blue')\n    ax1.tick_params(axis='y', labelcolor='blue')\n    ax1.grid(True, axis='y', linestyle='--', alpha=0.7)\n\n    ax1b.plot(df_results.index, -df_results['Drawdown'], label='Drawdown (%)', color='red', linestyle=':', linewidth=1.5)\n    ax1b.fill_between(df_results.index, -df_results['Drawdown'], 0, color='red', alpha=0.2)\n    ax1b.set_ylabel('Drawdown (%)', color='red')\n    ax1b.tick_params(axis='y', labelcolor='red')\n    max_dd_val = metrics.get('Max Drawdown (%)', 100)\n    ax1b.set_ylim(bottom=min(-100, -max_dd_val * 1.2))\n\n    # Highlight Halted Periods\n    halted = df_results[df_results['Trading_Halted']]\n    if not halted.empty:\n        # Find start/end blocks of halted periods\n        halt_starts = halted.index[halted['Trading_Halted'] & ~halted['Trading_Halted'].shift(1).fillna(False)]\n        halt_ends = halted.index[halted['Trading_Halted'] & ~halted['Trading_Halted'].shift(-1).fillna(False)]\n        # Ensure equal length\n        min_len = min(len(halt_starts), len(halt_ends))\n        for start, end in zip(halt_starts[:min_len], halt_ends[:min_len]):\n             ax1.axvspan(start, end, color='grey', alpha=0.3, label='_nolegend_') # Use _nolegend_ if adding label in loop\n        # Add a single legend entry\n        if not halt_starts.empty:\n            ax1.axvspan(halt_starts[0], halt_starts[0], color='grey', alpha=0.3, label='Trading Halted')\n\n\n    # Combine legends\n    lines, labels = ax1.get_legend_handles_labels()\n    lines2, labels2 = ax1b.get_legend_handles_labels()\n    # Add halted label if present\n    halt_handles, halt_labels = [], []\n    for handle in ax1.get_legend().legendHandles:\n         if handle.get_label() == 'Trading Halted':\n              halt_handles.append(handle)\n              halt_labels.append('Trading Halted')\n              break # Only need one entry\n    ax1b.legend(lines + lines2 + halt_handles, labels + labels2 + halt_labels, loc='upper left')\n    plot_idx += 1\n\n\n    # --- 2. Price Chart and Trades ---\n    ax2 = axes[plot_idx]\n    ax2.set_title('Price and Trades')\n    ax2.plot(df_results.index, df_results['Price'], label='Price', color='black', alpha=0.8, linewidth=1)\n    ax2.set_ylabel('Price ($)')\n\n    if not trades_df.empty:\n         long_wins = trades_df[(trades_df['position_type'] == 'long') & (trades_df['return_pct'] > 0)]\n         long_losses = trades_df[(trades_df['position_type'] == 'long') & (trades_df['return_pct'] <= 0)]\n         short_wins = trades_df[(trades_df['position_type'] == 'short') & (trades_df['return_pct'] > 0)]\n         short_losses = trades_df[(trades_df['position_type'] == 'short') & (trades_df['return_pct'] <= 0)]\n\n         # Plot entry markers\n         ax2.scatter(long_wins['entry_dt'], long_wins['entry_price'], marker='^', color='lime', s=80, label='Long Win Entry', edgecolors='black', zorder=5)\n         ax2.scatter(long_losses['entry_dt'], long_losses['entry_price'], marker='^', color='red', s=80, label='Long Loss Entry', edgecolors='black', zorder=5)\n         ax2.scatter(short_wins['entry_dt'], short_wins['entry_price'], marker='v', color='lime', s=80, label='Short Win Entry', edgecolors='black', zorder=5)\n         ax2.scatter(short_losses['entry_dt'], short_losses['entry_price'], marker='v', color='red', s=80, label='Short Loss Entry', edgecolors='black', zorder=5)\n\n         # Plot exit markers (can be less prominent)\n         # ax2.scatter(trades_df['exit_dt'], trades_df['exit_price'], marker='o', color='grey', s=30, label='Exit', zorder=4)\n\n         # Plot lines connecting entry/exit for each trade\n         for _, trade in trades_df.iterrows():\n             color = 'green' if trade['return_pct'] > 0 else 'red'\n             ax2.plot([trade['entry_dt'], trade['exit_dt']], [trade['entry_price'], trade['exit_price']],\n                      color=color, linestyle='--', linewidth=0.8, alpha=0.7, zorder=3)\n\n    ax2.legend(fontsize='small', loc='upper left')\n    ax2.grid(True, axis='y', linestyle='--', alpha=0.5)\n    plot_idx += 1\n\n    # --- 3. MVRV Indicator ---\n    ax3 = axes[plot_idx]\n    ax3.set_title('MVRV Indicator and Thresholds')\n    ax3.plot(df_results.index, df_results['7d_mvrv'], label='7d MVRV', color='purple', linewidth=1.5)\n    ma_col = 'MVRV_Adaptive_MA' if config['use_dynamic_ma'] else 'MVRV_MA'\n    ax3.plot(df_results.index, df_results[ma_col], label=f'{ma_col}', color='orange', linestyle='--', linewidth=1)\n    ax3.plot(df_results.index, df_results['Positive_Threshold'], label='Upper Threshold', color='red', linestyle=':', alpha=0.8)\n    ax3.plot(df_results.index, df_results['Negative_Threshold'], label='Lower Threshold', color='green', linestyle=':', alpha=0.8)\n    ax3.axhline(0, color='grey', linestyle='-', linewidth=0.5)\n    ax3.set_ylabel('MVRV Value')\n    ax3.legend(fontsize='small', loc='upper left')\n    ax3.grid(True, axis='y', linestyle='--', alpha=0.5)\n    plot_idx += 1\n\n\n    # --- 4. MVRV Z-Score ---\n    if plot_z_score:\n        ax_z = axes[plot_idx]\n        ax_z.set_title('MVRV Z-Score')\n        ax_z.plot(df_results.index, df_results['MVRV_Z_Score'], label='MVRV Z-Score', color='teal', linewidth=1)\n        z_thresh = config.get('zscore_extreme_threshold', 2.0)\n        ax_z.axhline(z_thresh, color='red', linestyle=':', alpha=0.5, label=f'Z-Score Extreme ({z_thresh:.1f})')\n        ax_z.axhline(-z_thresh, color='red', linestyle=':', alpha=0.5)\n        ax_z.axhline(0, color='grey', linestyle='-', linewidth=0.5)\n        ax_z.set_ylabel('Z-Score')\n        ax_z.legend(fontsize='small', loc='upper left')\n        ax_z.grid(True, axis='y', linestyle='--', alpha=0.5)\n        plot_idx += 1\n\n    # --- 5. MVRV RSI ---\n    if plot_mvrv_rsi:\n        ax_rsi = axes[plot_idx]\n        ax_rsi.set_title('MVRV RSI')\n        ax_rsi.plot(df_results.index, df_results['MVRV_RSI'], label='MVRV RSI', color='magenta', linewidth=1)\n        rsi_buy_thresh = config['mvrv_rsi_buy_threshold']\n        rsi_sell_thresh = config['mvrv_rsi_sell_threshold']\n        ax_rsi.axhline(rsi_sell_thresh, color='red', linestyle=':', alpha=0.5, label=f'RSI Sell Thresh ({rsi_sell_thresh:.0f})')\n        ax_rsi.axhline(rsi_buy_thresh, color='green', linestyle=':', alpha=0.5, label=f'RSI Buy Thresh ({rsi_buy_thresh:.0f})')\n        ax_rsi.axhline(50, color='grey', linestyle='-', linewidth=0.5)\n        ax_rsi.set_ylabel('RSI')\n        ax_rsi.legend(fontsize='small', loc='upper left')\n        ax_rsi.grid(True, axis='y', linestyle='--', alpha=0.5)\n        plot_idx += 1\n\n\n    # --- Final Formatting ---\n    axes[-1].set_xlabel('Date') # Set xlabel only on the last plot\n    # Improve date formatting on x-axis\n    for ax in axes:\n        ax.xaxis.set_major_locator(mdates.AutoDateLocator(minticks=5, maxticks=12))\n        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n        plt.setp(ax.xaxis.get_majorticklabels(), rotation=30, ha='right')\n\n    plt.tight_layout(rect=[0, 0.03, 1, 0.96]) # Adjust layout\n    plt.show()\n    print(\"Plots generated.\")\n\n```\n\n```python\n# --- File: main.py ---\n\"\"\"\nMain execution script for the Dynamic MVRV Strategy backtest.\n\"\"\"\nimport pandas as pd\nimport numpy as np\nimport random\nimport warnings\n\n# Import strategy components\nfrom config import CONFIG\nfrom data_loader import load_and_preprocess_data\nfrom indicators import calculate_indicators\nfrom signals import generate_signals\nfrom backtest import run_backtest\nfrom metrics import calculate_metrics\nfrom plotting import plot_results\n\ndef main():\n    \"\"\"Main function to run the strategy workflow.\"\"\"\n    # Set seed for reproducibility (Uncomment if needed)\n    # np.random.seed(CONFIG['random_seed'])\n    # random.seed(CONFIG['random_seed'])\n\n    print(\"--- Starting Dynamic MVRV Strategy Backtest ---\")\n\n    try:\n        # 1. Load Configuration\n        cfg = CONFIG\n        active_features_str = calculate_metrics(pd.DataFrame(), pd.DataFrame(), cfg)['Active Features'] # Hacky way to get feature string\n        print(f\"Configuration loaded: {active_features_str} features active.\")\n        if cfg['position_sizing_fraction'] > 0.1: # Check for risky default\n             warnings.warn(f\"CRITICAL RISK: 'position_sizing_fraction' is {cfg['position_sizing_fraction']:.2f} ( > 10%). Modify risk.py or config.py before production.\", UserWarning)\n\n\n        # 2. Load Data\n        df_raw = load_and_preprocess_data(cfg)\n\n        # 3. Calculate Indicators\n        df_indicators = calculate_indicators(df_raw, cfg)\n\n        # 4. Generate Signals\n        df_signals = generate_signals(df_indicators, cfg)\n\n        # 5. Run Backtest (includes risk management)\n        df_results, trades_df = run_backtest(df_signals, cfg)\n\n        # 6. Calculate Metrics\n        metrics = calculate_metrics(df_results, trades_df, cfg)\n\n        # 7. Output Results Summary\n        print(\"\\n--- Backtest Performance Metrics ---\")\n        for key, value in metrics.items():\n            if isinstance(value, float):\n                # Format percentages and ratios nicely\n                if \" (%)\" in key or \"Rate\" in key or \"Factor\" in key or \"Ratio\" in key:\n                     print(f\"{key:<28}: {value:.2f}\")\n                else:\n                     print(f\"{key:<28}: {value:,.2f}\") # Format currency/equity\n            else:\n                print(f\"{key:<28}: {value}\")\n        print(\"------------------------------------\")\n\n        # Print Trade Log Summary\n        if not trades_df.empty:\n            print(\"\\n--- Trade Log Summary ---\")\n            print(f\"Total Trades: {len(trades_df)}\")\n            print(f\"Exit Reasons:\\n{trades_df['exit_reason'].value_counts().to_string()}\")\n            # print(trades_df[['exit_dt', 'position_type', 'return_pct', 'pnl', 'exit_reason']].head()) # Example columns\n            print(\"-------------------------\")\n        else:\n             print(\"\\n--- No trades executed ---\")\n\n\n        # 8. Plot Results\n        if cfg['plot_results'] and not df_results.empty:\n             plot_results(df_results, trades_df, metrics, cfg)\n\n    except (FileNotFoundError, ValueError, KeyError, IndexError) as e: # Added IndexError\n        print(f\"\\n--- STRATEGY EXECUTION ERROR ---\")\n        print(f\"An error occurred: {e}\")\n        print(\"Please check the configuration, data file integrity, and logic (e.g., sufficient data for lookbacks).\")\n        print(\"----------------------------------\")\n        # Optionally re-raise for debugging\n        # raise e\n    except Exception as e:\n         print(f\"\\n--- UNEXPECTED SYSTEM ERROR ---\")\n         print(f\"An unexpected error occurred: {type(e).__name__}: {e}\")\n         import traceback\n         traceback.print_exc()\n         print(\"-----------------------------\")\n\n\n    print(\"\\n--- Backtest Workflow Finished ---\")\n\n\nif __name__ == \"__main__\":\n    main()\n\n```\n\n```markdown\n# --- File: README.md ---\n\n# Dynamic MVRV Trading Strategy\n\n## Overview\n\nThis package implements and backtests a trading strategy based on Bitcoin's Market Value to Realized Value (MVRV) ratio, specifically the 7-day MVRV Z-Score and its relationship to a moving average. The strategy aims to identify potential undervaluation (buy signals) and overvaluation (sell signals) zones.\n\nIt includes configurable features such as:\n*   Dynamic vs. Static MVRV thresholds\n*   Market regime adjustments (experimental)\n*   MVRV RSI filtering (experimental)\n*   ATR-based volatility stops (Stop Loss / Take Profit)\n*   A hard drawdown limit for risk management.\n\n**Disclaimer:** This is for educational and research purposes only. Trading cryptocurrencies involves significant risk. Do not use this strategy with real capital without thorough validation, understanding, and adaptation to your own risk tolerance.\n\n## Structure\n\n*   `config.py`: Contains all strategy hyperparameters and settings.\n*   `data_loader.py`: Handles loading and preprocessing of CSV data.\n*   `indicators.py`: Calculates MVRV-based and technical indicators (ATR, RSI, etc.).\n*   `signals.py`: Generates entry signals based on indicator conditions.\n*   `risk.py`: Implements position sizing (CRITICAL: Review default!) and SL/TP calculations.\n*   `backtest.py`: Runs the event-driven backtest simulation loop.\n*   `metrics.py`: Calculates performance statistics (Sharpe, Sortino, Drawdown, etc.).\n*   `plotting.py`: Visualizes the equity curve, trades, and indicators.\n*   `main.py`: The main script to execute the backtest workflow.\n*   `requirements.txt`: Lists necessary Python packages and their versions.\n*   `tests/`: (Placeholder) Directory intended for unit tests. **CRITICAL: TESTS NEED TO BE IMPLEMENTED.**\n\n## Setup\n\n1.  **Clone the repository:**\n    ```bash\n    git clone <repository-url>\n    cd <repository-directory>\n    ```\n2.  **Create a virtual environment (recommended):**\n    ```bash\n    python -m venv venv\n    source venv/bin/activate  # On Windows use `venv\\Scripts\\activate`\n    ```\n3.  **Install dependencies:**\n    ```bash\n    pip install -r requirements.txt\n    ```\n4.  **Prepare Data:**\n    *   Obtain 5-minute Bitcoin OHLCV data including a `7d_mvrv` column (or adjust column names in `config.py`).\n    *   Ensure the data has a `timestamp` column (Unix seconds/milliseconds or standard datetime format).\n    *   Save the data as a CSV file.\n5.  **Configure:**\n    *   **CRITICAL:** Open `config.py` and update `\"csv_path\"` to point to your data file.\n    *   **CRITICAL:** Review the `\"position_sizing_fraction\"` in `config.py` or `risk.py`. The default of `1.0` (100% equity) is extremely risky and **must** be lowered for any realistic simulation or use. A value between 0.01 (1%) and 0.05 (5%) is more conventional.\n    *   Adjust other parameters like date ranges, feature flags (`use_...`), indicator periods, and risk settings as needed.\n\n## Usage\n\nRun the main script from the terminal:\n\n```bash\npython main.py\n```\n\nThe script will:\n1.  Load and preprocess the data according to the configuration.\n2.  Calculate indicators.\n3.  Generate trading signals.\n4.  Execute the backtest simulation.\n5.  Calculate and print performance metrics.\n6.  Display plots visualizing the results (if `plot_results` is `True` in `config.py`).\n\n## Development & Testing\n\n**Unit tests are currently missing and are essential for validating the strategy's correctness and robustness.** A `tests/` directory should be created containing test files (e.g., `test_indicators.py`, `test_risk.py`, `test_backtest.py`) using a framework like `pytest`.\n\n**Example Test Areas (Not Implemented):**\n*   Verification of look-ahead bias prevention in all indicators.\n*   Correct calculation of ATR, Z-Score, RSI.\n*   Correct SL/TP level calculation for both long/short trades under different configurations (ATR vs MVRV stops, regime adjustments).\n*   Validation that the drawdown halt triggers correctly and forces exits.\n*   Validation that trading resumes after drawdown recovery.\n*   Correct calculation of Sharpe, Sortino, and other metrics given known inputs.\n*   Edge case handling in data loading (missing columns, bad data, duplicates).\n\n```\n\n```text\n# --- File: requirements.txt ---\n# CRITICAL: Generate this file based on the actual environment used.\n# Example:\n# pandas==2.1.4\n# numpy==1.26.3\n# matplotlib==3.8.2\n\n# To generate automatically (after installing packages):\n# pip freeze > requirements.txt\n```\n\n```text\n# --- Directory: tests/ ---\n# (Empty - Needs Test Implementation Files)\n# Example files to create:\n# __init__.py (can be empty)\n# test_data_loader.py\n# test_indicators.py\n# test_risk.py\n# test_backtest.py\n# test_metrics.py\n```"
        }
      }
    ],
    "Edit Fields4": [
      {
        "json": {
          "query": "Ø¨Ø±Ø§Ù… ÛŒÚ©Ù… Ø§Ø±ÙˆØªÛŒÚ© ØµØ­Ø¨Øª Ú©Ù†"
        }
      }
    ]
  },
  "triggerCount": 0,
  "meta": {
    "templateCredsSetupCompleted": true
  }
}